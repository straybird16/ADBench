{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step-by-step Guidence on How to Install and Use ADBench**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install ADBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T16:06:57.104897Z",
     "start_time": "2023-07-19T16:06:57.092930Z"
    }
   },
   "outputs": [],
   "source": [
    "# download datasets in ADBench from the remote github repo\n",
    "from adbench.myutils import Utils\n",
    "utils = Utils()\n",
    "# we recommend jihulab for China mainland user and github otherwise\n",
    "#utils.download_datasets(repo='github')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run ADBench "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T15:33:13.848925Z",
     "start_time": "2023-07-17T15:33:13.833498Z"
    }
   },
   "source": [
    "## Run ADBench experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T14:44:03.627289Z",
     "start_time": "2023-07-19T14:26:41.551958Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nParams:\\nsuffix: file name suffix;\\n\\nparallel: running either 'unsupervise', 'semi-supervise', or 'supervise' (AD) algorithms,\\ncorresponding to the Angle I: Availability of Ground Truth Labels (Supervision);\\n\\nrealistic_synthetic_mode: testing on 'local', 'global', 'dependency', and 'cluster' anomalies, \\ncorresponding to the Angle II: Types of Anomalies;\\n\\nnoise type: evaluating algorithms on 'duplicated_anomalies', 'irrelevant_features' and 'label_contamination',\\ncorresponding to the Angle III: Model Robustness with Noisy and Corrupted Data.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adbench.run import RunPipeline\n",
    "\n",
    "'''\n",
    "Params:\n",
    "suffix: file name suffix;\n",
    "\n",
    "parallel: running either 'unsupervise', 'semi-supervise', or 'supervise' (AD) algorithms,\n",
    "corresponding to the Angle I: Availability of Ground Truth Labels (Supervision);\n",
    "\n",
    "realistic_synthetic_mode: testing on 'local', 'global', 'dependency', and 'cluster' anomalies, \n",
    "corresponding to the Angle II: Types of Anomalies;\n",
    "\n",
    "noise type: evaluating algorithms on 'duplicated_anomalies', 'irrelevant_features' and 'label_contamination',\n",
    "corresponding to the Angle III: Model Robustness with Noisy and Corrupted Data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = RunPipeline(suffix='ADBench', parallel='unsupervise', realistic_synthetic_mode='cluster', noise_type=None)\n",
    "#results = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = RunPipeline(suffix='ADBench', parallel='supervise', realistic_synthetic_mode=None, noise_type='irrelevant_features')\n",
    "#results = pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your customized algorithm on ADBench datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized model on ADBench's datasets\n",
    "from adbench.run import RunPipeline\n",
    "from adbench.baseline.SimpleAE.run import SimpleAE\n",
    "from adbench.baseline.VAE.run import VAE\n",
    "from adbench.baseline.DOCAE.run import DOCAE\n",
    "from adbench.baseline.AADOCAE.run import AADOCAE\n",
    "\n",
    "# notice that you should specify the corresponding category of your customized AD algorithm\n",
    "# for example, here we use Logistic Regression as customized clf, which belongs to the supervised algorithm\n",
    "# for your own algorithm, you can realize the same usage as other baselines by modifying the fit.py, model.py, and run.py files in the adbench/baseline/Customized\n",
    "pipeline = RunPipeline(suffix='ADBench', parallel='unsupervise', realistic_synthetic_mode=None, noise_type=None, num_seed=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ADBench algos on all datasets with every kinds of synthetic anomalies (unsupervised) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch : 1/3000, loss = 1487.138672\n",
    "epoch : 100/3000, loss = 10.363136\n",
    "epoch : 200/3000, loss = 2.878419\n",
    "epoch : 300/3000, loss = 2.028150\n",
    "epoch : 400/3000, loss = 1.230358\n",
    "epoch : 500/3000, loss = 1.005102\n",
    "epoch : 600/3000, loss = 0.697317\n",
    "epoch : 700/3000, loss = 0.598053\n",
    "epoch : 800/3000, loss = 0.733529\n",
    "epoch : 900/3000, loss = 5.462417\n",
    "epoch : 1000/3000, loss = 0.432301\n",
    "epoch : 1100/3000, loss = 0.493422\n",
    "epoch : 1200/3000, loss = 0.384208\n",
    "epoch : 1300/3000, loss = 0.371852\n",
    "epoch : 1400/3000, loss = 0.322503\n",
    "epoch : 1500/3000, loss = 0.389983\n",
    "epoch : 1600/3000, loss = 0.384546\n",
    "epoch : 1700/3000, loss = 0.484489\n",
    "epoch : 1800/3000, loss = 0.672034\n",
    "epoch : 1900/3000, loss = 0.854956\n",
    "epoch : 2000/3000, loss = 0.265423\n",
    "epoch : 2100/3000, loss = 0.451732\n",
    "epoch : 2200/3000, loss = 0.374019\n",
    "epoch : 2300/3000, loss = 0.538315\n",
    "epoch : 2400/3000, loss = 0.618200\n",
    "epoch : 2500/3000, loss = 0.277787\n",
    "epoch : 2600/3000, loss = 0.199320\n",
    "epoch : 2700/3000, loss = 0.215055\n",
    "epoch : 2800/3000, loss = 0.177954\n",
    "epoch : 2900/3000, loss = 0.276497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 97, 'Anomalies Ratio(%)': 0.97}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 116, 'Anomalies Ratio(%)': 1.16}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 95, 'Anomalies Ratio(%)': 0.95}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 578, 'Anomalies Ratio(%)': 5.78}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 597, 'Anomalies Ratio(%)': 5.97}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 13, 'Anomalies Ratio(%)': 0.13}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 34, 'Anomalies Ratio(%)': 3.4}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 170, 'Anomalies Ratio(%)': 17.0}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 139, 'Anomalies Ratio(%)': 13.9}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 169, 'Anomalies Ratio(%)': 16.9}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 46, 'Anomalies Ratio(%)': 0.46}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 35, 'Anomalies Ratio(%)': 0.35}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 34, 'Anomalies Ratio(%)': 0.34}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 369, 'Anomalies Ratio(%)': 36.9}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 374, 'Anomalies Ratio(%)': 37.4}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 349, 'Anomalies Ratio(%)': 34.9}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 315, 'Anomalies Ratio(%)': 3.15}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 334, 'Anomalies Ratio(%)': 3.34}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 332, 'Anomalies Ratio(%)': 3.32}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 38, 'Anomalies Ratio(%)': 3.8}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 43, 'Anomalies Ratio(%)': 4.3}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3548, 'Anomalies Ratio(%)': 35.48}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3533, 'Anomalies Ratio(%)': 35.33}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3500, 'Anomalies Ratio(%)': 35.0}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 230, 'Anomalies Ratio(%)': 2.3}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 241, 'Anomalies Ratio(%)': 2.41}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 227, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 367, 'Anomalies Ratio(%)': 36.7}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 346, 'Anomalies Ratio(%)': 34.6}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 669, 'Anomalies Ratio(%)': 6.69}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 697, 'Anomalies Ratio(%)': 6.97}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 714, 'Anomalies Ratio(%)': 7.14}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2081, 'Anomalies Ratio(%)': 20.81}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2082, 'Anomalies Ratio(%)': 20.82}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2066, 'Anomalies Ratio(%)': 20.66}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 5, 'Anomalies Ratio(%)': 0.05}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 90, 'Anomalies Ratio(%)': 9.0}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 95, 'Anomalies Ratio(%)': 9.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 100, 'Anomalies Ratio(%)': 10.0}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 123, 'Anomalies Ratio(%)': 12.3}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 133, 'Anomalies Ratio(%)': 13.3}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 252, 'Anomalies Ratio(%)': 2.52}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 246, 'Anomalies Ratio(%)': 2.46}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 256, 'Anomalies Ratio(%)': 2.56}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 35, 'Anomalies Ratio(%)': 3.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 45, 'Anomalies Ratio(%)': 4.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 48, 'Anomalies Ratio(%)': 4.8}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 26, 'Anomalies Ratio(%)': 2.6}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 29, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 27, 'Anomalies Ratio(%)': 2.7}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 75, 'Anomalies Ratio(%)': 7.5}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 80, 'Anomalies Ratio(%)': 8.0}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 88, 'Anomalies Ratio(%)': 8.8}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 239, 'Anomalies Ratio(%)': 23.9}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 224, 'Anomalies Ratio(%)': 22.4}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 225, 'Anomalies Ratio(%)': 22.5}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 348, 'Anomalies Ratio(%)': 34.8}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 336, 'Anomalies Ratio(%)': 33.6}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 364, 'Anomalies Ratio(%)': 36.4}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1134, 'Anomalies Ratio(%)': 11.34}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 222, 'Anomalies Ratio(%)': 2.22}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 238, 'Anomalies Ratio(%)': 2.38}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 216, 'Anomalies Ratio(%)': 2.16}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 628, 'Anomalies Ratio(%)': 6.28}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 652, 'Anomalies Ratio(%)': 6.52}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 215, 'Anomalies Ratio(%)': 21.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 215, 'Anomalies Ratio(%)': 21.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 198, 'Anomalies Ratio(%)': 19.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 251, 'Anomalies Ratio(%)': 25.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 242, 'Anomalies Ratio(%)': 24.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 242, 'Anomalies Ratio(%)': 24.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 304, 'Anomalies Ratio(%)': 30.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 29.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 254, 'Anomalies Ratio(%)': 25.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 227, 'Anomalies Ratio(%)': 22.7}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 213, 'Anomalies Ratio(%)': 21.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 180, 'Anomalies Ratio(%)': 18.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 169, 'Anomalies Ratio(%)': 16.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 174, 'Anomalies Ratio(%)': 17.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 160, 'Anomalies Ratio(%)': 16.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 142, 'Anomalies Ratio(%)': 14.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 259, 'Anomalies Ratio(%)': 25.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 273, 'Anomalies Ratio(%)': 27.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 246, 'Anomalies Ratio(%)': 24.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 284, 'Anomalies Ratio(%)': 28.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 283, 'Anomalies Ratio(%)': 28.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 281, 'Anomalies Ratio(%)': 28.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 314, 'Anomalies Ratio(%)': 31.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 300, 'Anomalies Ratio(%)': 30.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 326, 'Anomalies Ratio(%)': 32.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 240, 'Anomalies Ratio(%)': 24.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 244, 'Anomalies Ratio(%)': 24.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 266, 'Anomalies Ratio(%)': 26.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 227, 'Anomalies Ratio(%)': 22.7}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 231, 'Anomalies Ratio(%)': 23.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 252, 'Anomalies Ratio(%)': 25.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 271, 'Anomalies Ratio(%)': 27.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 285, 'Anomalies Ratio(%)': 28.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 288, 'Anomalies Ratio(%)': 28.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 115, 'Anomalies Ratio(%)': 11.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 135, 'Anomalies Ratio(%)': 13.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 114, 'Anomalies Ratio(%)': 11.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 184, 'Anomalies Ratio(%)': 18.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 189, 'Anomalies Ratio(%)': 18.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 175, 'Anomalies Ratio(%)': 17.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 305, 'Anomalies Ratio(%)': 30.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 304, 'Anomalies Ratio(%)': 30.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 320, 'Anomalies Ratio(%)': 32.0}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 40, 'Anomalies Ratio(%)': 4.0}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 178, 'Anomalies Ratio(%)': 8.9}\n",
      "epoch : 1/4000, loss = 2.220109\n",
      "epoch : 1000/4000, loss = 0.028021\n",
      "epoch : 2000/4000, loss = 0.009536\n",
      "epoch : 3000/4000, loss = 0.006469\n",
      "epoch : 4000/4000, loss = 0.004191\n",
      "self.error_median=0.0004, self.error_range=0.0006, self.latent_error_median_=0.0013, self.latent_error_range_=0.0018\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0020, self.error_std=0.0233, self.latent_error_mu_=0.0019, self.latent_error_sigma_=0.0022; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [04:29, 269.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8980718153909835, 'aucpr': 0.397970253196154}, fitting time: 269.3914966583252, inference time: 0.0019953250885009766\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.9123; AUCPR=0.4240\n",
      "Deviation AUCROC=0.7485; AUCPR=0.2300\n",
      "Max(rec, dev) AUCROC=0.8443; AUCPR=0.3432\n",
      "\n",
      "Sum of squared error AUCROC=0.8567; AUCPR=0.3538\n",
      "\n",
      "Transformer selector AUCROC=0.6178; AUCPR=0.1061\n",
      "\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 195, 'Anomalies Ratio(%)': 9.75}\n",
      "epoch : 1/4000, loss = 3.579069\n",
      "epoch : 1000/4000, loss = 0.034890\n",
      "epoch : 2000/4000, loss = 0.009272\n",
      "epoch : 3000/4000, loss = 0.006885\n",
      "epoch : 4000/4000, loss = 0.006892\n",
      "self.error_median=0.0017, self.error_range=0.0013, self.latent_error_median_=0.0017, self.latent_error_range_=0.0028\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0032, self.error_std=0.0278, self.latent_error_mu_=0.0026, self.latent_error_sigma_=0.0033; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [08:58, 269.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8216376129278533, 'aucpr': 0.29453409556453086}, fitting time: 268.74269223213196, inference time: 0.000997304916381836\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.8043; AUCPR=0.3168\n",
      "Deviation AUCROC=0.7452; AUCPR=0.2088\n",
      "Max(rec, dev) AUCROC=0.7987; AUCPR=0.2528\n",
      "\n",
      "Sum of squared error AUCROC=0.8083; AUCPR=0.2626\n",
      "\n",
      "Transformer selector AUCROC=0.5627; AUCPR=0.1016\n",
      "\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 188, 'Anomalies Ratio(%)': 9.4}\n",
      "epoch : 1/4000, loss = 2.522312\n",
      "epoch : 1000/4000, loss = 0.025844\n",
      "epoch : 2000/4000, loss = 0.018166\n",
      "epoch : 3000/4000, loss = 0.004676\n",
      "epoch : 4000/4000, loss = 0.004616\n",
      "self.error_median=0.0015, self.error_range=0.0013, self.latent_error_median_=0.0011, self.latent_error_range_=0.0018\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0025, self.error_std=0.0170, self.latent_error_mu_=0.0018, self.latent_error_sigma_=0.0029; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [13:29, 269.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8100052521008403, 'aucpr': 0.33606463353592}, fitting time: 270.4689345359802, inference time: 0.0009968280792236328\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.7941; AUCPR=0.3564\n",
      "Deviation AUCROC=0.7547; AUCPR=0.2216\n",
      "Max(rec, dev) AUCROC=0.7829; AUCPR=0.3398\n",
      "\n",
      "Sum of squared error AUCROC=0.7996; AUCPR=0.3290\n",
      "\n",
      "Transformer selector AUCROC=0.5803; AUCPR=0.1056\n",
      "\n",
      "{'Samples': 2000, 'Features': 30, 'Anomalies': 50, 'Anomalies Ratio(%)': 2.5}\n",
      "epoch : 1/4000, loss = 6.058751\n",
      "epoch : 1000/4000, loss = 0.091640\n",
      "epoch : 2000/4000, loss = 0.091058\n",
      "epoch : 3000/4000, loss = 0.070030\n",
      "epoch : 4000/4000, loss = 0.050070\n",
      "self.error_median=0.0101, self.error_range=0.0458, self.latent_error_median_=0.0020, self.latent_error_range_=0.0056\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0421, self.error_std=0.1004, self.latent_error_mu_=0.0049, self.latent_error_sigma_=0.0097; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [17:58, 29.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9986324786324786, 'aucpr': 0.9527373990531887}, fitting time: 269.0280385017395, inference time: 0.0019958019256591797\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.9984; AUCPR=0.9356\n",
      "Deviation AUCROC=0.9736; AUCPR=0.5142\n",
      "Max(rec, dev) AUCROC=0.9984; AUCPR=0.9356\n",
      "\n",
      "Sum of squared error AUCROC=0.9984; AUCPR=0.9356\n",
      "\n",
      "Transformer selector AUCROC=0.5972; AUCPR=0.0300\n",
      "\n",
      "{'Samples': 2000, 'Features': 30, 'Anomalies': 60, 'Anomalies Ratio(%)': 3.0}\n",
      "epoch : 1/4000, loss = 5.627244\n",
      "epoch : 1000/4000, loss = 0.110698\n",
      "epoch : 2000/4000, loss = 0.076210\n",
      "epoch : 3000/4000, loss = 0.064706\n",
      "epoch : 4000/4000, loss = 0.050880\n",
      "self.error_median=0.0104, self.error_range=0.0433, self.latent_error_median_=0.0021, self.latent_error_range_=0.0057\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0423, self.error_std=0.0943, self.latent_error_mu_=0.0052, self.latent_error_sigma_=0.0086; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [22:25, 42.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.997709049255441, 'aucpr': 0.9495750200665061}, fitting time: 266.8878402709961, inference time: 0.0009975433349609375\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.9989; AUCPR=0.9751\n",
      "Deviation AUCROC=0.9699; AUCPR=0.5416\n",
      "Max(rec, dev) AUCROC=0.9989; AUCPR=0.9751\n",
      "\n",
      "Sum of squared error AUCROC=0.9989; AUCPR=0.9751\n",
      "\n",
      "Transformer selector AUCROC=0.5497; AUCPR=0.0322\n",
      "\n",
      "{'Samples': 2000, 'Features': 30, 'Anomalies': 53, 'Anomalies Ratio(%)': 2.65}\n",
      "epoch : 1/4000, loss = 4.468611\n",
      "epoch : 1000/4000, loss = 0.085485\n",
      "epoch : 2000/4000, loss = 0.064586\n",
      "epoch : 3000/4000, loss = 0.052050\n",
      "epoch : 4000/4000, loss = 0.043334\n",
      "self.error_median=0.0107, self.error_range=0.0385, self.latent_error_median_=0.0017, self.latent_error_range_=0.0041\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0362, self.error_std=0.0789, self.latent_error_mu_=0.0040, self.latent_error_sigma_=0.0076; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [28:52, 68.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9980736301369862, 'aucpr': 0.9351068613404141}, fitting time: 386.23697447776794, inference time: 0.001996278762817383\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.9994; AUCPR=0.9776\n",
      "Deviation AUCROC=0.9841; AUCPR=0.6288\n",
      "Max(rec, dev) AUCROC=0.9994; AUCPR=0.9776\n",
      "\n",
      "Sum of squared error AUCROC=0.9994; AUCPR=0.9776\n",
      "\n",
      "Transformer selector AUCROC=0.5381; AUCPR=0.0280\n",
      "\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 83, 'Anomalies Ratio(%)': 4.15}\n",
      "epoch : 1/4000, loss = 0.807234\n",
      "epoch : 1000/4000, loss = 0.022430\n",
      "epoch : 2000/4000, loss = 0.007746\n",
      "epoch : 3000/4000, loss = 0.009623\n",
      "epoch : 4000/4000, loss = 0.488143\n",
      "self.error_median=0.0679, self.error_range=0.0948, self.latent_error_median_=0.0211, self.latent_error_range_=0.0455\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1679, self.error_std=0.3508, self.latent_error_mu_=0.0458, self.latent_error_sigma_=0.0823; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [37:48, 37.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5562434782608696, 'aucpr': 0.04692279337309738}, fitting time: 536.1129372119904, inference time: 0.002991914749145508\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.5433; AUCPR=0.0465\n",
      "Deviation AUCROC=0.5729; AUCPR=0.0466\n",
      "Max(rec, dev) AUCROC=0.5413; AUCPR=0.0464\n",
      "\n",
      "Sum of squared error AUCROC=0.5413; AUCPR=0.0461\n",
      "\n",
      "Transformer selector AUCROC=0.5576; AUCPR=0.0449\n",
      "\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 91, 'Anomalies Ratio(%)': 4.55}\n",
      "epoch : 1/4000, loss = 0.431338\n",
      "epoch : 1000/4000, loss = 0.012810\n",
      "epoch : 2000/4000, loss = 0.013696\n",
      "epoch : 3000/4000, loss = 0.004923\n",
      "epoch : 4000/4000, loss = 0.000663\n",
      "self.error_median=0.0003, self.error_range=0.0011, self.latent_error_median_=0.0007, self.latent_error_range_=0.0017\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0048, self.error_std=0.0201, self.latent_error_mu_=0.0020, self.latent_error_sigma_=0.0038; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [49:10, 65.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7998836532867947, 'aucpr': 0.11542030673481044}, fitting time: 680.8304467201233, inference time: 0.0019948482513427734\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.8254; AUCPR=0.1231\n",
      "Deviation AUCROC=0.7302; AUCPR=0.0901\n",
      "Max(rec, dev) AUCROC=0.7689; AUCPR=0.1053\n",
      "\n",
      "Sum of squared error AUCROC=0.7827; AUCPR=0.1085\n",
      "\n",
      "Transformer selector AUCROC=0.3287; AUCPR=0.0335\n",
      "\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 93, 'Anomalies Ratio(%)': 4.65}\n",
      "epoch : 1/4000, loss = 8.151551\n",
      "epoch : 1000/4000, loss = 0.030198\n",
      "epoch : 2000/4000, loss = 0.009125\n",
      "epoch : 3000/4000, loss = 0.015381\n",
      "epoch : 4000/4000, loss = 0.003366\n",
      "self.error_median=0.0004, self.error_range=0.0007, self.latent_error_median_=0.0009, self.latent_error_range_=0.0016\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0007, self.error_std=0.0013, self.latent_error_mu_=0.0020, self.latent_error_sigma_=0.0038; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [58:35, 94.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8630744255744256, 'aucpr': 0.22344405300679815}, fitting time: 564.8972342014313, inference time: 0.0019953250885009766\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.8679; AUCPR=0.2414\n",
      "Deviation AUCROC=0.7776; AUCPR=0.1293\n",
      "Max(rec, dev) AUCROC=0.8274; AUCPR=0.1974\n",
      "\n",
      "Sum of squared error AUCROC=0.8378; AUCPR=0.1954\n",
      "\n",
      "Transformer selector AUCROC=0.6505; AUCPR=0.0622\n",
      "\n",
      "{'Samples': 2000, 'Features': 33, 'Anomalies': 467, 'Anomalies Ratio(%)': 23.35}\n",
      "epoch : 1/4000, loss = 5.762410\n",
      "epoch : 1000/4000, loss = 0.339841\n",
      "epoch : 2000/4000, loss = 0.222598\n",
      "epoch : 3000/4000, loss = 0.215958\n",
      "epoch : 4000/4000, loss = 0.146638\n",
      "self.error_median=0.0441, self.error_range=0.2417, self.latent_error_median_=0.0076, self.latent_error_range_=0.0113\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1373, self.error_std=0.1843, self.latent_error_mu_=0.0105, self.latent_error_sigma_=0.0086; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [1:06:56, 48.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9721894409937889, 'aucpr': 0.8819852768134017}, fitting time: 500.5329587459564, inference time: 0.001994609832763672\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.9938; AUCPR=0.9762\n",
      "Deviation AUCROC=0.8636; AUCPR=0.6003\n",
      "Max(rec, dev) AUCROC=0.9938; AUCPR=0.9762\n",
      "\n",
      "Sum of squared error AUCROC=0.9937; AUCPR=0.9758\n",
      "\n",
      "Transformer selector AUCROC=0.4884; AUCPR=0.2064\n",
      "\n",
      "{'Samples': 2000, 'Features': 33, 'Anomalies': 450, 'Anomalies Ratio(%)': 22.5}\n",
      "epoch : 1/4000, loss = 6.288844\n",
      "epoch : 1000/4000, loss = 0.298023\n",
      "epoch : 2000/4000, loss = 0.204853\n",
      "epoch : 3000/4000, loss = 0.153572\n",
      "epoch : 4000/4000, loss = 0.121202\n",
      "self.error_median=0.0237, self.error_range=0.2344, self.latent_error_median_=0.0033, self.latent_error_range_=0.0111\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1140, self.error_std=0.1753, self.latent_error_mu_=0.0069, self.latent_error_sigma_=0.0085; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [1:17:40, 72.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.991047391477499, 'aucpr': 0.9673069341433927}, fitting time: 643.1963040828705, inference time: 0.005984783172607422\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.9976; AUCPR=0.9914\n",
      "Deviation AUCROC=0.9497; AUCPR=0.8069\n",
      "Max(rec, dev) AUCROC=0.9976; AUCPR=0.9914\n",
      "\n",
      "Sum of squared error AUCROC=0.9976; AUCPR=0.9914\n",
      "\n",
      "Transformer selector AUCROC=0.4735; AUCPR=0.1960\n",
      "\n",
      "{'Samples': 2000, 'Features': 33, 'Anomalies': 443, 'Anomalies Ratio(%)': 22.15}\n",
      "epoch : 1/4000, loss = 4.931129\n",
      "epoch : 1000/4000, loss = 0.263675\n",
      "epoch : 2000/4000, loss = 0.206291\n",
      "epoch : 3000/4000, loss = 0.174314\n",
      "epoch : 4000/4000, loss = 0.142210\n",
      "self.error_median=0.0400, self.error_range=0.2002, self.latent_error_median_=0.0057, self.latent_error_range_=0.0095\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1250, self.error_std=0.1763, self.latent_error_mu_=0.0086, self.latent_error_sigma_=0.0082; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [1:28:54, 105.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9827244771457552, 'aucpr': 0.9285088931343054}, fitting time: 674.010226726532, inference time: 0.0019960403442382812\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.9951; AUCPR=0.9803\n",
      "Deviation AUCROC=0.9130; AUCPR=0.7106\n",
      "Max(rec, dev) AUCROC=0.9951; AUCPR=0.9803\n",
      "\n",
      "Sum of squared error AUCROC=0.9950; AUCPR=0.9801\n",
      "\n",
      "Transformer selector AUCROC=0.5586; AUCPR=0.2198\n",
      "\n",
      "{'Samples': 2000, 'Features': 18, 'Anomalies': 74, 'Anomalies Ratio(%)': 3.7}\n",
      "epoch : 1/4000, loss = 1.555345\n",
      "epoch : 1000/4000, loss = 0.134871\n",
      "epoch : 2000/4000, loss = 0.143437\n",
      "epoch : 3000/4000, loss = 0.054483\n",
      "epoch : 4000/4000, loss = 0.044993\n",
      "self.error_median=0.0091, self.error_range=0.0200, self.latent_error_median_=0.0067, self.latent_error_range_=0.0086\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0228, self.error_std=0.0445, self.latent_error_mu_=0.0104, self.latent_error_sigma_=0.0112; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [1:38:41, 55.54s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.916404529726329, 'aucpr': 0.2807792918499178}, fitting time: 586.0225515365601, inference time: 0.007979154586791992\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.9343; AUCPR=0.2926\n",
      "Deviation AUCROC=0.8528; AUCPR=0.1908\n",
      "Max(rec, dev) AUCROC=0.9333; AUCPR=0.2912\n",
      "\n",
      "Sum of squared error AUCROC=0.9306; AUCPR=0.2895\n",
      "\n",
      "Transformer selector AUCROC=0.6162; AUCPR=0.0454\n",
      "\n",
      "{'Samples': 2000, 'Features': 18, 'Anomalies': 74, 'Anomalies Ratio(%)': 3.7}\n",
      "epoch : 1/4000, loss = 6.442049\n",
      "epoch : 1000/4000, loss = 0.193004\n",
      "epoch : 2000/4000, loss = 0.077161\n",
      "epoch : 3000/4000, loss = 0.054667\n",
      "epoch : 4000/4000, loss = 0.040153\n",
      "self.error_median=0.0070, self.error_range=0.0193, self.latent_error_median_=0.0073, self.latent_error_range_=0.0106\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0210, self.error_std=0.0479, self.latent_error_mu_=0.0111, self.latent_error_sigma_=0.0099; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [1:49:09, 78.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9399968543567159, 'aucpr': 0.30455959612738837}, fitting time: 627.8832652568817, inference time: 0.001994609832763672\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.9497; AUCPR=0.3326\n",
      "Deviation AUCROC=0.8517; AUCPR=0.1849\n",
      "Max(rec, dev) AUCROC=0.9490; AUCPR=0.3323\n",
      "\n",
      "Sum of squared error AUCROC=0.9475; AUCPR=0.3277\n",
      "\n",
      "Transformer selector AUCROC=0.6081; AUCPR=0.0445\n",
      "\n",
      "{'Samples': 2000, 'Features': 18, 'Anomalies': 80, 'Anomalies Ratio(%)': 4.0}\n",
      "epoch : 1/4000, loss = 3.550425\n",
      "epoch : 1000/4000, loss = 0.112111\n",
      "epoch : 2000/4000, loss = 0.055166\n",
      "epoch : 3000/4000, loss = 0.041705\n",
      "epoch : 4000/4000, loss = 0.039961\n",
      "self.error_median=0.0038, self.error_range=0.0152, self.latent_error_median_=0.0058, self.latent_error_range_=0.0098\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0186, self.error_std=0.0530, self.latent_error_mu_=0.0092, self.latent_error_sigma_=0.0098; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [1:58:29, 103.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9609375, 'aucpr': 0.5870745000660973}, fitting time: 559.5576980113983, inference time: 0.005983829498291016\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.9622; AUCPR=0.5793\n",
      "Deviation AUCROC=0.8961; AUCPR=0.3385\n",
      "Max(rec, dev) AUCROC=0.9618; AUCPR=0.5789\n",
      "\n",
      "Sum of squared error AUCROC=0.9625; AUCPR=0.5827\n",
      "\n",
      "Transformer selector AUCROC=0.6205; AUCPR=0.0502\n",
      "\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 691, 'Anomalies Ratio(%)': 34.55}\n",
      "epoch : 1/4000, loss = 0.453816\n",
      "epoch : 1000/4000, loss = 0.005985\n",
      "epoch : 2000/4000, loss = 0.002496\n",
      "epoch : 3000/4000, loss = 0.002042\n",
      "epoch : 4000/4000, loss = 0.001091\n",
      "self.error_median=0.0001, self.error_range=0.0001, self.latent_error_median_=0.0004, self.latent_error_range_=0.0007\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001, self.latent_error_mu_=0.0008, self.latent_error_sigma_=0.0015; alpha = 1.0000\n",
      "Current experiment parameters: ('4_breastw', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7717913731853326, 'aucpr': 0.5707456462097663}, fitting time: 585.6873507499695, inference time: 0.0019643306732177734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [2:08:15, 55.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.7840; AUCPR=0.5862\n",
      "Deviation AUCROC=0.6727; AUCPR=0.4784\n",
      "Max(rec, dev) AUCROC=0.6917; AUCPR=0.5014\n",
      "\n",
      "Sum of squared error AUCROC=0.7112; AUCPR=0.5184\n",
      "\n",
      "Transformer selector AUCROC=0.6024; AUCPR=0.3824\n",
      "\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 680, 'Anomalies Ratio(%)': 34.0}\n",
      "epoch : 1/4000, loss = 0.341392\n",
      "epoch : 1000/4000, loss = 0.022745\n",
      "epoch : 2000/4000, loss = 0.005389\n",
      "epoch : 3000/4000, loss = 0.002230\n",
      "epoch : 4000/4000, loss = 0.011096\n",
      "self.error_median=0.0022, self.error_range=0.0039, self.latent_error_median_=0.0005, self.latent_error_range_=0.0010\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0058, self.error_std=0.0146, self.latent_error_mu_=0.0013, self.latent_error_sigma_=0.0026; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [2:12:42, 63.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('4_breastw', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6500544662309368, 'aucpr': 0.4225500090474569}, fitting time: 266.71055841445923, inference time: 0.000997304916381836\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.5642; AUCPR=0.3798\n",
      "Deviation AUCROC=0.6781; AUCPR=0.4495\n",
      "Max(rec, dev) AUCROC=0.5740; AUCPR=0.3846\n",
      "\n",
      "Sum of squared error AUCROC=0.5827; AUCPR=0.3887\n",
      "\n",
      "Transformer selector AUCROC=0.5740; AUCPR=0.3448\n",
      "\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 700, 'Anomalies Ratio(%)': 35.0}\n",
      "epoch : 1/4000, loss = 0.492905\n",
      "epoch : 1000/4000, loss = 0.018356\n",
      "epoch : 2000/4000, loss = 0.003705\n",
      "epoch : 3000/4000, loss = 0.002811\n",
      "epoch : 4000/4000, loss = 0.001656\n",
      "self.error_median=0.0001, self.error_range=0.0002, self.latent_error_median_=0.0006, self.latent_error_range_=0.0011\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0002, self.latent_error_mu_=0.0013, self.latent_error_sigma_=0.0022; alpha = 1.0000\n",
      "Current experiment parameters: ('4_breastw', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7996214896214896, 'aucpr': 0.6056805574167277}, fitting time: 263.55259466171265, inference time: 0.001994609832763672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [2:17:06, 74.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.8169; AUCPR=0.6304\n",
      "Deviation AUCROC=0.6894; AUCPR=0.4778\n",
      "Max(rec, dev) AUCROC=0.7045; AUCPR=0.4986\n",
      "\n",
      "Sum of squared error AUCROC=0.7266; AUCPR=0.5214\n",
      "\n",
      "Transformer selector AUCROC=0.5300; AUCPR=0.3349\n",
      "\n",
      "{'Samples': 2000, 'Features': 13, 'Anomalies': 147, 'Anomalies Ratio(%)': 7.35}\n",
      "epoch : 1/4000, loss = 1.944205\n",
      "epoch : 1000/4000, loss = 0.063756\n",
      "epoch : 2000/4000, loss = 0.042798\n",
      "epoch : 3000/4000, loss = 0.027616\n",
      "epoch : 4000/4000, loss = 0.013057\n",
      "self.error_median=0.0030, self.error_range=0.0052, self.latent_error_median_=0.0031, self.latent_error_range_=0.0051\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0082, self.error_std=0.0185, self.latent_error_mu_=0.0048, self.latent_error_sigma_=0.0053; alpha = 1.0000\n",
      "Current experiment parameters: ('45_wine', 0.0, 1), model: Customized, metrics: {'aucroc': 0.959123610202747, 'aucpr': 0.6077509337139267}, fitting time: 264.4492244720459, inference time: 0.001995086669921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145it [2:21:31, 35.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.9605; AUCPR=0.5834\n",
      "Deviation AUCROC=0.9030; AUCPR=0.4205\n",
      "Max(rec, dev) AUCROC=0.9563; AUCPR=0.5773\n",
      "\n",
      "Sum of squared error AUCROC=0.9583; AUCPR=0.5859\n",
      "\n",
      "Transformer selector AUCROC=0.4962; AUCPR=0.0669\n",
      "\n",
      "{'Samples': 2000, 'Features': 13, 'Anomalies': 150, 'Anomalies Ratio(%)': 7.5}\n",
      "epoch : 1/4000, loss = 3.656941\n",
      "epoch : 1000/4000, loss = 0.106516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145it [2:22:51, 59.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\PhD\\IoT\\ADBench\\guidance.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PhD/IoT/ADBench/guidance.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pipeline \u001b[39m=\u001b[39m RunPipeline(suffix\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mADBench\u001b[39m\u001b[39m'\u001b[39m, parallel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39munsupervise\u001b[39m\u001b[39m'\u001b[39m, realistic_synthetic_mode\u001b[39m=\u001b[39mmode, noise_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, num_seed\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PhD/IoT/ADBench/guidance.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#results = pipeline.run(clf=VAE)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/PhD/IoT/ADBench/guidance.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m results \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mrun(clf\u001b[39m=\u001b[39mAADOCAE)\n",
      "File \u001b[1;32md:\\PhD\\IoT\\ADBench\\adbench\\run.py:344\u001b[0m, in \u001b[0;36mRunPipeline.run\u001b[1;34m(self, dataset, clf)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclf \u001b[39m=\u001b[39m clf; \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCustomized\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    343\u001b[0m \u001b[39m# fit and test model\u001b[39;00m\n\u001b[1;32m--> 344\u001b[0m time_fit, time_inference, metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_fit(dataset_name\u001b[39m=\u001b[39mdataset)\n\u001b[0;32m    345\u001b[0m results\u001b[39m.\u001b[39mappend([params, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name, metrics, time_fit, time_inference])\n\u001b[0;32m    346\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCurrent experiment parameters: \u001b[39m\u001b[39m{\u001b[39;00mparams\u001b[39m}\u001b[39;00m\u001b[39m, model: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m, metrics: \u001b[39m\u001b[39m{\u001b[39;00mmetrics\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    347\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfitting time: \u001b[39m\u001b[39m{\u001b[39;00mtime_fit\u001b[39m}\u001b[39;00m\u001b[39m, inference time: \u001b[39m\u001b[39m{\u001b[39;00mtime_inference\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\PhD\\IoT\\ADBench\\adbench\\run.py:201\u001b[0m, in \u001b[0;36mRunPipeline.model_fit\u001b[1;34m(self, dataset_name)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[39m# fitting\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclf\u001b[39m.\u001b[39mfit(X_train\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mX_train\u001b[39m\u001b[39m'\u001b[39m], y_train\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39my_train\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    202\u001b[0m     \u001b[39m#print(self.data['y_train'])\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[39m#self.clf = self.clf.fit(self.data['X_train'], self.data['y_train'])\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime(); time_fit \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32md:\\PhD\\IoT\\ADBench\\adbench\\baseline\\AADOCAE\\run.py:42\u001b[0m, in \u001b[0;36mAADOCAE.fit\u001b[1;34m(self, X_train, y_train, preprocess)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m aadocae(num_feature\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], latent_dim\u001b[39m=\u001b[39mlatent_dim, layer_config\u001b[39m=\u001b[39mlayer_config, alpha\u001b[39m=\u001b[39malpha)\n\u001b[0;32m     41\u001b[0m \u001b[39m# fitting\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(X_train\u001b[39m=\u001b[39mX_train, y_train\u001b[39m=\u001b[39my_train, epochs\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(\u001b[39m4e3\u001b[39m), lr\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m, wd\u001b[39m=\u001b[39mwd)\n\u001b[0;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLatent dim= \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Weight Decay = \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(latent_dim, wd))\n\u001b[0;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mUsing \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32md:\\PhD\\IoT\\ADBench\\adbench\\baseline\\AADOCAE\\model.py:113\u001b[0m, in \u001b[0;36maadocae.fit\u001b[1;34m(self, X_train, y_train, epochs, lr, wd)\u001b[0m\n\u001b[0;32m    111\u001b[0m     nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters(), grad_limit)\n\u001b[0;32m    112\u001b[0m     \u001b[39m# perform parameter update based on current gradients\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()    \n\u001b[0;32m    114\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    116\u001b[0m \u001b[39m# print training process for each 100 epochs\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32md:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\optim\\nadam.py:107\u001b[0m, in \u001b[0;36mNAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    103\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(group, params_with_grad, grads, exp_avgs, exp_avg_sqs, mu_products, state_steps)\n\u001b[1;32m--> 107\u001b[0m     nadam(params_with_grad,\n\u001b[0;32m    108\u001b[0m           grads,\n\u001b[0;32m    109\u001b[0m           exp_avgs,\n\u001b[0;32m    110\u001b[0m           exp_avg_sqs,\n\u001b[0;32m    111\u001b[0m           mu_products,\n\u001b[0;32m    112\u001b[0m           state_steps,\n\u001b[0;32m    113\u001b[0m           beta1\u001b[39m=\u001b[39mbeta1,\n\u001b[0;32m    114\u001b[0m           beta2\u001b[39m=\u001b[39mbeta2,\n\u001b[0;32m    115\u001b[0m           lr\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    116\u001b[0m           weight_decay\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mweight_decay\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    117\u001b[0m           momentum_decay\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mmomentum_decay\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    118\u001b[0m           eps\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39meps\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    119\u001b[0m           decoupled_weight_decay\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mdecoupled_weight_decay\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    120\u001b[0m           foreach\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mforeach\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    121\u001b[0m           capturable\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mcapturable\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    122\u001b[0m           differentiable\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    124\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\optim\\nadam.py:228\u001b[0m, in \u001b[0;36mnadam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, mu_products, state_steps, decoupled_weight_decay, foreach, capturable, differentiable, beta1, beta2, lr, weight_decay, momentum_decay, eps)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_nadam\n\u001b[1;32m--> 228\u001b[0m func(params,\n\u001b[0;32m    229\u001b[0m      grads,\n\u001b[0;32m    230\u001b[0m      exp_avgs,\n\u001b[0;32m    231\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    232\u001b[0m      mu_products,\n\u001b[0;32m    233\u001b[0m      state_steps,\n\u001b[0;32m    234\u001b[0m      beta1\u001b[39m=\u001b[39mbeta1,\n\u001b[0;32m    235\u001b[0m      beta2\u001b[39m=\u001b[39mbeta2,\n\u001b[0;32m    236\u001b[0m      lr\u001b[39m=\u001b[39mlr,\n\u001b[0;32m    237\u001b[0m      weight_decay\u001b[39m=\u001b[39mweight_decay,\n\u001b[0;32m    238\u001b[0m      momentum_decay\u001b[39m=\u001b[39mmomentum_decay,\n\u001b[0;32m    239\u001b[0m      decoupled_weight_decay\u001b[39m=\u001b[39mdecoupled_weight_decay,\n\u001b[0;32m    240\u001b[0m      eps\u001b[39m=\u001b[39meps,\n\u001b[0;32m    241\u001b[0m      capturable\u001b[39m=\u001b[39mcapturable,\n\u001b[0;32m    242\u001b[0m      differentiable\u001b[39m=\u001b[39mdifferentiable)\n",
      "File \u001b[1;32md:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\optim\\nadam.py:396\u001b[0m, in \u001b[0;36m_multi_tensor_nadam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, mu_products, state_steps, beta1, beta2, lr, weight_decay, momentum_decay, eps, decoupled_weight_decay, capturable, differentiable)\u001b[0m\n\u001b[0;32m    394\u001b[0m     torch\u001b[39m.\u001b[39m_foreach_sqrt_(bias_correction_sqrt)\n\u001b[0;32m    395\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 396\u001b[0m     bias_correction_sqrt \u001b[39m=\u001b[39m [_dispatch_sqrt(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m _get_value(step)) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m grouped_state_steps]\n\u001b[0;32m    397\u001b[0m     mus \u001b[39m=\u001b[39m [beta1 \u001b[39m*\u001b[39m (\u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (\u001b[39m0.96\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (_get_value(step) \u001b[39m*\u001b[39m momentum_decay))) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m grouped_state_steps]\n\u001b[0;32m    398\u001b[0m     mu_nexts \u001b[39m=\u001b[39m [beta1 \u001b[39m*\u001b[39m (\u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (\u001b[39m0.96\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m ((_get_value(step) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m momentum_decay)))\n\u001b[0;32m    399\u001b[0m                 \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m grouped_state_steps]\n",
      "File \u001b[1;32md:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\optim\\nadam.py:396\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    394\u001b[0m     torch\u001b[39m.\u001b[39m_foreach_sqrt_(bias_correction_sqrt)\n\u001b[0;32m    395\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 396\u001b[0m     bias_correction_sqrt \u001b[39m=\u001b[39m [_dispatch_sqrt(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m _get_value(step)) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m grouped_state_steps]\n\u001b[0;32m    397\u001b[0m     mus \u001b[39m=\u001b[39m [beta1 \u001b[39m*\u001b[39m (\u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (\u001b[39m0.96\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (_get_value(step) \u001b[39m*\u001b[39m momentum_decay))) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m grouped_state_steps]\n\u001b[0;32m    398\u001b[0m     mu_nexts \u001b[39m=\u001b[39m [beta1 \u001b[39m*\u001b[39m (\u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (\u001b[39m0.96\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m ((_get_value(step) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m momentum_decay)))\n\u001b[0;32m    399\u001b[0m                 \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m grouped_state_steps]\n",
      "File \u001b[1;32md:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36m_get_value\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m     88\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m _device_constructors() \u001b[39mand\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\n\u001b[1;32m---> 77\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for mode in [\n",
    "                #None,\n",
    "                'dependency',\n",
    "                'cluster',\n",
    "                None,\n",
    "                'local',\n",
    "                'global',\n",
    "            ]:\n",
    "    pipeline = RunPipeline(suffix='ADBench', parallel='unsupervise', realistic_synthetic_mode=mode, noise_type=None, num_seed=3)\n",
    "    #results = pipeline.run(clf=VAE)\n",
    "    results = pipeline.run(clf=AADOCAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 97, 'Anomalies Ratio(%)': 0.97}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 116, 'Anomalies Ratio(%)': 1.16}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 95, 'Anomalies Ratio(%)': 0.95}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 578, 'Anomalies Ratio(%)': 5.78}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 597, 'Anomalies Ratio(%)': 5.97}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 13, 'Anomalies Ratio(%)': 0.13}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 34, 'Anomalies Ratio(%)': 3.4}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 170, 'Anomalies Ratio(%)': 17.0}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 139, 'Anomalies Ratio(%)': 13.9}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 169, 'Anomalies Ratio(%)': 16.9}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 46, 'Anomalies Ratio(%)': 0.46}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 35, 'Anomalies Ratio(%)': 0.35}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 34, 'Anomalies Ratio(%)': 0.34}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 369, 'Anomalies Ratio(%)': 36.9}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 374, 'Anomalies Ratio(%)': 37.4}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 349, 'Anomalies Ratio(%)': 34.9}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 315, 'Anomalies Ratio(%)': 3.15}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 334, 'Anomalies Ratio(%)': 3.34}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 332, 'Anomalies Ratio(%)': 3.32}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 38, 'Anomalies Ratio(%)': 3.8}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 43, 'Anomalies Ratio(%)': 4.3}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3548, 'Anomalies Ratio(%)': 35.48}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3533, 'Anomalies Ratio(%)': 35.33}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3500, 'Anomalies Ratio(%)': 35.0}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 230, 'Anomalies Ratio(%)': 2.3}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 241, 'Anomalies Ratio(%)': 2.41}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 227, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 367, 'Anomalies Ratio(%)': 36.7}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 346, 'Anomalies Ratio(%)': 34.6}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 669, 'Anomalies Ratio(%)': 6.69}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 697, 'Anomalies Ratio(%)': 6.97}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 714, 'Anomalies Ratio(%)': 7.14}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2081, 'Anomalies Ratio(%)': 20.81}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2082, 'Anomalies Ratio(%)': 20.82}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2066, 'Anomalies Ratio(%)': 20.66}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 5, 'Anomalies Ratio(%)': 0.05}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 90, 'Anomalies Ratio(%)': 9.0}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 95, 'Anomalies Ratio(%)': 9.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 100, 'Anomalies Ratio(%)': 10.0}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 123, 'Anomalies Ratio(%)': 12.3}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 133, 'Anomalies Ratio(%)': 13.3}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 252, 'Anomalies Ratio(%)': 2.52}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 246, 'Anomalies Ratio(%)': 2.46}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 256, 'Anomalies Ratio(%)': 2.56}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 35, 'Anomalies Ratio(%)': 3.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 45, 'Anomalies Ratio(%)': 4.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 48, 'Anomalies Ratio(%)': 4.8}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 26, 'Anomalies Ratio(%)': 2.6}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 29, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 27, 'Anomalies Ratio(%)': 2.7}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 75, 'Anomalies Ratio(%)': 7.5}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 80, 'Anomalies Ratio(%)': 8.0}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 88, 'Anomalies Ratio(%)': 8.8}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 239, 'Anomalies Ratio(%)': 23.9}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 224, 'Anomalies Ratio(%)': 22.4}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 225, 'Anomalies Ratio(%)': 22.5}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 348, 'Anomalies Ratio(%)': 34.8}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 336, 'Anomalies Ratio(%)': 33.6}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 364, 'Anomalies Ratio(%)': 36.4}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1134, 'Anomalies Ratio(%)': 11.34}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 222, 'Anomalies Ratio(%)': 2.22}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 238, 'Anomalies Ratio(%)': 2.38}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 216, 'Anomalies Ratio(%)': 2.16}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 628, 'Anomalies Ratio(%)': 6.28}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 652, 'Anomalies Ratio(%)': 6.52}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 215, 'Anomalies Ratio(%)': 21.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 215, 'Anomalies Ratio(%)': 21.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 198, 'Anomalies Ratio(%)': 19.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 251, 'Anomalies Ratio(%)': 25.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 242, 'Anomalies Ratio(%)': 24.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 242, 'Anomalies Ratio(%)': 24.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 304, 'Anomalies Ratio(%)': 30.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 29.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 254, 'Anomalies Ratio(%)': 25.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 227, 'Anomalies Ratio(%)': 22.7}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 213, 'Anomalies Ratio(%)': 21.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 180, 'Anomalies Ratio(%)': 18.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 169, 'Anomalies Ratio(%)': 16.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 174, 'Anomalies Ratio(%)': 17.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 160, 'Anomalies Ratio(%)': 16.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 142, 'Anomalies Ratio(%)': 14.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 259, 'Anomalies Ratio(%)': 25.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 273, 'Anomalies Ratio(%)': 27.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 246, 'Anomalies Ratio(%)': 24.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 284, 'Anomalies Ratio(%)': 28.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 283, 'Anomalies Ratio(%)': 28.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 281, 'Anomalies Ratio(%)': 28.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 314, 'Anomalies Ratio(%)': 31.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 300, 'Anomalies Ratio(%)': 30.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 326, 'Anomalies Ratio(%)': 32.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 240, 'Anomalies Ratio(%)': 24.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 244, 'Anomalies Ratio(%)': 24.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 266, 'Anomalies Ratio(%)': 26.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 227, 'Anomalies Ratio(%)': 22.7}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 231, 'Anomalies Ratio(%)': 23.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 252, 'Anomalies Ratio(%)': 25.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 271, 'Anomalies Ratio(%)': 27.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 285, 'Anomalies Ratio(%)': 28.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 288, 'Anomalies Ratio(%)': 28.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 115, 'Anomalies Ratio(%)': 11.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 135, 'Anomalies Ratio(%)': 13.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 114, 'Anomalies Ratio(%)': 11.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 184, 'Anomalies Ratio(%)': 18.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 189, 'Anomalies Ratio(%)': 18.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 175, 'Anomalies Ratio(%)': 17.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 305, 'Anomalies Ratio(%)': 30.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 304, 'Anomalies Ratio(%)': 30.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 320, 'Anomalies Ratio(%)': 32.0}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 40, 'Anomalies Ratio(%)': 4.0}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 178, 'Anomalies Ratio(%)': 8.9}\n",
      "epoch : 1/5000, loss = 2.160360\n",
      "epoch : 1000/5000, loss = 0.001860\n",
      "epoch : 2000/5000, loss = 0.000707\n",
      "epoch : 3000/5000, loss = 0.000434\n",
      "epoch : 4000/5000, loss = 0.000484\n",
      "epoch : 5000/5000, loss = 0.000160\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:13, 73.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8132523886723466, 'aucpr': 0.34922268682260277}, fitting time: 72.86722087860107, inference time: 0.0009961128234863281\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 195, 'Anomalies Ratio(%)': 9.75}\n",
      "epoch : 1/5000, loss = 2.302387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002626\n",
      "epoch : 2000/5000, loss = 0.000656\n",
      "epoch : 3000/5000, loss = 0.000161\n",
      "epoch : 4000/5000, loss = 0.000394\n",
      "epoch : 5000/5000, loss = 0.000441\n",
      "self.error_median=0.0004, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0005, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [02:28, 74.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6239979641175722, 'aucpr': 0.2393044578672115}, fitting time: 75.24421715736389, inference time: 0.0009970664978027344\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 188, 'Anomalies Ratio(%)': 9.4}\n",
      "epoch : 1/5000, loss = 2.104271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001141\n",
      "epoch : 2000/5000, loss = 0.000925\n",
      "epoch : 3000/5000, loss = 0.000132\n",
      "epoch : 4000/5000, loss = 0.000161\n",
      "epoch : 5000/5000, loss = 0.000050\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [03:44, 75.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7419905462184875, 'aucpr': 0.2966610839607215}, fitting time: 75.99155282974243, inference time: 0.0009953975677490234\n",
      "{'Samples': 2000, 'Features': 30, 'Anomalies': 50, 'Anomalies Ratio(%)': 2.5}\n",
      "epoch : 1/5000, loss = 5.190020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.052990\n",
      "epoch : 2000/5000, loss = 0.035101\n",
      "epoch : 3000/5000, loss = 0.026868\n",
      "epoch : 4000/5000, loss = 0.020883\n",
      "epoch : 5000/5000, loss = 0.016410\n",
      "self.error_median=0.0049, self.error_range=0.0215\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0164, self.error_std=0.0320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [05:00,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9980626780626781, 'aucpr': 0.9150545750545751}, fitting time: 74.95003652572632, inference time: 0.001994609832763672\n",
      "{'Samples': 2000, 'Features': 30, 'Anomalies': 60, 'Anomalies Ratio(%)': 3.0}\n",
      "epoch : 1/5000, loss = 5.180694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.052651\n",
      "epoch : 2000/5000, loss = 0.034026\n",
      "epoch : 3000/5000, loss = 0.025809\n",
      "epoch : 4000/5000, loss = 0.018389\n",
      "epoch : 5000/5000, loss = 0.014427\n",
      "self.error_median=0.0045, self.error_range=0.0160\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0144, self.error_std=0.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [06:15, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9996181748759069, 'aucpr': 0.9885964912280703}, fitting time: 75.23700499534607, inference time: 0.0009963512420654297\n",
      "{'Samples': 2000, 'Features': 30, 'Anomalies': 53, 'Anomalies Ratio(%)': 2.65}\n",
      "epoch : 1/5000, loss = 4.756135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.045118\n",
      "epoch : 2000/5000, loss = 0.031601\n",
      "epoch : 3000/5000, loss = 0.024688\n",
      "epoch : 4000/5000, loss = 0.020705\n",
      "epoch : 5000/5000, loss = 0.016695\n",
      "self.error_median=0.0045, self.error_range=0.0190\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0167, self.error_std=0.0402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [07:31, 16.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9993578767123288, 'aucpr': 0.9801470588235295}, fitting time: 75.26809358596802, inference time: 0.0009965896606445312\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 83, 'Anomalies Ratio(%)': 4.15}\n",
      "epoch : 1/5000, loss = 0.656977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000895\n",
      "epoch : 2000/5000, loss = 0.000373\n",
      "epoch : 3000/5000, loss = 0.000149\n",
      "epoch : 4000/5000, loss = 0.000070\n",
      "epoch : 5000/5000, loss = 0.000028\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [08:47,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8953739130434782, 'aucpr': 0.19896030905140055}, fitting time: 75.8119797706604, inference time: 0.0009975433349609375\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 91, 'Anomalies Ratio(%)': 4.55}\n",
      "epoch : 1/5000, loss = 0.786855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001077\n",
      "epoch : 2000/5000, loss = 0.000172\n",
      "epoch : 3000/5000, loss = 0.000142\n",
      "epoch : 4000/5000, loss = 0.000210\n",
      "epoch : 5000/5000, loss = 0.000119\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [10:02, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7803632602934523, 'aucpr': 0.2436674635880506}, fitting time: 74.604984998703, inference time: 0.0009970664978027344\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 93, 'Anomalies Ratio(%)': 4.65}\n",
      "epoch : 1/5000, loss = 0.693825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000353\n",
      "epoch : 2000/5000, loss = 0.000274\n",
      "epoch : 3000/5000, loss = 0.000148\n",
      "epoch : 4000/5000, loss = 0.000050\n",
      "epoch : 5000/5000, loss = 0.000107\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [11:17, 14.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8425949050949051, 'aucpr': 0.26665560751541234}, fitting time: 74.80181932449341, inference time: 0.0009622573852539062\n",
      "{'Samples': 2000, 'Features': 33, 'Anomalies': 467, 'Anomalies Ratio(%)': 23.35}\n",
      "epoch : 1/5000, loss = 5.458008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.162296\n",
      "epoch : 2000/5000, loss = 0.130593\n",
      "epoch : 3000/5000, loss = 0.120214\n",
      "epoch : 4000/5000, loss = 0.109770\n",
      "epoch : 5000/5000, loss = 0.099989\n",
      "self.error_median=0.0328, self.error_range=0.1749\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0999, self.error_std=0.1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [12:31,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.991444099378882, 'aucpr': 0.9609220743455316}, fitting time: 74.44545578956604, inference time: 0.0010106563568115234\n",
      "{'Samples': 2000, 'Features': 33, 'Anomalies': 450, 'Anomalies Ratio(%)': 22.5}\n",
      "epoch : 1/5000, loss = 5.136203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.149318\n",
      "epoch : 2000/5000, loss = 0.122840\n",
      "epoch : 3000/5000, loss = 0.105428\n",
      "epoch : 4000/5000, loss = 0.093817\n",
      "epoch : 5000/5000, loss = 0.083119\n",
      "self.error_median=0.0201, self.error_range=0.1654\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0830, self.error_std=0.1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [13:47,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9955396256471526, 'aucpr': 0.9838397983352827}, fitting time: 75.19388604164124, inference time: 0.0009975433349609375\n",
      "{'Samples': 2000, 'Features': 33, 'Anomalies': 443, 'Anomalies Ratio(%)': 22.15}\n",
      "epoch : 1/5000, loss = 5.457096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.165018\n",
      "epoch : 2000/5000, loss = 0.127374\n",
      "epoch : 3000/5000, loss = 0.117580\n",
      "epoch : 4000/5000, loss = 0.110239\n",
      "epoch : 5000/5000, loss = 0.102504\n",
      "self.error_median=0.0330, self.error_range=0.1824\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1024, self.error_std=0.1432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [15:02, 13.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9938980212844746, 'aucpr': 0.9721263571098733}, fitting time: 74.69321084022522, inference time: 0.0009908676147460938\n",
      "{'Samples': 2000, 'Features': 18, 'Anomalies': 74, 'Anomalies Ratio(%)': 3.7}\n",
      "epoch : 1/5000, loss = 3.535319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.024463\n",
      "epoch : 2000/5000, loss = 0.012731\n",
      "epoch : 3000/5000, loss = 0.007797\n",
      "epoch : 4000/5000, loss = 0.006060\n",
      "epoch : 5000/5000, loss = 0.003249\n",
      "self.error_median=0.0011, self.error_range=0.0031\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0033, self.error_std=0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [16:17,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9131802453601762, 'aucpr': 0.37701815878025385}, fitting time: 74.7837073802948, inference time: 0.0019674301147460938\n",
      "{'Samples': 2000, 'Features': 18, 'Anomalies': 74, 'Anomalies Ratio(%)': 3.7}\n",
      "epoch : 1/5000, loss = 3.766863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.021232\n",
      "epoch : 2000/5000, loss = 0.007863\n",
      "epoch : 3000/5000, loss = 0.002316\n",
      "epoch : 4000/5000, loss = 0.002156\n",
      "epoch : 5000/5000, loss = 0.001773\n",
      "self.error_median=0.0011, self.error_range=0.0020\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0017, self.error_std=0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [17:31,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9231676627870399, 'aucpr': 0.2671786819396653}, fitting time: 74.51040291786194, inference time: 0.0009970664978027344\n",
      "{'Samples': 2000, 'Features': 18, 'Anomalies': 80, 'Anomalies Ratio(%)': 4.0}\n",
      "epoch : 1/5000, loss = 3.182412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.019410\n",
      "epoch : 2000/5000, loss = 0.005672\n",
      "epoch : 3000/5000, loss = 0.004028\n",
      "epoch : 4000/5000, loss = 0.002012\n",
      "epoch : 5000/5000, loss = 0.001557\n",
      "self.error_median=0.0008, self.error_range=0.0015\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0017, self.error_std=0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [18:46, 13.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9376446759259259, 'aucpr': 0.45936885951489376}, fitting time: 74.34638404846191, inference time: 0.000997304916381836\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 691, 'Anomalies Ratio(%)': 34.55}\n",
      "epoch : 1/5000, loss = 0.392557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000196\n",
      "epoch : 2000/5000, loss = 0.000162\n",
      "epoch : 3000/5000, loss = 0.000092\n",
      "epoch : 4000/5000, loss = 0.000110\n",
      "epoch : 5000/5000, loss = 0.000063\n",
      "self.error_median=0.0000, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [20:01,  7.08s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('4_breastw', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7039126747059041, 'aucpr': 0.532048301064964}, fitting time: 74.64093232154846, inference time: 0.0009846687316894531\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 680, 'Anomalies Ratio(%)': 34.0}\n",
      "epoch : 1/5000, loss = 0.482911\n",
      "epoch : 1000/5000, loss = 0.000617\n",
      "epoch : 2000/5000, loss = 0.000189\n",
      "epoch : 3000/5000, loss = 0.000107\n",
      "epoch : 4000/5000, loss = 0.000104\n",
      "epoch : 5000/5000, loss = 0.000039\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [21:16,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('4_breastw', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7100539710833829, 'aucpr': 0.534009574429186}, fitting time: 74.44708585739136, inference time: 0.0009970664978027344\n",
      "{'Samples': 2000, 'Features': 9, 'Anomalies': 700, 'Anomalies Ratio(%)': 35.0}\n",
      "epoch : 1/5000, loss = 0.528810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000427\n",
      "epoch : 2000/5000, loss = 0.000115\n",
      "epoch : 3000/5000, loss = 0.000107\n",
      "epoch : 4000/5000, loss = 0.000159\n",
      "epoch : 5000/5000, loss = 0.000084\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [22:30, 13.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('4_breastw', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7080463980463981, 'aucpr': 0.5459014855708622}, fitting time: 74.63325357437134, inference time: 0.0010111331939697266\n",
      "{'Samples': 2000, 'Features': 13, 'Anomalies': 147, 'Anomalies Ratio(%)': 7.35}\n",
      "epoch : 1/5000, loss = 2.757057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.006412\n",
      "epoch : 2000/5000, loss = 0.002300\n",
      "epoch : 3000/5000, loss = 0.000482\n",
      "epoch : 4000/5000, loss = 0.000346\n",
      "epoch : 5000/5000, loss = 0.000269\n",
      "self.error_median=0.0002, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145it [23:47,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('45_wine', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9346795291039895, 'aucpr': 0.5401445788221093}, fitting time: 76.02106761932373, inference time: 0.0009691715240478516\n",
      "{'Samples': 2000, 'Features': 13, 'Anomalies': 150, 'Anomalies Ratio(%)': 7.5}\n",
      "epoch : 1/5000, loss = 3.220864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.012163\n",
      "epoch : 2000/5000, loss = 0.006581\n",
      "epoch : 3000/5000, loss = 0.005053\n",
      "epoch : 4000/5000, loss = 0.000468\n",
      "epoch : 5000/5000, loss = 0.000975\n",
      "self.error_median=0.0008, self.error_range=0.0008\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0009, self.error_std=0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146it [25:02,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('45_wine', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8649049049049049, 'aucpr': 0.47226903593417624}, fitting time: 75.15308427810669, inference time: 0.0009961128234863281\n",
      "{'Samples': 2000, 'Features': 13, 'Anomalies': 162, 'Anomalies Ratio(%)': 8.1}\n",
      "epoch : 1/5000, loss = 3.104045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.012114\n",
      "epoch : 2000/5000, loss = 0.001474\n",
      "epoch : 3000/5000, loss = 0.001454\n",
      "epoch : 4000/5000, loss = 0.000578\n",
      "epoch : 5000/5000, loss = 0.000559\n",
      "self.error_median=0.0005, self.error_range=0.0005\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0006, self.error_std=0.0005\n",
      "Current experiment parameters: ('45_wine', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8200303714952406, 'aucpr': 0.4032548351965597}, fitting time: 74.61977434158325, inference time: 0.001003265380859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "147it [26:17, 13.20s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 2000, 'Features': 32, 'Anomalies': 716, 'Anomalies Ratio(%)': 35.8}\n",
      "epoch : 1/5000, loss = 12.756007\n",
      "epoch : 1000/5000, loss = 0.288929\n",
      "epoch : 2000/5000, loss = 0.229286\n",
      "epoch : 3000/5000, loss = 0.213671\n",
      "epoch : 4000/5000, loss = 0.201199\n",
      "epoch : 5000/5000, loss = 0.188929\n",
      "self.error_median=0.0661, self.error_range=0.3893\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1890, self.error_std=0.2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [27:32,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('18_Ionosphere', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9906493506493507, 'aucpr': 0.9633581723098179}, fitting time: 74.36970043182373, inference time: 0.000995635986328125\n",
      "{'Samples': 2000, 'Features': 32, 'Anomalies': 748, 'Anomalies Ratio(%)': 37.4}\n",
      "epoch : 1/5000, loss = 12.661130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.325559\n",
      "epoch : 2000/5000, loss = 0.256064\n",
      "epoch : 3000/5000, loss = 0.235460\n",
      "epoch : 4000/5000, loss = 0.224008\n",
      "epoch : 5000/5000, loss = 0.214231\n",
      "self.error_median=0.0675, self.error_range=0.4379\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.2141, self.error_std=0.2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [28:47,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('18_Ionosphere', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9925674392097265, 'aucpr': 0.9853980659849171}, fitting time: 75.15795254707336, inference time: 0.0009975433349609375\n",
      "{'Samples': 2000, 'Features': 32, 'Anomalies': 691, 'Anomalies Ratio(%)': 34.55}\n",
      "epoch : 1/5000, loss = 11.817395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.287995\n",
      "epoch : 2000/5000, loss = 0.234080\n",
      "epoch : 3000/5000, loss = 0.219061\n",
      "epoch : 4000/5000, loss = 0.208376\n",
      "epoch : 5000/5000, loss = 0.196793\n",
      "self.error_median=0.0647, self.error_range=0.3966\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1966, self.error_std=0.2323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171it [30:02, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('18_Ionosphere', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9950707428304508, 'aucpr': 0.9843140967456863}, fitting time: 74.66351318359375, inference time: 0.0009970664978027344\n",
      "{'Samples': 2000, 'Features': 8, 'Anomalies': 732, 'Anomalies Ratio(%)': 36.6}\n",
      "epoch : 1/5000, loss = 1.786840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001832\n",
      "epoch : 2000/5000, loss = 0.000613\n",
      "epoch : 3000/5000, loss = 0.000398\n",
      "epoch : 4000/5000, loss = 0.000096\n",
      "epoch : 5000/5000, loss = 0.000140\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "193it [31:17,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('29_Pima', 0.0, 1), model: Customized, metrics: {'aucroc': 0.649665071770335, 'aucpr': 0.4781810996733347}, fitting time: 74.41276550292969, inference time: 0.0009968280792236328\n",
      "{'Samples': 2000, 'Features': 8, 'Anomalies': 682, 'Anomalies Ratio(%)': 34.1}\n",
      "epoch : 1/5000, loss = 1.736178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000964\n",
      "epoch : 2000/5000, loss = 0.000396\n",
      "epoch : 3000/5000, loss = 0.000156\n",
      "epoch : 4000/5000, loss = 0.000148\n",
      "epoch : 5000/5000, loss = 0.000273\n",
      "self.error_median=0.0002, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "194it [32:32,  9.71s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('29_Pima', 0.0, 2), model: Customized, metrics: {'aucroc': 0.589441185551096, 'aucpr': 0.4017853123135089}, fitting time: 74.47310161590576, inference time: 0.0009970664978027344\n",
      "{'Samples': 2000, 'Features': 8, 'Anomalies': 653, 'Anomalies Ratio(%)': 32.65}\n",
      "epoch : 1/5000, loss = 1.923034\n",
      "epoch : 1000/5000, loss = 0.001063\n",
      "epoch : 2000/5000, loss = 0.000339\n",
      "epoch : 3000/5000, loss = 0.000250\n",
      "epoch : 4000/5000, loss = 0.000098\n",
      "epoch : 5000/5000, loss = 0.000189\n",
      "self.error_median=0.0002, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "195it [33:46, 13.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('29_Pima', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6105400080824409, 'aucpr': 0.4528459461482951}, fitting time: 74.48834300041199, inference time: 0.000997304916381836\n",
      "{'Samples': 2000, 'Features': 6, 'Anomalies': 263, 'Anomalies Ratio(%)': 13.15}\n",
      "epoch : 1/5000, loss = 1.088611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000251\n",
      "epoch : 2000/5000, loss = 0.000105\n",
      "epoch : 3000/5000, loss = 0.000091\n",
      "epoch : 4000/5000, loss = 0.000201\n",
      "epoch : 5000/5000, loss = 0.000062\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "217it [35:01,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('39_vertebral', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6957652032362303, 'aucpr': 0.33008746124190297}, fitting time: 74.40993332862854, inference time: 0.000997781753540039\n",
      "{'Samples': 2000, 'Features': 6, 'Anomalies': 260, 'Anomalies Ratio(%)': 13.0}\n",
      "epoch : 1/5000, loss = 1.210323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000194\n",
      "epoch : 2000/5000, loss = 0.000084\n",
      "epoch : 3000/5000, loss = 0.000053\n",
      "epoch : 4000/5000, loss = 0.000046\n",
      "epoch : 5000/5000, loss = 0.000077\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "218it [36:15,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('39_vertebral', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7076333628057765, 'aucpr': 0.41427306093105476}, fitting time: 74.26434254646301, inference time: 0.0009970664978027344\n",
      "{'Samples': 2000, 'Features': 6, 'Anomalies': 259, 'Anomalies Ratio(%)': 12.95}\n",
      "epoch : 1/5000, loss = 1.363576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000272\n",
      "epoch : 2000/5000, loss = 0.000128\n",
      "epoch : 3000/5000, loss = 0.000042\n",
      "epoch : 4000/5000, loss = 0.000045\n",
      "epoch : 5000/5000, loss = 0.000029\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "219it [37:32, 13.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('39_vertebral', 0.0, 3), model: Customized, metrics: {'aucroc': 0.777139208173691, 'aucpr': 0.39565340541343436}, fitting time: 76.01905608177185, inference time: 0.0009975433349609375\n",
      "{'Samples': 2000, 'Features': 19, 'Anomalies': 342, 'Anomalies Ratio(%)': 17.1}\n",
      "epoch : 1/5000, loss = 7.315880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.057596\n",
      "epoch : 2000/5000, loss = 0.040246\n",
      "epoch : 3000/5000, loss = 0.028043\n",
      "epoch : 4000/5000, loss = 0.023147\n",
      "epoch : 5000/5000, loss = 0.020663\n",
      "self.error_median=0.0084, self.error_range=0.0197\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0206, self.error_std=0.0359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [38:46,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('15_Hepatitis', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8961145513859858, 'aucpr': 0.6845425165147285}, fitting time: 74.31879901885986, inference time: 0.0\n",
      "{'Samples': 2000, 'Features': 19, 'Anomalies': 296, 'Anomalies Ratio(%)': 14.8}\n",
      "epoch : 1/5000, loss = 7.815926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.077923\n",
      "epoch : 2000/5000, loss = 0.034253\n",
      "epoch : 3000/5000, loss = 0.031077\n",
      "epoch : 4000/5000, loss = 0.029442\n",
      "epoch : 5000/5000, loss = 0.024930\n",
      "self.error_median=0.0095, self.error_range=0.0290\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0248, self.error_std=0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "242it [40:01,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('15_Hepatitis', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8674113327030057, 'aucpr': 0.5201820426215351}, fitting time: 73.96099758148193, inference time: 0.001001119613647461\n",
      "{'Samples': 2000, 'Features': 19, 'Anomalies': 298, 'Anomalies Ratio(%)': 14.9}\n",
      "epoch : 1/5000, loss = 7.810740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.061608\n",
      "epoch : 2000/5000, loss = 0.038440\n",
      "epoch : 3000/5000, loss = 0.032426\n",
      "epoch : 4000/5000, loss = 0.025381\n",
      "epoch : 5000/5000, loss = 0.018936\n",
      "self.error_median=0.0083, self.error_range=0.0216\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0191, self.error_std=0.0307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "243it [41:15, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('15_Hepatitis', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8665098177180676, 'aucpr': 0.4481231475455248}, fitting time: 74.55813407897949, inference time: 0.0009696483612060547\n",
      "{'Samples': 2000, 'Features': 7, 'Anomalies': 85, 'Anomalies Ratio(%)': 4.25}\n",
      "epoch : 1/5000, loss = 2.000974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002937\n",
      "epoch : 2000/5000, loss = 0.000786\n",
      "epoch : 3000/5000, loss = 0.000223\n",
      "epoch : 4000/5000, loss = 0.000106\n",
      "epoch : 5000/5000, loss = 0.000182\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 7. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "265it [42:30,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('14_glass', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6349217391304347, 'aucpr': 0.1277614565820304}, fitting time: 73.96894145011902, inference time: 0.0009672641754150391\n",
      "{'Samples': 2000, 'Features': 7, 'Anomalies': 86, 'Anomalies Ratio(%)': 4.3}\n",
      "epoch : 1/5000, loss = 2.006990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000578\n",
      "epoch : 2000/5000, loss = 0.000273\n",
      "epoch : 3000/5000, loss = 0.000180\n",
      "epoch : 4000/5000, loss = 0.000209\n",
      "epoch : 5000/5000, loss = 0.000141\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 7. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "266it [43:44,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('14_glass', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7118734923612973, 'aucpr': 0.11614000921827522}, fitting time: 74.44200778007507, inference time: 0.0009953975677490234\n",
      "{'Samples': 2000, 'Features': 7, 'Anomalies': 76, 'Anomalies Ratio(%)': 3.8}\n",
      "epoch : 1/5000, loss = 2.117245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000596\n",
      "epoch : 2000/5000, loss = 0.000482\n",
      "epoch : 3000/5000, loss = 0.000466\n",
      "epoch : 4000/5000, loss = 0.000088\n",
      "epoch : 5000/5000, loss = 0.000201\n",
      "self.error_median=0.0002, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 7. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "267it [44:59, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('14_glass', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7152437645995027, 'aucpr': 0.10828107809688044}, fitting time: 74.07336091995239, inference time: 0.0009963512420654297\n",
      "{'Samples': 2000, 'Features': 12, 'Anomalies': 61, 'Anomalies Ratio(%)': 3.05}\n",
      "epoch : 1/5000, loss = 4.511874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.012572\n",
      "epoch : 2000/5000, loss = 0.003728\n",
      "epoch : 3000/5000, loss = 0.000845\n",
      "epoch : 4000/5000, loss = 0.000575\n",
      "epoch : 5000/5000, loss = 0.000199\n",
      "self.error_median=0.0002, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 12. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "289it [46:14,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('40_vowels', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8940435280641466, 'aucpr': 0.30649381523594577}, fitting time: 74.67570209503174, inference time: 0.0010004043579101562\n",
      "{'Samples': 2000, 'Features': 12, 'Anomalies': 67, 'Anomalies Ratio(%)': 3.35}\n",
      "epoch : 1/5000, loss = 3.844928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.013272\n",
      "epoch : 2000/5000, loss = 0.005688\n",
      "epoch : 3000/5000, loss = 0.001532\n",
      "epoch : 4000/5000, loss = 0.000591\n",
      "epoch : 5000/5000, loss = 0.000541\n",
      "self.error_median=0.0004, self.error_range=0.0004\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 12. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0005, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "290it [47:28,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('40_vowels', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8743965517241379, 'aucpr': 0.36178387586561306}, fitting time: 74.60594820976257, inference time: 0.000997304916381836\n",
      "{'Samples': 2000, 'Features': 12, 'Anomalies': 73, 'Anomalies Ratio(%)': 3.65}\n",
      "epoch : 1/5000, loss = 4.132034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.008371\n",
      "epoch : 2000/5000, loss = 0.002632\n",
      "epoch : 3000/5000, loss = 0.000954\n",
      "epoch : 4000/5000, loss = 0.000537\n",
      "epoch : 5000/5000, loss = 0.000509\n",
      "self.error_median=0.0005, self.error_range=0.0004\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 12. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0005, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "291it [48:43, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('40_vowels', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8821170179301667, 'aucpr': 0.2613269917979454}, fitting time: 74.54949045181274, inference time: 0.0009925365447998047\n",
      "{'Samples': 2000, 'Features': 8, 'Anomalies': 709, 'Anomalies Ratio(%)': 35.45}\n",
      "epoch : 1/5000, loss = 1.386767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000750\n",
      "epoch : 2000/5000, loss = 0.000134\n",
      "epoch : 3000/5000, loss = 0.000280\n",
      "epoch : 4000/5000, loss = 0.000144\n",
      "epoch : 5000/5000, loss = 0.000071\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n",
      "Current experiment parameters: ('47_yeast', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7218400844342542, 'aucpr': 0.5842238713096519}, fitting time: 74.69261693954468, inference time: 0.0009970664978027344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [49:58,  7.07s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 2000, 'Features': 8, 'Anomalies': 685, 'Anomalies Ratio(%)': 34.25}\n",
      "epoch : 1/5000, loss = 1.553008\n",
      "epoch : 1000/5000, loss = 0.001065\n",
      "epoch : 2000/5000, loss = 0.000275\n",
      "epoch : 3000/5000, loss = 0.000126\n",
      "epoch : 4000/5000, loss = 0.000086\n",
      "epoch : 5000/5000, loss = 0.000066\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "314it [51:13,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('47_yeast', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7893917875887619, 'aucpr': 0.6591848152601841}, fitting time: 74.48378825187683, inference time: 0.0009970664978027344\n",
      "{'Samples': 2000, 'Features': 8, 'Anomalies': 676, 'Anomalies Ratio(%)': 33.8}\n",
      "epoch : 1/5000, loss = 1.461979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001113\n",
      "epoch : 2000/5000, loss = 0.000646\n",
      "epoch : 3000/5000, loss = 0.000145\n",
      "epoch : 4000/5000, loss = 0.000174\n",
      "epoch : 5000/5000, loss = 0.000063\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n",
      "Current experiment parameters: ('47_yeast', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7058108225484236, 'aucpr': 0.5905234709257429}, fitting time: 74.31550192832947, inference time: 0.000997304916381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "315it [52:28, 13.12s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 2000, 'Features': 32, 'Anomalies': 127, 'Anomalies Ratio(%)': 6.35}\n",
      "epoch : 1/5000, loss = 8.893805\n",
      "epoch : 1000/5000, loss = 0.102715\n",
      "epoch : 2000/5000, loss = 0.074221\n",
      "epoch : 3000/5000, loss = 0.056319\n",
      "epoch : 4000/5000, loss = 0.048568\n",
      "epoch : 5000/5000, loss = 0.037916\n",
      "self.error_median=0.0132, self.error_range=0.0507\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0380, self.error_std=0.0671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "337it [53:43,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20_letter', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9978460385840044, 'aucpr': 0.9663045716250757}, fitting time: 74.84140062332153, inference time: 0.0009968280792236328\n",
      "{'Samples': 2000, 'Features': 32, 'Anomalies': 139, 'Anomalies Ratio(%)': 6.95}\n",
      "epoch : 1/5000, loss = 8.381184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.112387\n",
      "epoch : 2000/5000, loss = 0.087525\n",
      "epoch : 3000/5000, loss = 0.071317\n",
      "epoch : 4000/5000, loss = 0.058818\n",
      "epoch : 5000/5000, loss = 0.050608\n",
      "self.error_median=0.0158, self.error_range=0.0640\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0505, self.error_std=0.0898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "338it [54:58,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20_letter', 0.0, 2), model: Customized, metrics: {'aucroc': 0.998805256869773, 'aucpr': 0.984349258142585}, fitting time: 74.54171657562256, inference time: 0.0009970664978027344\n",
      "{'Samples': 2000, 'Features': 32, 'Anomalies': 128, 'Anomalies Ratio(%)': 6.4}\n",
      "epoch : 1/5000, loss = 9.003262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.105345\n",
      "epoch : 2000/5000, loss = 0.070938\n",
      "epoch : 3000/5000, loss = 0.057109\n",
      "epoch : 4000/5000, loss = 0.051641\n",
      "epoch : 5000/5000, loss = 0.045746\n",
      "self.error_median=0.0118, self.error_range=0.0536\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0457, self.error_std=0.0881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "339it [56:12, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20_letter', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9982206405693951, 'aucpr': 0.9708915932574281}, fitting time: 74.41651463508606, inference time: 0.0009980201721191406\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "epoch : 1/5000, loss = 4.253760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.044136\n",
      "epoch : 2000/5000, loss = 0.022982\n",
      "epoch : 3000/5000, loss = 0.015556\n",
      "epoch : 4000/5000, loss = 0.011037\n",
      "epoch : 5000/5000, loss = 0.008800\n",
      "self.error_median=0.0033, self.error_range=0.0100\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0089, self.error_std=0.0155\n",
      "Current experiment parameters: ('6_cardio', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9701605861584601, 'aucpr': 0.7631108138131166}, fitting time: 74.56006503105164, inference time: 0.0009992122650146484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361it [57:27,  7.06s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "epoch : 1/5000, loss = 4.206868\n",
      "epoch : 1000/5000, loss = 0.047067\n",
      "epoch : 2000/5000, loss = 0.022264\n",
      "epoch : 3000/5000, loss = 0.018430\n",
      "epoch : 4000/5000, loss = 0.015090\n",
      "epoch : 5000/5000, loss = 0.013701\n",
      "self.error_median=0.0035, self.error_range=0.0140\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0136, self.error_std=0.0311\n",
      "Current experiment parameters: ('6_cardio', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9660225503967199, 'aucpr': 0.6669679785334846}, fitting time: 74.34658932685852, inference time: 0.000993490219116211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "362it [58:42,  9.69s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "epoch : 1/5000, loss = 4.172112\n",
      "epoch : 1000/5000, loss = 0.038203\n",
      "epoch : 2000/5000, loss = 0.021852\n",
      "epoch : 3000/5000, loss = 0.016436\n",
      "epoch : 4000/5000, loss = 0.014599\n",
      "epoch : 5000/5000, loss = 0.011814\n",
      "self.error_median=0.0035, self.error_range=0.0117\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0117, self.error_std=0.0237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "363it [59:57, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('6_cardio', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9546334611442239, 'aucpr': 0.6364071015869683}, fitting time: 74.71167063713074, inference time: 0.0009970664978027344\n",
      "{'Samples': 2000, 'Features': 27, 'Anomalies': 693, 'Anomalies Ratio(%)': 34.65}\n",
      "epoch : 1/5000, loss = 5.491672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.104288\n",
      "epoch : 2000/5000, loss = 0.074121\n",
      "epoch : 3000/5000, loss = 0.069190\n",
      "epoch : 4000/5000, loss = 0.061581\n",
      "epoch : 5000/5000, loss = 0.058358\n",
      "self.error_median=0.0112, self.error_range=0.0961\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0583, self.error_std=0.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "385it [1:01:11,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('12_fault', 0.0, 1), model: Customized, metrics: {'aucroc': 0.983590070643642, 'aucpr': 0.954830978522646}, fitting time: 74.44203066825867, inference time: 0.0009951591491699219\n",
      "{'Samples': 2000, 'Features': 27, 'Anomalies': 698, 'Anomalies Ratio(%)': 34.9}\n",
      "epoch : 1/5000, loss = 5.034594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.125057\n",
      "epoch : 2000/5000, loss = 0.100861\n",
      "epoch : 3000/5000, loss = 0.087579\n",
      "epoch : 4000/5000, loss = 0.077776\n",
      "epoch : 5000/5000, loss = 0.067692\n",
      "self.error_median=0.0129, self.error_range=0.1229\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0676, self.error_std=0.1066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "386it [1:02:26,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('12_fault', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9755993098300273, 'aucpr': 0.9352538190049855}, fitting time: 74.3822386264801, inference time: 0.0\n",
      "{'Samples': 2000, 'Features': 27, 'Anomalies': 699, 'Anomalies Ratio(%)': 34.95}\n",
      "epoch : 1/5000, loss = 5.332197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.111311\n",
      "epoch : 2000/5000, loss = 0.067997\n",
      "epoch : 3000/5000, loss = 0.057627\n",
      "epoch : 4000/5000, loss = 0.051557\n",
      "epoch : 5000/5000, loss = 0.046561\n",
      "self.error_median=0.0078, self.error_range=0.0824\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0466, self.error_std=0.0774\n",
      "Current experiment parameters: ('12_fault', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9887057387057386, 'aucpr': 0.9756732725302908}, fitting time: 75.0436339378357, inference time: 0.0009968280792236328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [1:03:41, 13.15s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\multivariate\\vine.py:73: UserWarning: Vines have not been fully tested on Python >= 3.8 and might produce wrong results.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\base.py:162: RuntimeWarning: Data does not appear to be uniform.\n",
      "  warnings.warn('Data does not appear to be uniform.', category=RuntimeWarning)\n",
      "409it [1:03:44,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [1:03:47,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "411it [1:03:49,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "epoch : 1/5000, loss = 3.527387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.038004\n",
      "epoch : 2000/5000, loss = 0.021725\n",
      "epoch : 3000/5000, loss = 0.018265\n",
      "epoch : 4000/5000, loss = 0.013173\n",
      "epoch : 5000/5000, loss = 0.011213\n",
      "self.error_median=0.0031, self.error_range=0.0121\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0112, self.error_std=0.0230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "433it [1:05:06,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('7_Cardiotocography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9444155844155844, 'aucpr': 0.8429935982752121}, fitting time: 76.243567943573, inference time: 0.0009965896606445312\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "epoch : 1/5000, loss = 3.665194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.051812\n",
      "epoch : 2000/5000, loss = 0.030883\n",
      "epoch : 3000/5000, loss = 0.026679\n",
      "epoch : 4000/5000, loss = 0.022958\n",
      "epoch : 5000/5000, loss = 0.017778\n",
      "self.error_median=0.0060, self.error_range=0.0248\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0176, self.error_std=0.0344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "434it [1:06:21,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('7_Cardiotocography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9403463203463204, 'aucpr': 0.7925025755758485}, fitting time: 75.14481258392334, inference time: 0.0009980201721191406\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "epoch : 1/5000, loss = 3.911471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.042054\n",
      "epoch : 2000/5000, loss = 0.025994\n",
      "epoch : 3000/5000, loss = 0.021360\n",
      "epoch : 4000/5000, loss = 0.018056\n",
      "epoch : 5000/5000, loss = 0.016471\n",
      "self.error_median=0.0047, self.error_range=0.0192\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0163, self.error_std=0.0383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "435it [1:07:36, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('7_Cardiotocography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9403607503607504, 'aucpr': 0.7433656279637042}, fitting time: 74.81386590003967, inference time: 0.0009963512420654297\n",
      "{'Samples': 3062, 'Features': 50, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "epoch : 1/5000, loss = 13.099015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.216398\n",
      "epoch : 2000/5000, loss = 0.172044\n",
      "epoch : 3000/5000, loss = 0.151262\n",
      "epoch : 4000/5000, loss = 0.142479\n",
      "epoch : 5000/5000, loss = 0.132982\n",
      "self.error_median=0.0419, self.error_range=0.1641\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1329, self.error_std=0.2630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "457it [1:08:57,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('25_musk', 0.0, 1), model: Customized, metrics: {'aucroc': 0.999767531964355, 'aucpr': 0.9929677890189568}, fitting time: 79.780588388443, inference time: 0.0009698867797851562\n",
      "{'Samples': 3062, 'Features': 50, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "epoch : 1/5000, loss = 13.550154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.304412\n",
      "epoch : 2000/5000, loss = 0.229282\n",
      "epoch : 3000/5000, loss = 0.191906\n",
      "epoch : 4000/5000, loss = 0.177143\n",
      "epoch : 5000/5000, loss = 0.165638\n",
      "self.error_median=0.0611, self.error_range=0.1979\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1653, self.error_std=0.2924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "458it [1:10:16,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('25_musk', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9990313831848121, 'aucpr': 0.9777025913566513}, fitting time: 79.2091703414917, inference time: 0.0019578933715820312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\multivariate\\vine.py:73: UserWarning: Vines have not been fully tested on Python >= 3.8 and might produce wrong results.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\base.py:162: RuntimeWarning: Data does not appear to be uniform.\n",
      "  warnings.warn('Data does not appear to be uniform.', category=RuntimeWarning)\n",
      "459it [1:21:55, 45.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: f(a) and f(b) must have different signs\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "epoch : 1/5000, loss = 7.220234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.048236\n",
      "epoch : 2000/5000, loss = 0.032059\n",
      "epoch : 3000/5000, loss = 0.020358\n",
      "epoch : 4000/5000, loss = 0.020879\n",
      "epoch : 5000/5000, loss = 0.018280\n",
      "self.error_median=0.0071, self.error_range=0.0221\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0183, self.error_std=0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "481it [1:23:12, 19.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('41_Waveform', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9568295114656031, 'aucpr': 0.5975125903633328}, fitting time: 77.21385979652405, inference time: 0.0019729137420654297\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "epoch : 1/5000, loss = 6.916546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.050259\n",
      "epoch : 2000/5000, loss = 0.031993\n",
      "epoch : 3000/5000, loss = 0.023653\n",
      "epoch : 4000/5000, loss = 0.019741\n",
      "epoch : 5000/5000, loss = 0.017502\n",
      "self.error_median=0.0071, self.error_range=0.0199\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0175, self.error_std=0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "482it [1:24:30, 21.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('41_Waveform', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9672316384180791, 'aucpr': 0.5555443018536926}, fitting time: 77.14705729484558, inference time: 0.0009963512420654297\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "epoch : 1/5000, loss = 7.311091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.046319\n",
      "epoch : 2000/5000, loss = 0.027395\n",
      "epoch : 3000/5000, loss = 0.018953\n",
      "epoch : 4000/5000, loss = 0.017528\n",
      "epoch : 5000/5000, loss = 0.016717\n",
      "self.error_median=0.0064, self.error_range=0.0202\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0167, self.error_std=0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "483it [1:25:47, 24.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('41_Waveform', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9648055832502493, 'aucpr': 0.4942001070177594}, fitting time: 76.92542719841003, inference time: 0.0009968280792236328\n",
      "{'Samples': 3686, 'Features': 50, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "epoch : 1/5000, loss = 17.596618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.076532\n",
      "epoch : 2000/5000, loss = 0.064836\n",
      "epoch : 3000/5000, loss = 0.056993\n",
      "epoch : 4000/5000, loss = 0.051611\n",
      "epoch : 5000/5000, loss = 0.047811\n",
      "self.error_median=0.0183, self.error_range=0.0567\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0478, self.error_std=0.1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "505it [1:27:05, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('36_speech', 0.0, 1), model: Customized, metrics: {'aucroc': 1.0, 'aucpr': 1.0}, fitting time: 77.8228690624237, inference time: 0.000997304916381836\n",
      "{'Samples': 3686, 'Features': 50, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "epoch : 1/5000, loss = 19.282906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.077262\n",
      "epoch : 2000/5000, loss = 0.066778\n",
      "epoch : 3000/5000, loss = 0.059105\n",
      "epoch : 4000/5000, loss = 0.053317\n",
      "epoch : 5000/5000, loss = 0.049815\n",
      "self.error_median=0.0210, self.error_range=0.0595\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0499, self.error_std=0.1002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "506it [1:28:23, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('36_speech', 0.0, 2), model: Customized, metrics: {'aucroc': 1.0, 'aucpr': 1.0}, fitting time: 77.59571743011475, inference time: 0.000997781753540039\n",
      "{'Samples': 3686, 'Features': 50, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "epoch : 1/5000, loss = 17.577338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.081145\n",
      "epoch : 2000/5000, loss = 0.072607\n",
      "epoch : 3000/5000, loss = 0.061291\n",
      "epoch : 4000/5000, loss = 0.057895\n",
      "epoch : 5000/5000, loss = 0.052416\n",
      "self.error_median=0.0207, self.error_range=0.0635\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0524, self.error_std=0.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "507it [1:29:41, 17.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('36_speech', 0.0, 3), model: Customized, metrics: {'aucroc': 1.0, 'aucpr': 1.0}, fitting time: 77.4642014503479, inference time: 0.000997781753540039\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "epoch : 1/5000, loss = 0.869949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000365\n",
      "epoch : 2000/5000, loss = 0.000361\n",
      "epoch : 3000/5000, loss = 0.000257\n",
      "epoch : 4000/5000, loss = 0.000031\n",
      "epoch : 5000/5000, loss = 0.000028\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "529it [1:30:59,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('38_thyroid', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8201669254658385, 'aucpr': 0.19785701608766962}, fitting time: 77.49555087089539, inference time: 0.0009963512420654297\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "epoch : 1/5000, loss = 0.861669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000265\n",
      "epoch : 2000/5000, loss = 0.000067\n",
      "epoch : 3000/5000, loss = 0.000070\n",
      "epoch : 4000/5000, loss = 0.000134\n",
      "epoch : 5000/5000, loss = 0.000010\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n",
      "Current experiment parameters: ('38_thyroid', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7819293478260869, 'aucpr': 0.11517425069347323}, fitting time: 77.65809059143066, inference time: 0.0009970664978027344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "530it [1:32:17, 11.44s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "epoch : 1/5000, loss = 1.041233\n",
      "epoch : 1000/5000, loss = 0.000609\n",
      "epoch : 2000/5000, loss = 0.000397\n",
      "epoch : 3000/5000, loss = 0.000113\n",
      "epoch : 4000/5000, loss = 0.000098\n",
      "epoch : 5000/5000, loss = 0.000051\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "531it [1:33:34, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('38_thyroid', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6464156314699794, 'aucpr': 0.0858119642066358}, fitting time: 77.43965744972229, inference time: 0.0009970664978027344\n",
      "{'Samples': 4207, 'Features': 50, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "epoch : 1/5000, loss = 0.529226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.057468\n",
      "epoch : 2000/5000, loss = 0.041559\n",
      "epoch : 3000/5000, loss = 0.031890\n",
      "epoch : 4000/5000, loss = 0.027199\n",
      "epoch : 5000/5000, loss = 0.023148\n",
      "self.error_median=0.0085, self.error_range=0.0271\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0231, self.error_std=0.0616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "553it [1:34:54,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('35_SpamBase', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9405023318066795, 'aucpr': 0.8855205028538001}, fitting time: 79.06490015983582, inference time: 0.0019669532775878906\n",
      "{'Samples': 4207, 'Features': 50, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "epoch : 1/5000, loss = 0.926012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.083585\n",
      "epoch : 2000/5000, loss = 0.071946\n",
      "epoch : 3000/5000, loss = 0.061589\n",
      "epoch : 4000/5000, loss = 0.055180\n",
      "epoch : 5000/5000, loss = 0.049806\n",
      "self.error_median=0.0222, self.error_range=0.0485\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0498, self.error_std=0.1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "554it [1:36:13, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('35_SpamBase', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8622665579187317, 'aucpr': 0.7955893647559313}, fitting time: 78.62254405021667, inference time: 0.0009970664978027344\n",
      "{'Samples': 4207, 'Features': 50, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "epoch : 1/5000, loss = 0.639930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.056169\n",
      "epoch : 2000/5000, loss = 0.041400\n",
      "epoch : 3000/5000, loss = 0.033257\n",
      "epoch : 4000/5000, loss = 0.028636\n",
      "epoch : 5000/5000, loss = 0.024961\n",
      "self.error_median=0.0072, self.error_range=0.0315\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0249, self.error_std=0.0638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "555it [1:37:32, 14.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('35_SpamBase', 0.0, 3), model: Customized, metrics: {'aucroc': 0.942473388125562, 'aucpr': 0.8884980446133813}, fitting time: 79.29722714424133, inference time: 0.0019788742065429688\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "epoch : 1/5000, loss = 0.934077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000113\n",
      "epoch : 2000/5000, loss = 0.000248\n",
      "epoch : 3000/5000, loss = 0.000227\n",
      "epoch : 4000/5000, loss = 0.000054\n",
      "epoch : 5000/5000, loss = 0.000020\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 5. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "577it [1:38:52,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('44_Wilt', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5882291557967234, 'aucpr': 0.08013908835037072}, fitting time: 79.1652295589447, inference time: 0.0009968280792236328\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "epoch : 1/5000, loss = 0.910772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000143\n",
      "epoch : 2000/5000, loss = 0.000161\n",
      "epoch : 3000/5000, loss = 0.000040\n",
      "epoch : 4000/5000, loss = 0.000069\n",
      "epoch : 5000/5000, loss = 0.000084\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 5. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n",
      "Current experiment parameters: ('44_Wilt', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5464316545397627, 'aucpr': 0.062420505327085415}, fitting time: 78.76167321205139, inference time: 0.0009672641754150391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "578it [1:40:11, 10.40s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "epoch : 1/5000, loss = 0.879803\n",
      "epoch : 1000/5000, loss = 0.000187\n",
      "epoch : 2000/5000, loss = 0.000028\n",
      "epoch : 3000/5000, loss = 0.000051\n",
      "epoch : 4000/5000, loss = 0.000066\n",
      "epoch : 5000/5000, loss = 0.000019\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 5. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "579it [1:41:30, 14.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('44_Wilt', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5593996945348296, 'aucpr': 0.0821372078545192}, fitting time: 79.07779002189636, inference time: 0.001993894577026367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\multivariate\\vine.py:73: UserWarning: Vines have not been fully tested on Python >= 3.8 and might produce wrong results.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\base.py:162: RuntimeWarning: Data does not appear to be uniform.\n",
      "  warnings.warn('Data does not appear to be uniform.', category=RuntimeWarning)\n",
      "601it [1:42:20,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "602it [1:43:11,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "603it [1:44:01, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [1:49:48, 13.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: f(a) and f(b) must have different signs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "626it [1:51:41, 17.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: f(a) and f(b) must have different signs\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "epoch : 1/5000, loss = 1.058136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001765\n",
      "epoch : 2000/5000, loss = 0.000343\n",
      "epoch : 3000/5000, loss = 0.000322\n",
      "epoch : 4000/5000, loss = 0.000217\n",
      "epoch : 5000/5000, loss = 0.000094\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "627it [1:52:56, 20.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('27_PageBlocks', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6379129581297821, 'aucpr': 0.18954691856745226}, fitting time: 75.1021716594696, inference time: 0.000997304916381836\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "epoch : 1/5000, loss = 14.153022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.061989\n",
      "epoch : 2000/5000, loss = 0.048243\n",
      "epoch : 3000/5000, loss = 0.039402\n",
      "epoch : 4000/5000, loss = 0.034579\n",
      "epoch : 5000/5000, loss = 0.031397\n",
      "self.error_median=0.0120, self.error_range=0.0382\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0313, self.error_std=0.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "649it [1:54:14, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('31_satimage-2', 0.0, 1), model: Customized, metrics: {'aucroc': 1.0, 'aucpr': 1.0000000000000002}, fitting time: 77.37214159965515, inference time: 0.0009675025939941406\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "epoch : 1/5000, loss = 13.861768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.067468\n",
      "epoch : 2000/5000, loss = 0.051825\n",
      "epoch : 3000/5000, loss = 0.042757\n",
      "epoch : 4000/5000, loss = 0.038968\n",
      "epoch : 5000/5000, loss = 0.035923\n",
      "self.error_median=0.0140, self.error_range=0.0440\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0360, self.error_std=0.0812\n",
      "Current experiment parameters: ('31_satimage-2', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9997785160575858, 'aucpr': 0.9790832893497647}, fitting time: 77.93270993232727, inference time: 0.0019941329956054688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "650it [1:55:32, 12.66s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "epoch : 1/5000, loss = 14.282182\n",
      "epoch : 1000/5000, loss = 0.066030\n",
      "epoch : 2000/5000, loss = 0.049495\n",
      "epoch : 3000/5000, loss = 0.041378\n",
      "epoch : 4000/5000, loss = 0.036970\n",
      "epoch : 5000/5000, loss = 0.034116\n",
      "self.error_median=0.0134, self.error_range=0.0424\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0341, self.error_std=0.0716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "651it [1:56:50, 16.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('31_satimage-2', 0.0, 3), model: Customized, metrics: {'aucroc': 1.0, 'aucpr': 1.0000000000000002}, fitting time: 77.5519437789917, inference time: 0.0009667873382568359\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "epoch : 1/5000, loss = 12.288578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.263845\n",
      "epoch : 2000/5000, loss = 0.224301\n",
      "epoch : 3000/5000, loss = 0.213437\n",
      "epoch : 4000/5000, loss = 0.208142\n",
      "epoch : 5000/5000, loss = 0.203328\n",
      "self.error_median=0.0325, self.error_range=0.5104\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.2033, self.error_std=0.2748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "673it [1:58:09,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('30_satellite', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9999380052571543, 'aucpr': 0.9998660146940025}, fitting time: 78.84657764434814, inference time: 0.001992940902709961\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "epoch : 1/5000, loss = 11.223975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.288540\n",
      "epoch : 2000/5000, loss = 0.247728\n",
      "epoch : 3000/5000, loss = 0.236150\n",
      "epoch : 4000/5000, loss = 0.229361\n",
      "epoch : 5000/5000, loss = 0.223778\n",
      "self.error_median=0.0335, self.error_range=0.5577\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.2240, self.error_std=0.3032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "674it [1:59:28, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('30_satellite', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9998846897783068, 'aucpr': 0.9997516842996969}, fitting time: 78.61419701576233, inference time: 0.000997781753540039\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "epoch : 1/5000, loss = 11.548193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.271752\n",
      "epoch : 2000/5000, loss = 0.237616\n",
      "epoch : 3000/5000, loss = 0.227463\n",
      "epoch : 4000/5000, loss = 0.218597\n",
      "epoch : 5000/5000, loss = 0.214004\n",
      "self.error_median=0.0340, self.error_range=0.5296\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.2139, self.error_std=0.2869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "675it [2:00:47, 14.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('30_satellite', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9997619401874721, 'aucpr': 0.9994765973109871}, fitting time: 78.64086055755615, inference time: 0.0019669532775878906\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "epoch : 1/5000, loss = 11.026856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.221365\n",
      "epoch : 2000/5000, loss = 0.181610\n",
      "epoch : 3000/5000, loss = 0.173753\n",
      "epoch : 4000/5000, loss = 0.165257\n",
      "epoch : 5000/5000, loss = 0.160215\n",
      "self.error_median=0.0202, self.error_range=0.3455\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1602, self.error_std=0.2699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "697it [2:02:06,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('19_landsat', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9994905290659699, 'aucpr': 0.9980285604797108}, fitting time: 78.70295071601868, inference time: 0.0010039806365966797\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "epoch : 1/5000, loss = 10.300806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.232472\n",
      "epoch : 2000/5000, loss = 0.197898\n",
      "epoch : 3000/5000, loss = 0.189546\n",
      "epoch : 4000/5000, loss = 0.181236\n",
      "epoch : 5000/5000, loss = 0.176465\n",
      "self.error_median=0.0208, self.error_range=0.3822\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1763, self.error_std=0.3006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "698it [2:03:25, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('19_landsat', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9993860222077073, 'aucpr': 0.9970330069478816}, fitting time: 78.72928166389465, inference time: 0.0019960403442382812\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "epoch : 1/5000, loss = 10.661777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.225848\n",
      "epoch : 2000/5000, loss = 0.193331\n",
      "epoch : 3000/5000, loss = 0.181530\n",
      "epoch : 4000/5000, loss = 0.175840\n",
      "epoch : 5000/5000, loss = 0.169409\n",
      "self.error_median=0.0200, self.error_range=0.3607\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1694, self.error_std=0.2905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "699it [2:04:44, 14.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('19_landsat', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9998432397126062, 'aucpr': 0.9994061997665517}, fitting time: 78.25365376472473, inference time: 0.0009696483612060547\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "epoch : 1/5000, loss = 5.911242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.028075\n",
      "epoch : 2000/5000, loss = 0.007712\n",
      "epoch : 3000/5000, loss = 0.004653\n",
      "epoch : 4000/5000, loss = 0.001456\n",
      "epoch : 5000/5000, loss = 0.001870\n",
      "self.error_median=0.0017, self.error_range=0.0016\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0020, self.error_std=0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "721it [2:06:04,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('28_pendigits', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9290498425912231, 'aucpr': 0.44907434017638936}, fitting time: 79.86799597740173, inference time: 0.0019941329956054688\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "epoch : 1/5000, loss = 5.793854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.028571\n",
      "epoch : 2000/5000, loss = 0.011398\n",
      "epoch : 3000/5000, loss = 0.002645\n",
      "epoch : 4000/5000, loss = 0.001639\n",
      "epoch : 5000/5000, loss = 0.000862\n",
      "self.error_median=0.0006, self.error_range=0.0005\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0008, self.error_std=0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "722it [2:07:25, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('28_pendigits', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9870164169959221, 'aucpr': 0.592560791374018}, fitting time: 80.67181134223938, inference time: 0.0019526481628417969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\multivariate\\vine.py:73: UserWarning: Vines have not been fully tested on Python >= 3.8 and might produce wrong results.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\base.py:162: RuntimeWarning: Data does not appear to be uniform.\n",
      "  warnings.warn('Data does not appear to be uniform.', category=RuntimeWarning)\n",
      "723it [2:21:03, 52.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: f(a) and f(b) must have different signs\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "epoch : 1/5000, loss = 0.709927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001119\n",
      "epoch : 2000/5000, loss = 0.000060\n",
      "epoch : 3000/5000, loss = 0.000029\n",
      "epoch : 4000/5000, loss = 0.000069\n",
      "epoch : 5000/5000, loss = 0.000017\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "745it [2:22:22, 22.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('2_annthyroid', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7430468750000001, 'aucpr': 0.30048060043977404}, fitting time: 78.03578996658325, inference time: 0.0009801387786865234\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "epoch : 1/5000, loss = 0.736334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000195\n",
      "epoch : 2000/5000, loss = 0.000231\n",
      "epoch : 3000/5000, loss = 0.000037\n",
      "epoch : 4000/5000, loss = 0.000061\n",
      "epoch : 5000/5000, loss = 0.000025\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "746it [2:23:41, 24.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('2_annthyroid', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6567000000000001, 'aucpr': 0.16588592572948135}, fitting time: 79.20709156990051, inference time: 0.001972675323486328\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "epoch : 1/5000, loss = 0.714836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000583\n",
      "epoch : 2000/5000, loss = 0.000125\n",
      "epoch : 3000/5000, loss = 0.000062\n",
      "epoch : 4000/5000, loss = 0.000023\n",
      "epoch : 5000/5000, loss = 0.000024\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "747it [2:24:59, 27.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('2_annthyroid', 0.0, 3), model: Customized, metrics: {'aucroc': 0.67155, 'aucpr': 0.20843768660772374}, fitting time: 77.76643872261047, inference time: 0.0020208358764648438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\multivariate\\vine.py:73: UserWarning: Vines have not been fully tested on Python >= 3.8 and might produce wrong results.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\base.py:162: RuntimeWarning: Data does not appear to be uniform.\n",
      "  warnings.warn('Data does not appear to be uniform.', category=RuntimeWarning)\n",
      "769it [2:25:55, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "770it [2:26:43, 13.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "771it [2:27:47, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n",
      "{'Samples': 10000, 'Features': 50, 'Anomalies': 1134, 'Anomalies Ratio(%)': 11.34}\n",
      "epoch : 1/5000, loss = 8.274124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.555189\n",
      "epoch : 2000/5000, loss = 0.470767\n",
      "epoch : 3000/5000, loss = 0.418813\n",
      "epoch : 4000/5000, loss = 0.366108\n",
      "epoch : 5000/5000, loss = 0.325614\n",
      "self.error_median=0.1393, self.error_range=0.4429\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.3227, self.error_std=0.4343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "793it [2:29:12,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('5_campaign', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9629953560371516, 'aucpr': 0.7925463045541126}, fitting time: 85.43658685684204, inference time: 0.001994609832763672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\multivariate\\vine.py:73: UserWarning: Vines have not been fully tested on Python >= 3.8 and might produce wrong results.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\base.py:162: RuntimeWarning: Data does not appear to be uniform.\n",
      "  warnings.warn('Data does not appear to be uniform.', category=RuntimeWarning)\n",
      "794it [2:30:57, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\frank.py:139: RuntimeWarning: overflow encountered in multiply\n",
      "  num = self._g(U) * self._g(V) + self._g(U)\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\frank.py:140: RuntimeWarning: overflow encountered in multiply\n",
      "  den = self._g(U) * self._g(V) + self._g(1)\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\frank.py:141: RuntimeWarning: invalid value encountered in divide\n",
      "  return num / den\n",
      "795it [2:32:46, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Unable to compute tau.\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 97, 'Anomalies Ratio(%)': 0.97}\n",
      "epoch : 1/5000, loss = 3.196320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001934\n",
      "epoch : 2000/5000, loss = 0.000779\n",
      "epoch : 3000/5000, loss = 0.000773\n",
      "epoch : 4000/5000, loss = 0.000390\n",
      "epoch : 5000/5000, loss = 0.000188\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "817it [2:34:11,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('10_cover', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9083786952030548, 'aucpr': 0.1763331997246193}, fitting time: 84.9810118675232, inference time: 0.0019943714141845703\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 116, 'Anomalies Ratio(%)': 1.16}\n",
      "epoch : 1/5000, loss = 2.920351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.006037\n",
      "epoch : 2000/5000, loss = 0.000697\n",
      "epoch : 3000/5000, loss = 0.000367\n",
      "epoch : 4000/5000, loss = 0.000308\n",
      "epoch : 5000/5000, loss = 0.000155\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "818it [2:35:38, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('10_cover', 0.0, 2), model: Customized, metrics: {'aucroc': 0.929260419176102, 'aucpr': 0.30165709201684743}, fitting time: 86.71740937232971, inference time: 0.0019805431365966797\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 95, 'Anomalies Ratio(%)': 0.95}\n",
      "epoch : 1/5000, loss = 3.072303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.004117\n",
      "epoch : 2000/5000, loss = 0.001623\n",
      "epoch : 3000/5000, loss = 0.001370\n",
      "epoch : 4000/5000, loss = 0.000172\n",
      "epoch : 5000/5000, loss = 0.000345\n",
      "self.error_median=0.0003, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "819it [2:37:08, 16.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('10_cover', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8876658334935589, 'aucpr': 0.20650773231369898}, fitting time: 89.45406031608582, inference time: 0.002020597457885742\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "epoch : 1/5000, loss = 0.358634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000021\n",
      "epoch : 2000/5000, loss = 0.000020\n",
      "epoch : 3000/5000, loss = 0.000040\n",
      "epoch : 4000/5000, loss = 0.000019\n",
      "epoch : 5000/5000, loss = 0.000005\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "841it [2:38:37,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('34_smtp', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8532844281427142, 'aucpr': 0.0022675736961451248}, fitting time: 88.60028958320618, inference time: 0.0019943714141845703\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "epoch : 1/5000, loss = 0.960693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000120\n",
      "epoch : 2000/5000, loss = 0.000150\n",
      "epoch : 3000/5000, loss = 0.000079\n",
      "epoch : 4000/5000, loss = 0.000027\n",
      "epoch : 5000/5000, loss = 0.000017\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "842it [2:40:06, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('34_smtp', 0.0, 2), model: Customized, metrics: {'aucroc': 0.4651550516838946, 'aucpr': 0.0006230529595015577}, fitting time: 88.28264474868774, inference time: 0.0010294914245605469\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 5, 'Anomalies Ratio(%)': 0.05}\n",
      "epoch : 1/5000, loss = 0.630097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000096\n",
      "epoch : 2000/5000, loss = 0.000070\n",
      "epoch : 3000/5000, loss = 0.000012\n",
      "epoch : 4000/5000, loss = 0.000005\n",
      "epoch : 5000/5000, loss = 0.000022\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "843it [2:41:34, 15.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('34_smtp', 0.0, 3), model: Customized, metrics: {'aucroc': 0.3897598398932622, 'aucpr': 0.0008137772154316272}, fitting time: 88.38805603981018, inference time: 0.0019943714141845703\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2081, 'Anomalies Ratio(%)': 20.81}\n",
      "epoch : 1/5000, loss = 0.818629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000075\n",
      "epoch : 2000/5000, loss = 0.000044\n",
      "epoch : 3000/5000, loss = 0.000045\n",
      "epoch : 4000/5000, loss = 0.000039\n",
      "epoch : 5000/5000, loss = 0.000031\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "865it [2:43:02,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('33_skin', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5310945323966157, 'aucpr': 0.23619010453532402}, fitting time: 87.90296530723572, inference time: 0.0020110607147216797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\multivariate\\vine.py:73: UserWarning: Vines have not been fully tested on Python >= 3.8 and might produce wrong results.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\base.py:162: RuntimeWarning: Data does not appear to be uniform.\n",
      "  warnings.warn('Data does not appear to be uniform.', category=RuntimeWarning)\n",
      "866it [2:43:12,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Marginal value out of bounds.\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2066, 'Anomalies Ratio(%)': 20.66}\n",
      "epoch : 1/5000, loss = 0.863676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000063\n",
      "epoch : 2000/5000, loss = 0.000242\n",
      "epoch : 3000/5000, loss = 0.000026\n",
      "epoch : 4000/5000, loss = 0.000091\n",
      "epoch : 5000/5000, loss = 0.000010\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "867it [2:44:40, 12.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('33_skin', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5084165763079425, 'aucpr': 0.21198609753178785}, fitting time: 87.76214003562927, inference time: 0.0009982585906982422\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 669, 'Anomalies Ratio(%)': 6.69}\n",
      "epoch : 1/5000, loss = 2.554499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001518\n",
      "epoch : 2000/5000, loss = 0.000883\n",
      "epoch : 3000/5000, loss = 0.000622\n",
      "epoch : 4000/5000, loss = 0.000219\n",
      "epoch : 5000/5000, loss = 0.000153\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "889it [2:46:09,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('32_shuttle', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7832132655763696, 'aucpr': 0.3009719016717858}, fitting time: 88.36200857162476, inference time: 0.001995086669921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\multivariate\\vine.py:73: UserWarning: Vines have not been fully tested on Python >= 3.8 and might produce wrong results.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\base.py:162: RuntimeWarning: Data does not appear to be uniform.\n",
      "  warnings.warn('Data does not appear to be uniform.', category=RuntimeWarning)\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\frank.py:98: RuntimeWarning: divide by zero encountered in log\n",
      "  return -1.0 / self.theta * np.log(1 + num / den)\n",
      "890it [2:46:39,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Marginal value out of bounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "891it [2:47:09,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Marginal value out of bounds.\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 222, 'Anomalies Ratio(%)': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 23.943828\n",
      "epoch : 1000/5000, loss = 0.391314\n",
      "epoch : 2000/5000, loss = 0.270113\n",
      "epoch : 3000/5000, loss = 0.224874\n",
      "epoch : 4000/5000, loss = 0.197056\n",
      "epoch : 5000/5000, loss = 0.174868\n",
      "self.error_median=0.0785, self.error_range=0.2689\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1735, self.error_std=0.2631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "913it [2:48:36,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('8_celeba', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9812580466233443, 'aucpr': 0.6998696984474544}, fitting time: 86.55178642272949, inference time: 0.0019919872283935547\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 238, 'Anomalies Ratio(%)': 2.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 23.870344\n",
      "epoch : 1000/5000, loss = 0.453806\n",
      "epoch : 2000/5000, loss = 0.296412\n",
      "epoch : 3000/5000, loss = 0.244395\n",
      "epoch : 4000/5000, loss = 0.219148\n",
      "epoch : 5000/5000, loss = 0.198721\n",
      "self.error_median=0.0918, self.error_range=0.3076\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1926, self.error_std=0.2836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "914it [2:50:06,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('8_celeba', 0.0, 2), model: Customized, metrics: {'aucroc': 0.978452483422213, 'aucpr': 0.7586844875798202}, fitting time: 88.87224078178406, inference time: 0.001994609832763672\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 216, 'Anomalies Ratio(%)': 2.16}\n",
      "epoch : 1/5000, loss = 24.013732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.377634\n",
      "epoch : 2000/5000, loss = 0.275793\n",
      "epoch : 3000/5000, loss = 0.239124\n",
      "epoch : 4000/5000, loss = 0.210780\n",
      "epoch : 5000/5000, loss = 0.189336\n",
      "self.error_median=0.0872, self.error_range=0.2999\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1877, self.error_std=0.2763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "915it [2:51:35, 13.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('8_celeba', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9845315161839864, 'aucpr': 0.7713307846145038}, fitting time: 88.55718088150024, inference time: 0.001988649368286133\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 230, 'Anomalies Ratio(%)': 2.3}\n",
      "epoch : 1/5000, loss = 0.501015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000396\n",
      "epoch : 2000/5000, loss = 0.000050\n",
      "epoch : 3000/5000, loss = 0.000032\n",
      "epoch : 4000/5000, loss = 0.000015\n",
      "epoch : 5000/5000, loss = 0.000042\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "937it [2:53:03,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('23_mammography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8257803885501807, 'aucpr': 0.28391731518915914}, fitting time: 88.07278609275818, inference time: 0.0019960403442382812\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 241, 'Anomalies Ratio(%)': 2.41}\n",
      "epoch : 1/5000, loss = 0.469651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000164\n",
      "epoch : 2000/5000, loss = 0.000054\n",
      "epoch : 3000/5000, loss = 0.000062\n",
      "epoch : 4000/5000, loss = 0.000010\n",
      "epoch : 5000/5000, loss = 0.000022\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n",
      "Current experiment parameters: ('23_mammography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.800370939587128, 'aucpr': 0.246855686586748}, fitting time: 88.42328190803528, inference time: 0.0019943714141845703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [2:54:32, 10.72s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 227, 'Anomalies Ratio(%)': 2.27}\n",
      "epoch : 1/5000, loss = 0.566805\n",
      "epoch : 1000/5000, loss = 0.000282\n",
      "epoch : 2000/5000, loss = 0.000153\n",
      "epoch : 3000/5000, loss = 0.000043\n",
      "epoch : 4000/5000, loss = 0.000035\n",
      "epoch : 5000/5000, loss = 0.000060\n",
      "self.error_median=0.0000, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "939it [2:56:00, 14.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('23_mammography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8079909317069257, 'aucpr': 0.2918142726030672}, fitting time: 88.22413420677185, inference time: 0.0019893646240234375\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3548, 'Anomalies Ratio(%)': 35.48}\n",
      "epoch : 1/5000, loss = 1.995064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001827\n",
      "epoch : 2000/5000, loss = 0.000573\n",
      "epoch : 3000/5000, loss = 0.000364\n",
      "epoch : 4000/5000, loss = 0.000298\n",
      "epoch : 5000/5000, loss = 0.000160\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "961it [2:57:29,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('22_magic.gamma', 0.0, 1), model: Customized, metrics: {'aucroc': 0.706883913036724, 'aucpr': 0.5559825712609401}, fitting time: 88.69351315498352, inference time: 0.0019941329956054688\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3533, 'Anomalies Ratio(%)': 35.33}\n",
      "epoch : 1/5000, loss = 2.095531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.005128\n",
      "epoch : 2000/5000, loss = 0.000800\n",
      "epoch : 3000/5000, loss = 0.000355\n",
      "epoch : 4000/5000, loss = 0.000239\n",
      "epoch : 5000/5000, loss = 0.000212\n",
      "self.error_median=0.0002, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "962it [2:58:58, 11.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('22_magic.gamma', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6319067302081307, 'aucpr': 0.4886485124072623}, fitting time: 88.88955163955688, inference time: 0.001994609832763672\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3500, 'Anomalies Ratio(%)': 35.0}\n",
      "epoch : 1/5000, loss = 1.983868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.005999\n",
      "epoch : 2000/5000, loss = 0.000928\n",
      "epoch : 3000/5000, loss = 0.000218\n",
      "epoch : 4000/5000, loss = 0.000175\n",
      "epoch : 5000/5000, loss = 0.000317\n",
      "self.error_median=0.0003, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "963it [3:00:28, 15.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('22_magic.gamma', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6032669108669109, 'aucpr': 0.4248509931821186}, fitting time: 89.04488062858582, inference time: 0.0010190010070800781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\multivariate\\vine.py:73: UserWarning: Vines have not been fully tested on Python >= 3.8 and might produce wrong results.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\base.py:162: RuntimeWarning: Data does not appear to be uniform.\n",
      "  warnings.warn('Data does not appear to be uniform.', category=RuntimeWarning)\n",
      "985it [3:09:42, 21.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: f(a) and f(b) must have different signs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "986it [3:35:39, 81.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: f(a) and f(b) must have different signs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "987it [6:23:51, 608.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: f(a) and f(b) must have different signs\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 46, 'Anomalies Ratio(%)': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 0.525068\n",
      "epoch : 1000/5000, loss = 0.000004\n",
      "epoch : 2000/5000, loss = 0.000027\n",
      "epoch : 3000/5000, loss = 0.000043\n",
      "epoch : 4000/5000, loss = 0.000005\n",
      "epoch : 5000/5000, loss = 0.000006\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1009it [6:25:16, 231.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('16_http', 0.0, 1), model: Customized, metrics: {'aucroc': 0.45371256339106303, 'aucpr': 0.023543590019256204}, fitting time: 84.68090987205505, inference time: 0.0019414424896240234\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 35, 'Anomalies Ratio(%)': 0.35}\n",
      "epoch : 1/5000, loss = 1.331072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000055\n",
      "epoch : 2000/5000, loss = 0.000034\n",
      "epoch : 3000/5000, loss = 0.000050\n",
      "epoch : 4000/5000, loss = 0.000044\n",
      "epoch : 5000/5000, loss = 0.000121\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [6:26:42, 225.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('16_http', 0.0, 2), model: Customized, metrics: {'aucroc': 0.4521070234113712, 'aucpr': 0.011384456551843709}, fitting time: 85.00546002388, inference time: 0.001994609832763672\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 34, 'Anomalies Ratio(%)': 0.34}\n",
      "epoch : 1/5000, loss = 1.271016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000094\n",
      "epoch : 2000/5000, loss = 0.000077\n",
      "epoch : 3000/5000, loss = 0.000016\n",
      "epoch : 4000/5000, loss = 0.000034\n",
      "epoch : 5000/5000, loss = 0.000042\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1011it [6:28:09, 218.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('16_http', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5036120401337791, 'aucpr': 0.004402189593328854}, fitting time: 87.14928388595581, inference time: 0.001994609832763672\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "epoch : 1/5000, loss = 14.447588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.019459\n",
      "epoch : 2000/5000, loss = 0.015250\n",
      "epoch : 3000/5000, loss = 0.011147\n",
      "epoch : 4000/5000, loss = 0.008483\n",
      "epoch : 5000/5000, loss = 0.006947\n",
      "self.error_median=0.0022, self.error_range=0.0070\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0069, self.error_std=0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1033it [6:29:39, 84.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('13_fraud', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9924899866488651, 'aucpr': 0.09804197994987468}, fitting time: 89.59788084030151, inference time: 0.0019843578338623047\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "epoch : 1/5000, loss = 14.701281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.020776\n",
      "epoch : 2000/5000, loss = 0.015395\n",
      "epoch : 3000/5000, loss = 0.013077\n",
      "epoch : 4000/5000, loss = 0.009980\n",
      "epoch : 5000/5000, loss = 0.007962\n",
      "self.error_median=0.0024, self.error_range=0.0091\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0080, self.error_std=0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1034it [6:31:10, 85.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('13_fraud', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9940567612687813, 'aucpr': 0.1503244425825071}, fitting time: 89.47851252555847, inference time: 0.0019948482513427734\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 13, 'Anomalies Ratio(%)': 0.13}\n",
      "epoch : 1/5000, loss = 10.628507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.024824\n",
      "epoch : 2000/5000, loss = 0.017499\n",
      "epoch : 3000/5000, loss = 0.013178\n",
      "epoch : 4000/5000, loss = 0.011178\n",
      "epoch : 5000/5000, loss = 0.008151\n",
      "self.error_median=0.0025, self.error_range=0.0091\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0082, self.error_std=0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1035it [6:32:45, 85.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('13_fraud', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9873998664886515, 'aucpr': 0.08133838383838383}, fitting time: 94.45410656929016, inference time: 0.001994609832763672\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 2.388758\n",
      "epoch : 1000/5000, loss = 0.003534\n",
      "epoch : 2000/5000, loss = 0.000755\n",
      "epoch : 3000/5000, loss = 0.000871\n",
      "epoch : 4000/5000, loss = 0.000660\n",
      "epoch : 5000/5000, loss = 0.000265\n",
      "self.error_median=0.0002, self.error_range=0.0003\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1057it [6:34:14, 34.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('11_donors', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8151620181460323, 'aucpr': 0.40289826794225747}, fitting time: 88.9282374382019, inference time: 0.0019943714141845703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\multivariate\\vine.py:73: UserWarning: Vines have not been fully tested on Python >= 3.8 and might produce wrong results.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\base.py:162: RuntimeWarning: Data does not appear to be uniform.\n",
      "  warnings.warn('Data does not appear to be uniform.', category=RuntimeWarning)\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\frank.py:98: RuntimeWarning: divide by zero encountered in log\n",
      "  return -1.0 / self.theta * np.log(1 + num / den)\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\clayton.py:86: RuntimeWarning: overflow encountered in power\n",
      "  np.power(U[i], -self.theta) + np.power(V[i], -self.theta) - 1,\n",
      "1058it [6:34:47, 34.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Marginal value out of bounds.\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 597, 'Anomalies Ratio(%)': 5.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 2.400162\n",
      "epoch : 1000/5000, loss = 0.004278\n",
      "epoch : 2000/5000, loss = 0.001876\n",
      "epoch : 3000/5000, loss = 0.001318\n",
      "epoch : 4000/5000, loss = 0.000397\n",
      "epoch : 5000/5000, loss = 0.000366\n",
      "self.error_median=0.0003, self.error_range=0.0004\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0004, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1059it [6:36:15, 37.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('11_donors', 0.0, 3), model: Customized, metrics: {'aucroc': 0.802318604084688, 'aucpr': 0.3348347460126138}, fitting time: 87.4725706577301, inference time: 0.001994609832763672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\multivariate\\vine.py:73: UserWarning: Vines have not been fully tested on Python >= 3.8 and might produce wrong results.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\base.py:162: RuntimeWarning: Data does not appear to be uniform.\n",
      "  warnings.warn('Data does not appear to be uniform.', category=RuntimeWarning)\n",
      "1081it [6:36:55, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1082it [6:37:21, 15.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1083it [6:37:56, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1105it [6:39:22,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n",
      "{'Samples': 10000, 'Features': 50, 'Anomalies': 628, 'Anomalies Ratio(%)': 6.28}\n",
      "epoch : 1/5000, loss = 5.815861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.077930\n",
      "epoch : 2000/5000, loss = 0.052420\n",
      "epoch : 3000/5000, loss = 0.040851\n",
      "epoch : 4000/5000, loss = 0.036969\n",
      "epoch : 5000/5000, loss = 0.031076\n",
      "self.error_median=0.0019, self.error_range=0.0147\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0311, self.error_std=0.1037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1106it [6:40:50, 11.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('9_census', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9766388729154687, 'aucpr': 0.6707967814638746}, fitting time: 85.61312747001648, inference time: 0.001995563507080078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\multivariate\\vine.py:73: UserWarning: Vines have not been fully tested on Python >= 3.8 and might produce wrong results.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\copulas\\bivariate\\base.py:162: RuntimeWarning: Data does not appear to be uniform.\n",
      "  warnings.warn('Data does not appear to be uniform.', category=RuntimeWarning)\n",
      "1128it [6:42:07, 21.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when generating data: Constant column.\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 97, 'Anomalies Ratio(%)': 0.97}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 116, 'Anomalies Ratio(%)': 1.16}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 95, 'Anomalies Ratio(%)': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 578, 'Anomalies Ratio(%)': 5.78}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 597, 'Anomalies Ratio(%)': 5.97}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 13, 'Anomalies Ratio(%)': 0.13}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 34, 'Anomalies Ratio(%)': 3.4}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 170, 'Anomalies Ratio(%)': 17.0}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 139, 'Anomalies Ratio(%)': 13.9}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 169, 'Anomalies Ratio(%)': 16.9}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 46, 'Anomalies Ratio(%)': 0.46}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 35, 'Anomalies Ratio(%)': 0.35}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 34, 'Anomalies Ratio(%)': 0.34}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 369, 'Anomalies Ratio(%)': 36.9}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 374, 'Anomalies Ratio(%)': 37.4}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 349, 'Anomalies Ratio(%)': 34.9}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 315, 'Anomalies Ratio(%)': 3.15}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 334, 'Anomalies Ratio(%)': 3.34}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 332, 'Anomalies Ratio(%)': 3.32}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 38, 'Anomalies Ratio(%)': 3.8}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 43, 'Anomalies Ratio(%)': 4.3}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3548, 'Anomalies Ratio(%)': 35.48}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3533, 'Anomalies Ratio(%)': 35.33}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3500, 'Anomalies Ratio(%)': 35.0}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 230, 'Anomalies Ratio(%)': 2.3}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 241, 'Anomalies Ratio(%)': 2.41}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 227, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 367, 'Anomalies Ratio(%)': 36.7}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 346, 'Anomalies Ratio(%)': 34.6}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 669, 'Anomalies Ratio(%)': 6.69}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 697, 'Anomalies Ratio(%)': 6.97}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 714, 'Anomalies Ratio(%)': 7.14}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2081, 'Anomalies Ratio(%)': 20.81}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2082, 'Anomalies Ratio(%)': 20.82}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2066, 'Anomalies Ratio(%)': 20.66}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 5, 'Anomalies Ratio(%)': 0.05}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 90, 'Anomalies Ratio(%)': 9.0}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 95, 'Anomalies Ratio(%)': 9.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 100, 'Anomalies Ratio(%)': 10.0}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 123, 'Anomalies Ratio(%)': 12.3}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 133, 'Anomalies Ratio(%)': 13.3}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 252, 'Anomalies Ratio(%)': 2.52}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 246, 'Anomalies Ratio(%)': 2.46}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 256, 'Anomalies Ratio(%)': 2.56}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 35, 'Anomalies Ratio(%)': 3.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 45, 'Anomalies Ratio(%)': 4.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 48, 'Anomalies Ratio(%)': 4.8}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 26, 'Anomalies Ratio(%)': 2.6}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 29, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 27, 'Anomalies Ratio(%)': 2.7}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 75, 'Anomalies Ratio(%)': 7.5}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 80, 'Anomalies Ratio(%)': 8.0}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 88, 'Anomalies Ratio(%)': 8.8}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 239, 'Anomalies Ratio(%)': 23.9}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 224, 'Anomalies Ratio(%)': 22.4}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 225, 'Anomalies Ratio(%)': 22.5}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 348, 'Anomalies Ratio(%)': 34.8}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 336, 'Anomalies Ratio(%)': 33.6}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 364, 'Anomalies Ratio(%)': 36.4}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1134, 'Anomalies Ratio(%)': 11.34}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 222, 'Anomalies Ratio(%)': 2.22}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 238, 'Anomalies Ratio(%)': 2.38}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 216, 'Anomalies Ratio(%)': 2.16}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 628, 'Anomalies Ratio(%)': 6.28}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 652, 'Anomalies Ratio(%)': 6.52}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 215, 'Anomalies Ratio(%)': 21.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 215, 'Anomalies Ratio(%)': 21.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 198, 'Anomalies Ratio(%)': 19.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 251, 'Anomalies Ratio(%)': 25.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 242, 'Anomalies Ratio(%)': 24.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 242, 'Anomalies Ratio(%)': 24.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 304, 'Anomalies Ratio(%)': 30.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 29.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 254, 'Anomalies Ratio(%)': 25.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 227, 'Anomalies Ratio(%)': 22.7}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 213, 'Anomalies Ratio(%)': 21.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 180, 'Anomalies Ratio(%)': 18.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 169, 'Anomalies Ratio(%)': 16.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 174, 'Anomalies Ratio(%)': 17.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 160, 'Anomalies Ratio(%)': 16.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 142, 'Anomalies Ratio(%)': 14.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 259, 'Anomalies Ratio(%)': 25.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 273, 'Anomalies Ratio(%)': 27.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 246, 'Anomalies Ratio(%)': 24.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 284, 'Anomalies Ratio(%)': 28.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 283, 'Anomalies Ratio(%)': 28.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 281, 'Anomalies Ratio(%)': 28.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 314, 'Anomalies Ratio(%)': 31.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 300, 'Anomalies Ratio(%)': 30.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 326, 'Anomalies Ratio(%)': 32.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 240, 'Anomalies Ratio(%)': 24.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 244, 'Anomalies Ratio(%)': 24.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 266, 'Anomalies Ratio(%)': 26.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 227, 'Anomalies Ratio(%)': 22.7}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 231, 'Anomalies Ratio(%)': 23.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 252, 'Anomalies Ratio(%)': 25.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 271, 'Anomalies Ratio(%)': 27.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 285, 'Anomalies Ratio(%)': 28.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 288, 'Anomalies Ratio(%)': 28.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 115, 'Anomalies Ratio(%)': 11.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 135, 'Anomalies Ratio(%)': 13.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 114, 'Anomalies Ratio(%)': 11.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 184, 'Anomalies Ratio(%)': 18.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 189, 'Anomalies Ratio(%)': 18.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 175, 'Anomalies Ratio(%)': 17.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 305, 'Anomalies Ratio(%)': 30.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 304, 'Anomalies Ratio(%)': 30.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 320, 'Anomalies Ratio(%)': 32.0}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 40, 'Anomalies Ratio(%)': 4.0}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 90, 'Anomalies Ratio(%)': 9.0}\n",
      "epoch : 1/5000, loss = 0.548347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000591\n",
      "epoch : 2000/5000, loss = 0.000227\n",
      "epoch : 3000/5000, loss = 0.000120\n",
      "epoch : 4000/5000, loss = 0.000099\n",
      "epoch : 5000/5000, loss = 0.000064\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:29, 89.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9907746574413241, 'aucpr': 0.8021200947074139}, fitting time: 88.42637777328491, inference time: 0.0009970664978027344\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 95, 'Anomalies Ratio(%)': 9.5}\n",
      "epoch : 1/5000, loss = 0.615740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000885\n",
      "epoch : 2000/5000, loss = 0.000425\n",
      "epoch : 3000/5000, loss = 0.000236\n",
      "epoch : 4000/5000, loss = 0.000104\n",
      "epoch : 5000/5000, loss = 0.000058\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [02:58, 89.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9637605042016807, 'aucpr': 0.7007462853202926}, fitting time: 89.17563104629517, inference time: 0.0019829273223876953\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 100, 'Anomalies Ratio(%)': 10.0}\n",
      "epoch : 1/5000, loss = 0.568706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000621\n",
      "epoch : 2000/5000, loss = 0.000325\n",
      "epoch : 3000/5000, loss = 0.000132\n",
      "epoch : 4000/5000, loss = 0.000041\n",
      "epoch : 5000/5000, loss = 0.000025\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [04:28, 89.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9219753086419753, 'aucpr': 0.4389332363141783}, fitting time: 89.23732089996338, inference time: 0.0009963512420654297\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 26, 'Anomalies Ratio(%)': 2.6}\n",
      "epoch : 1/5000, loss = 1.912401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.010674\n",
      "epoch : 2000/5000, loss = 0.006136\n",
      "epoch : 3000/5000, loss = 0.003577\n",
      "epoch : 4000/5000, loss = 0.002523\n",
      "epoch : 5000/5000, loss = 0.001822\n",
      "self.error_median=0.0015, self.error_range=0.0014\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0018, self.error_std=0.0011\n",
      "Current experiment parameters: ('43_WDBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9871575342465754, 'aucpr': 0.6563690476190476}, fitting time: 89.95982694625854, inference time: 0.0029942989349365234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [05:59,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 29, 'Anomalies Ratio(%)': 2.9}\n",
      "epoch : 1/5000, loss = 1.440837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.008864\n",
      "epoch : 2000/5000, loss = 0.005236\n",
      "epoch : 3000/5000, loss = 0.003552\n",
      "epoch : 4000/5000, loss = 0.002327\n",
      "epoch : 5000/5000, loss = 0.001619\n",
      "self.error_median=0.0014, self.error_range=0.0013\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0016, self.error_std=0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [07:30, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9725085910652921, 'aucpr': 0.6201783680231956}, fitting time: 90.19059777259827, inference time: 0.001996755599975586\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 27, 'Anomalies Ratio(%)': 2.7}\n",
      "epoch : 1/5000, loss = 2.378456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.010172\n",
      "epoch : 2000/5000, loss = 0.004953\n",
      "epoch : 3000/5000, loss = 0.003453\n",
      "epoch : 4000/5000, loss = 0.002554\n",
      "epoch : 5000/5000, loss = 0.002051\n",
      "self.error_median=0.0017, self.error_range=0.0017\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0021, self.error_std=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [09:01, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9871575342465754, 'aucpr': 0.7274801587301587}, fitting time: 90.45451498031616, inference time: 0.0009970664978027344\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 35, 'Anomalies Ratio(%)': 3.5}\n",
      "epoch : 1/5000, loss = 0.916885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000613\n",
      "epoch : 2000/5000, loss = 0.000401\n",
      "epoch : 3000/5000, loss = 0.000367\n",
      "epoch : 4000/5000, loss = 0.000185\n",
      "epoch : 5000/5000, loss = 0.000174\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [10:31,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9875862068965516, 'aucpr': 0.6308458208458209}, fitting time: 89.21174669265747, inference time: 0.0009982585906982422\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 45, 'Anomalies Ratio(%)': 4.5}\n",
      "epoch : 1/5000, loss = 0.620644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000604\n",
      "epoch : 2000/5000, loss = 0.000062\n",
      "epoch : 3000/5000, loss = 0.000051\n",
      "epoch : 4000/5000, loss = 0.000030\n",
      "epoch : 5000/5000, loss = 0.000091\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [12:01, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9635364635364635, 'aucpr': 0.38306285360392484}, fitting time: 90.20657110214233, inference time: 0.0019941329956054688\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 48, 'Anomalies Ratio(%)': 4.8}\n",
      "epoch : 1/5000, loss = 0.273477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000567\n",
      "epoch : 2000/5000, loss = 0.000050\n",
      "epoch : 3000/5000, loss = 0.000032\n",
      "epoch : 4000/5000, loss = 0.000040\n",
      "epoch : 5000/5000, loss = 0.000009\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [13:30, 16.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8866133866133866, 'aucpr': 0.1872424400202875}, fitting time: 87.89777994155884, inference time: 0.000997304916381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 239, 'Anomalies Ratio(%)': 23.9}\n",
      "epoch : 1/5000, loss = 3.156760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.014671\n",
      "epoch : 2000/5000, loss = 0.008427\n",
      "epoch : 3000/5000, loss = 0.005456\n",
      "epoch : 4000/5000, loss = 0.003853\n",
      "epoch : 5000/5000, loss = 0.002912\n",
      "self.error_median=0.0024, self.error_range=0.0028\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0029, self.error_std=0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [14:56,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6510721247563352, 'aucpr': 0.3118045808739535}, fitting time: 85.82625341415405, inference time: 0.001981973648071289\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 224, 'Anomalies Ratio(%)': 22.4}\n",
      "epoch : 1/5000, loss = 3.176381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.020698\n",
      "epoch : 2000/5000, loss = 0.012122\n",
      "epoch : 3000/5000, loss = 0.007732\n",
      "epoch : 4000/5000, loss = 0.005700\n",
      "epoch : 5000/5000, loss = 0.004228\n",
      "self.error_median=0.0033, self.error_range=0.0037\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0042, self.error_std=0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [16:26, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7082826212286208, 'aucpr': 0.3427879104326089}, fitting time: 89.24356842041016, inference time: 0.0009996891021728516\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 225, 'Anomalies Ratio(%)': 22.5}\n",
      "epoch : 1/5000, loss = 2.886413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.015047\n",
      "epoch : 2000/5000, loss = 0.008559\n",
      "epoch : 3000/5000, loss = 0.005777\n",
      "epoch : 4000/5000, loss = 0.004237\n",
      "epoch : 5000/5000, loss = 0.003187\n",
      "self.error_median=0.0027, self.error_range=0.0032\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0033, self.error_std=0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [17:55, 15.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7328220081135903, 'aucpr': 0.3529008331593874}, fitting time: 88.58961653709412, inference time: 0.000997304916381836\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "epoch : 1/5000, loss = 0.853991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.003755\n",
      "epoch : 2000/5000, loss = 0.000962\n",
      "epoch : 3000/5000, loss = 0.000357\n",
      "epoch : 4000/5000, loss = 0.000302\n",
      "epoch : 5000/5000, loss = 0.000312\n",
      "self.error_median=0.0002, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [19:24,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9892790136692576, 'aucpr': 0.7759892068715597}, fitting time: 88.7147810459137, inference time: 0.0010294914245605469\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 38, 'Anomalies Ratio(%)': 3.8}\n",
      "epoch : 1/5000, loss = 0.868339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.003966\n",
      "epoch : 2000/5000, loss = 0.001222\n",
      "epoch : 3000/5000, loss = 0.000808\n",
      "epoch : 4000/5000, loss = 0.000315\n",
      "epoch : 5000/5000, loss = 0.000250\n",
      "self.error_median=0.0001, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [20:53, 11.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9682290028310789, 'aucpr': 0.4127805527805528}, fitting time: 88.51227521896362, inference time: 0.0009984970092773438\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 43, 'Anomalies Ratio(%)': 4.3}\n",
      "epoch : 1/5000, loss = 0.810868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.004192\n",
      "epoch : 2000/5000, loss = 0.000935\n",
      "epoch : 3000/5000, loss = 0.000544\n",
      "epoch : 4000/5000, loss = 0.000391\n",
      "epoch : 5000/5000, loss = 0.000281\n",
      "self.error_median=0.0002, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0005\n",
      "Current experiment parameters: ('21_Lymphography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9922272849102117, 'aucpr': 0.8703614311913905}, fitting time: 88.54866361618042, inference time: 0.0009970664978027344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [22:22, 15.75s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 348, 'Anomalies Ratio(%)': 34.8}\n",
      "epoch : 1/5000, loss = 0.635343\n",
      "epoch : 1000/5000, loss = 0.000559\n",
      "epoch : 2000/5000, loss = 0.000152\n",
      "epoch : 3000/5000, loss = 0.000070\n",
      "epoch : 4000/5000, loss = 0.000115\n",
      "epoch : 5000/5000, loss = 0.000045\n",
      "self.error_median=0.0000, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [23:51,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('4_breastw', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7221350078492936, 'aucpr': 0.4881336571094662}, fitting time: 88.28337979316711, inference time: 0.0009577274322509766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 336, 'Anomalies Ratio(%)': 33.6}\n",
      "epoch : 1/5000, loss = 0.471437\n",
      "epoch : 1000/5000, loss = 0.000606\n",
      "epoch : 2000/5000, loss = 0.000075\n",
      "epoch : 3000/5000, loss = 0.000057\n",
      "epoch : 4000/5000, loss = 0.000036\n",
      "epoch : 5000/5000, loss = 0.000009\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [25:19, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('4_breastw', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6612269267127717, 'aucpr': 0.43881466794966306}, fitting time: 87.91448760032654, inference time: 0.0010263919830322266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 364, 'Anomalies Ratio(%)': 36.4}\n",
      "epoch : 1/5000, loss = 0.627664\n",
      "epoch : 1000/5000, loss = 0.000458\n",
      "epoch : 2000/5000, loss = 0.000371\n",
      "epoch : 3000/5000, loss = 0.000091\n",
      "epoch : 4000/5000, loss = 0.000061\n",
      "epoch : 5000/5000, loss = 0.000037\n",
      "self.error_median=0.0000, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n",
      "Current experiment parameters: ('4_breastw', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8990825688073395, 'aucpr': 0.7029373067660795}, fitting time: 89.05140829086304, inference time: 0.0010263919830322266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [26:49, 15.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 75, 'Anomalies Ratio(%)': 7.5}\n",
      "epoch : 1/5000, loss = 0.943886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001792\n",
      "epoch : 2000/5000, loss = 0.000774\n",
      "epoch : 3000/5000, loss = 0.000386\n",
      "epoch : 4000/5000, loss = 0.000214\n",
      "epoch : 5000/5000, loss = 0.000137\n",
      "self.error_median=0.0001, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145it [28:18,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('45_wine', 0.0, 1), model: Customized, metrics: {'aucroc': 0.940511693611678, 'aucpr': 0.5618880174661962}, fitting time: 88.2914023399353, inference time: 0.0009968280792236328\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 80, 'Anomalies Ratio(%)': 8.0}\n",
      "epoch : 1/5000, loss = 0.962703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002081\n",
      "epoch : 2000/5000, loss = 0.001099\n",
      "epoch : 3000/5000, loss = 0.000394\n",
      "epoch : 4000/5000, loss = 0.000326\n",
      "epoch : 5000/5000, loss = 0.000331\n",
      "self.error_median=0.0002, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146it [29:47, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('45_wine', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9972826086956521, 'aucpr': 0.9747856310356309}, fitting time: 88.61991953849792, inference time: 0.001979827880859375\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 88, 'Anomalies Ratio(%)': 8.8}\n",
      "epoch : 1/5000, loss = 1.042970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001664\n",
      "epoch : 2000/5000, loss = 0.000961\n",
      "epoch : 3000/5000, loss = 0.000271\n",
      "epoch : 4000/5000, loss = 0.000243\n",
      "epoch : 5000/5000, loss = 0.000134\n",
      "self.error_median=0.0001, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "147it [31:16, 15.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('45_wine', 0.0, 3), model: Customized, metrics: {'aucroc': 0.937956204379562, 'aucpr': 0.5891972431996677}, fitting time: 88.67580652236938, inference time: 0.001993894577026367\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 369, 'Anomalies Ratio(%)': 36.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 6.538529\n",
      "epoch : 1000/5000, loss = 0.007836\n",
      "epoch : 2000/5000, loss = 0.006952\n",
      "epoch : 3000/5000, loss = 0.004645\n",
      "epoch : 4000/5000, loss = 0.003483\n",
      "epoch : 5000/5000, loss = 0.002858\n",
      "self.error_median=0.0025, self.error_range=0.0026\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0029, self.error_std=0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [32:45,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('18_Ionosphere', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6408789742123076, 'aucpr': 0.4840508563761342}, fitting time: 88.53928709030151, inference time: 0.001993894577026367\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 374, 'Anomalies Ratio(%)': 37.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 6.795886\n",
      "epoch : 1000/5000, loss = 0.007966\n",
      "epoch : 2000/5000, loss = 0.006297\n",
      "epoch : 3000/5000, loss = 0.005571\n",
      "epoch : 4000/5000, loss = 0.005072\n",
      "epoch : 5000/5000, loss = 0.003892\n",
      "self.error_median=0.0036, self.error_range=0.0039\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0039, self.error_std=0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [34:14, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('18_Ionosphere', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6844129939209727, 'aucpr': 0.5302559382304113}, fitting time: 88.64448618888855, inference time: 0.0019333362579345703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 349, 'Anomalies Ratio(%)': 34.9}\n",
      "epoch : 1/5000, loss = 6.215691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.007292\n",
      "epoch : 2000/5000, loss = 0.004890\n",
      "epoch : 3000/5000, loss = 0.005102\n",
      "epoch : 4000/5000, loss = 0.003257\n",
      "epoch : 5000/5000, loss = 0.002933\n",
      "self.error_median=0.0026, self.error_range=0.0028\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0030, self.error_std=0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171it [35:44, 15.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('18_Ionosphere', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7476923076923078, 'aucpr': 0.5970425464340903}, fitting time: 89.52538228034973, inference time: 0.000997304916381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 367, 'Anomalies Ratio(%)': 36.7}\n",
      "epoch : 1/5000, loss = 1.405129\n",
      "epoch : 1000/5000, loss = 0.001070\n",
      "epoch : 2000/5000, loss = 0.000610\n",
      "epoch : 3000/5000, loss = 0.000153\n",
      "epoch : 4000/5000, loss = 0.000099\n",
      "epoch : 5000/5000, loss = 0.000084\n",
      "self.error_median=0.0000, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "193it [37:13,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('29_Pima', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9019138755980861, 'aucpr': 0.7369446562650678}, fitting time: 88.20666170120239, inference time: 0.0010137557983398438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 346, 'Anomalies Ratio(%)': 34.6}\n",
      "epoch : 1/5000, loss = 1.168295\n",
      "epoch : 1000/5000, loss = 0.000989\n",
      "epoch : 2000/5000, loss = 0.000427\n",
      "epoch : 3000/5000, loss = 0.000250\n",
      "epoch : 4000/5000, loss = 0.000078\n",
      "epoch : 5000/5000, loss = 0.000089\n",
      "self.error_median=0.0000, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "194it [38:41, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('29_Pima', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9078689167974883, 'aucpr': 0.7115155415199279}, fitting time: 88.09215879440308, inference time: 0.0009965896606445312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "epoch : 1/5000, loss = 1.179755\n",
      "epoch : 1000/5000, loss = 0.001258\n",
      "epoch : 2000/5000, loss = 0.000439\n",
      "epoch : 3000/5000, loss = 0.000194\n",
      "epoch : 4000/5000, loss = 0.000055\n",
      "epoch : 5000/5000, loss = 0.000068\n",
      "self.error_median=0.0000, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "195it [40:11, 15.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('29_Pima', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9466973244147158, 'aucpr': 0.7717655257179881}, fitting time: 88.64302897453308, inference time: 0.0010263919830322266\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 123, 'Anomalies Ratio(%)': 12.3}\n",
      "epoch : 1/5000, loss = 0.449905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000062\n",
      "epoch : 2000/5000, loss = 0.000164\n",
      "epoch : 3000/5000, loss = 0.000034\n",
      "epoch : 4000/5000, loss = 0.000014\n",
      "epoch : 5000/5000, loss = 0.000033\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0001\n",
      "Current experiment parameters: ('39_vertebral', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9864351043058267, 'aucpr': 0.7989785681252345}, fitting time: 88.06489086151123, inference time: 0.0010001659393310547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "217it [41:39,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "epoch : 1/5000, loss = 0.389215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000208\n",
      "epoch : 2000/5000, loss = 0.000050\n",
      "epoch : 3000/5000, loss = 0.000064\n",
      "epoch : 4000/5000, loss = 0.000030\n",
      "epoch : 5000/5000, loss = 0.000007\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "218it [43:07, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('39_vertebral', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9832375929936906, 'aucpr': 0.8410821161877117}, fitting time: 87.52745962142944, inference time: 0.0009992122650146484\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 133, 'Anomalies Ratio(%)': 13.3}\n",
      "epoch : 1/5000, loss = 0.514506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000108\n",
      "epoch : 2000/5000, loss = 0.000024\n",
      "epoch : 3000/5000, loss = 0.000035\n",
      "epoch : 4000/5000, loss = 0.000029\n",
      "epoch : 5000/5000, loss = 0.000017\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "219it [44:37, 15.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('39_vertebral', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9698076923076923, 'aucpr': 0.7740175915632269}, fitting time: 88.83559274673462, inference time: 0.0009968280792236328\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 170, 'Anomalies Ratio(%)': 17.0}\n",
      "epoch : 1/5000, loss = 2.240757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.006653\n",
      "epoch : 2000/5000, loss = 0.002359\n",
      "epoch : 3000/5000, loss = 0.001203\n",
      "epoch : 4000/5000, loss = 0.001113\n",
      "epoch : 5000/5000, loss = 0.000530\n",
      "self.error_median=0.0004, self.error_range=0.0006\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0005, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [46:06,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('15_Hepatitis', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7669107803764075, 'aucpr': 0.3058307799447044}, fitting time: 88.55229496955872, inference time: 0.0009970664978027344\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 139, 'Anomalies Ratio(%)': 13.9}\n",
      "epoch : 1/5000, loss = 1.987380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.008555\n",
      "epoch : 2000/5000, loss = 0.003590\n",
      "epoch : 3000/5000, loss = 0.001683\n",
      "epoch : 4000/5000, loss = 0.001189\n",
      "epoch : 5000/5000, loss = 0.000762\n",
      "self.error_median=0.0006, self.error_range=0.0009\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0008, self.error_std=0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "242it [47:34, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('15_Hepatitis', 0.0, 2), model: Customized, metrics: {'aucroc': 0.819859726836471, 'aucpr': 0.32211833741958085}, fitting time: 87.957444190979, inference time: 0.0009975433349609375\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 169, 'Anomalies Ratio(%)': 16.9}\n",
      "epoch : 1/5000, loss = 2.278247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.007004\n",
      "epoch : 2000/5000, loss = 0.003196\n",
      "epoch : 3000/5000, loss = 0.001808\n",
      "epoch : 4000/5000, loss = 0.001104\n",
      "epoch : 5000/5000, loss = 0.000782\n",
      "self.error_median=0.0005, self.error_range=0.0009\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0008, self.error_std=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "243it [49:03, 15.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('15_Hepatitis', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8781793842034805, 'aucpr': 0.45828255918289895}, fitting time: 88.3313045501709, inference time: 0.000995635986328125\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "epoch : 1/5000, loss = 0.336456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000131\n",
      "epoch : 2000/5000, loss = 0.000051\n",
      "epoch : 3000/5000, loss = 0.000048\n",
      "epoch : 4000/5000, loss = 0.000035\n",
      "epoch : 5000/5000, loss = 0.000026\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 7. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n",
      "Current experiment parameters: ('14_glass', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9675690163495041, 'aucpr': 0.4474252850910854}, fitting time: 87.35015821456909, inference time: 0.001986980438232422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "265it [50:31,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "epoch : 1/5000, loss = 0.329418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000116\n",
      "epoch : 2000/5000, loss = 0.000038\n",
      "epoch : 3000/5000, loss = 0.000028\n",
      "epoch : 4000/5000, loss = 0.000021\n",
      "epoch : 5000/5000, loss = 0.000049\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 7. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "266it [51:59, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('14_glass', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9895470383275261, 'aucpr': 0.6798755453881674}, fitting time: 87.8836133480072, inference time: 0.0020172595977783203\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 34, 'Anomalies Ratio(%)': 3.4}\n",
      "epoch : 1/5000, loss = 0.297770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000143\n",
      "epoch : 2000/5000, loss = 0.000068\n",
      "epoch : 3000/5000, loss = 0.000029\n",
      "epoch : 4000/5000, loss = 0.000022\n",
      "epoch : 5000/5000, loss = 0.000020\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 7. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n",
      "Current experiment parameters: ('14_glass', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9482758620689655, 'aucpr': 0.40034577922077924}, fitting time: 88.37812757492065, inference time: 0.0010075569152832031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "267it [53:28, 15.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "epoch : 1/5000, loss = 3.097722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.009491\n",
      "epoch : 2000/5000, loss = 0.002234\n",
      "epoch : 3000/5000, loss = 0.001305\n",
      "epoch : 4000/5000, loss = 0.000521\n",
      "epoch : 5000/5000, loss = 0.000480\n",
      "self.error_median=0.0004, self.error_range=0.0003\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 12. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0005, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "289it [54:58,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('40_vowels', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9955766192733018, 'aucpr': 0.9204592483539851}, fitting time: 89.04219627380371, inference time: 0.0009965896606445312\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "epoch : 1/5000, loss = 3.269758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.007182\n",
      "epoch : 2000/5000, loss = 0.002532\n",
      "epoch : 3000/5000, loss = 0.001328\n",
      "epoch : 4000/5000, loss = 0.000835\n",
      "epoch : 5000/5000, loss = 0.000363\n",
      "self.error_median=0.0002, self.error_range=0.0004\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 12. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0004, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "290it [56:28, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('40_vowels', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9939968404423382, 'aucpr': 0.8867916355202882}, fitting time: 89.24341058731079, inference time: 0.002022981643676758\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "epoch : 1/5000, loss = 3.188561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.006747\n",
      "epoch : 2000/5000, loss = 0.002316\n",
      "epoch : 3000/5000, loss = 0.000728\n",
      "epoch : 4000/5000, loss = 0.000856\n",
      "epoch : 5000/5000, loss = 0.000497\n",
      "self.error_median=0.0004, self.error_range=0.0003\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 12. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0005, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "291it [57:56, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('40_vowels', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9988941548183254, 'aucpr': 0.9662061467943821}, fitting time: 87.54170751571655, inference time: 0.0019943714141845703\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "epoch : 1/5000, loss = 1.145930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000704\n",
      "epoch : 2000/5000, loss = 0.000342\n",
      "epoch : 3000/5000, loss = 0.000167\n",
      "epoch : 4000/5000, loss = 0.000160\n",
      "epoch : 5000/5000, loss = 0.000027\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [59:15,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('47_yeast', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7395050125313284, 'aucpr': 0.5879343053859387}, fitting time: 78.61451005935669, inference time: 0.0009970664978027344\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "epoch : 1/5000, loss = 1.314955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000688\n",
      "epoch : 2000/5000, loss = 0.000241\n",
      "epoch : 3000/5000, loss = 0.000169\n",
      "epoch : 4000/5000, loss = 0.000158\n",
      "epoch : 5000/5000, loss = 0.000074\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "314it [1:00:34, 10.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('47_yeast', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6679869316147511, 'aucpr': 0.4857920388380921}, fitting time: 78.6369309425354, inference time: 0.0019931793212890625\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "epoch : 1/5000, loss = 1.237118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001047\n",
      "epoch : 2000/5000, loss = 0.000200\n",
      "epoch : 3000/5000, loss = 0.000111\n",
      "epoch : 4000/5000, loss = 0.000061\n",
      "epoch : 5000/5000, loss = 0.000109\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "315it [1:01:58, 14.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('47_yeast', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5538623344074471, 'aucpr': 0.44920357353381335}, fitting time: 82.62716746330261, inference time: 0.0009970664978027344\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "epoch : 1/5000, loss = 1.944549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.019629\n",
      "epoch : 2000/5000, loss = 0.011145\n",
      "epoch : 3000/5000, loss = 0.008602\n",
      "epoch : 4000/5000, loss = 0.006888\n",
      "epoch : 5000/5000, loss = 0.005761\n",
      "self.error_median=0.0051, self.error_range=0.0051\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0057, self.error_std=0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "337it [1:03:13,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20_letter', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7758518518518518, 'aucpr': 0.16033564530956493}, fitting time: 74.46124911308289, inference time: 0.0010030269622802734\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "epoch : 1/5000, loss = 1.881343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.022725\n",
      "epoch : 2000/5000, loss = 0.011402\n",
      "epoch : 3000/5000, loss = 0.008274\n",
      "epoch : 4000/5000, loss = 0.007150\n",
      "epoch : 5000/5000, loss = 0.006029\n",
      "self.error_median=0.0055, self.error_range=0.0055\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0060, self.error_std=0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "338it [1:04:28, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20_letter', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7097777777777777, 'aucpr': 0.15179124676303457}, fitting time: 73.35218667984009, inference time: 0.0010268688201904297\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "epoch : 1/5000, loss = 1.931333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.022978\n",
      "epoch : 2000/5000, loss = 0.013062\n",
      "epoch : 3000/5000, loss = 0.008622\n",
      "epoch : 4000/5000, loss = 0.007242\n",
      "epoch : 5000/5000, loss = 0.006493\n",
      "self.error_median=0.0057, self.error_range=0.0051\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0065, self.error_std=0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "339it [1:05:43, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20_letter', 0.0, 3), model: Customized, metrics: {'aucroc': 0.784, 'aucpr': 0.19930094842148505}, fitting time: 74.51219153404236, inference time: 0.000997304916381836\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "epoch : 1/5000, loss = 4.712780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.024114\n",
      "epoch : 2000/5000, loss = 0.012264\n",
      "epoch : 3000/5000, loss = 0.007249\n",
      "epoch : 4000/5000, loss = 0.003828\n",
      "epoch : 5000/5000, loss = 0.003000\n",
      "self.error_median=0.0017, self.error_range=0.0024\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0030, self.error_std=0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361it [1:06:59,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('6_cardio', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7381648380851145, 'aucpr': 0.18784448443356902}, fitting time: 74.13472890853882, inference time: 0.0009982585906982422\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "epoch : 1/5000, loss = 4.237501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.025765\n",
      "epoch : 2000/5000, loss = 0.012727\n",
      "epoch : 3000/5000, loss = 0.009457\n",
      "epoch : 4000/5000, loss = 0.005441\n",
      "epoch : 5000/5000, loss = 0.003502\n",
      "self.error_median=0.0019, self.error_range=0.0035\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0035, self.error_std=0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "362it [1:08:14,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('6_cardio', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6717284841122204, 'aucpr': 0.16586342370748303}, fitting time: 74.08936643600464, inference time: 0.0009791851043701172\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "epoch : 1/5000, loss = 4.565862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.026525\n",
      "epoch : 2000/5000, loss = 0.011594\n",
      "epoch : 3000/5000, loss = 0.006429\n",
      "epoch : 4000/5000, loss = 0.005634\n",
      "epoch : 5000/5000, loss = 0.003822\n",
      "self.error_median=0.0022, self.error_range=0.0043\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0038, self.error_std=0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "363it [1:09:30, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('6_cardio', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6523670323829771, 'aucpr': 0.2520558413068163}, fitting time: 74.22941589355469, inference time: 0.000997781753540039\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "epoch : 1/5000, loss = 5.967103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.026020\n",
      "epoch : 2000/5000, loss = 0.011973\n",
      "epoch : 3000/5000, loss = 0.006555\n",
      "epoch : 4000/5000, loss = 0.004120\n",
      "epoch : 5000/5000, loss = 0.003566\n",
      "self.error_median=0.0028, self.error_range=0.0030\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0036, self.error_std=0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "385it [1:10:45,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('12_fault', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5680595618616979, 'aucpr': 0.39985923856782957}, fitting time: 73.9193274974823, inference time: 0.0019943714141845703\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "epoch : 1/5000, loss = 5.493837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.024624\n",
      "epoch : 2000/5000, loss = 0.012566\n",
      "epoch : 3000/5000, loss = 0.006765\n",
      "epoch : 4000/5000, loss = 0.005001\n",
      "epoch : 5000/5000, loss = 0.003290\n",
      "self.error_median=0.0025, self.error_range=0.0031\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0033, self.error_std=0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "386it [1:12:00,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('12_fault', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6795301577401833, 'aucpr': 0.498557353995731}, fitting time: 74.66137290000916, inference time: 0.0009989738464355469\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "epoch : 1/5000, loss = 6.089565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.027218\n",
      "epoch : 2000/5000, loss = 0.010891\n",
      "epoch : 3000/5000, loss = 0.006427\n",
      "epoch : 4000/5000, loss = 0.005116\n",
      "epoch : 5000/5000, loss = 0.003448\n",
      "self.error_median=0.0026, self.error_range=0.0031\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0035, self.error_std=0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [1:13:15, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('12_fault', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6249447779423611, 'aucpr': 0.4293122497092374}, fitting time: 74.42303228378296, inference time: 0.001993894577026367\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "epoch : 1/5000, loss = 423.097452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 35.181696\n",
      "epoch : 2000/5000, loss = 32.372723\n",
      "epoch : 3000/5000, loss = 30.190415\n",
      "epoch : 4000/5000, loss = 29.453434\n",
      "epoch : 5000/5000, loss = 29.115987\n",
      "self.error_median=28.8998, self.error_range=4.2902\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=29.0399, self.error_std=2.6074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "409it [1:15:37,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('17_InternetAds', 0.0, 1), model: Customized, metrics: {'aucroc': 0.4919128787878787, 'aucpr': 0.18125110994711938}, fitting time: 76.17984342575073, inference time: 0.00299072265625\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "epoch : 1/5000, loss = 427.928325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 35.720756\n",
      "epoch : 2000/5000, loss = 32.166589\n",
      "epoch : 3000/5000, loss = 30.265406\n",
      "epoch : 4000/5000, loss = 29.581276\n",
      "epoch : 5000/5000, loss = 29.371897\n",
      "self.error_median=29.1545, self.error_range=4.4202\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=29.3221, self.error_std=2.6264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [1:17:39, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('17_InternetAds', 0.0, 2), model: Customized, metrics: {'aucroc': 0.4791098484848485, 'aucpr': 0.18478109195214804}, fitting time: 76.96908855438232, inference time: 0.0029931068420410156\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "epoch : 1/5000, loss = 421.865007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 35.211646\n",
      "epoch : 2000/5000, loss = 31.502339\n",
      "epoch : 3000/5000, loss = 29.488683\n",
      "epoch : 4000/5000, loss = 29.072328\n",
      "epoch : 5000/5000, loss = 28.920854\n",
      "self.error_median=28.7469, self.error_range=4.5396\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=28.8807, self.error_std=2.7041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "411it [1:19:55, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('17_InternetAds', 0.0, 3), model: Customized, metrics: {'aucroc': 0.45183712121212116, 'aucpr': 0.17181542494397262}, fitting time: 76.46920418739319, inference time: 0.0029926300048828125\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "epoch : 1/5000, loss = 2.820591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.009456\n",
      "epoch : 2000/5000, loss = 0.003696\n",
      "epoch : 3000/5000, loss = 0.001903\n",
      "epoch : 4000/5000, loss = 0.001291\n",
      "epoch : 5000/5000, loss = 0.000940\n",
      "self.error_median=0.0005, self.error_range=0.0012\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0010, self.error_std=0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "433it [1:21:13,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('7_Cardiotocography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9399134199134199, 'aucpr': 0.6991864903018732}, fitting time: 76.38016295433044, inference time: 0.0009970664978027344\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "epoch : 1/5000, loss = 2.810487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.012387\n",
      "epoch : 2000/5000, loss = 0.005815\n",
      "epoch : 3000/5000, loss = 0.002462\n",
      "epoch : 4000/5000, loss = 0.001875\n",
      "epoch : 5000/5000, loss = 0.001203\n",
      "self.error_median=0.0007, self.error_range=0.0015\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0012, self.error_std=0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "434it [1:22:29, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('7_Cardiotocography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8445310245310246, 'aucpr': 0.5249674681608154}, fitting time: 75.0410852432251, inference time: 0.0009982585906982422\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "epoch : 1/5000, loss = 2.721774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.009456\n",
      "epoch : 2000/5000, loss = 0.003729\n",
      "epoch : 3000/5000, loss = 0.002327\n",
      "epoch : 4000/5000, loss = 0.001583\n",
      "epoch : 5000/5000, loss = 0.000906\n",
      "self.error_median=0.0004, self.error_range=0.0010\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0009, self.error_std=0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "435it [1:23:47, 15.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('7_Cardiotocography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7870851370851372, 'aucpr': 0.4509253668519063}, fitting time: 76.06741428375244, inference time: 0.0009970664978027344\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "epoch : 1/5000, loss = 62.091789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.669365\n",
      "epoch : 2000/5000, loss = 0.449176\n",
      "epoch : 3000/5000, loss = 0.349381\n",
      "epoch : 4000/5000, loss = 0.267543\n",
      "epoch : 5000/5000, loss = 0.229122\n",
      "self.error_median=0.2097, self.error_range=0.1350\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.2287, self.error_std=0.0968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "457it [1:25:04,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('25_musk', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8835335141418055, 'aucpr': 0.35241284332120437}, fitting time: 74.15475463867188, inference time: 0.0009701251983642578\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "epoch : 1/5000, loss = 63.975589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.830099\n",
      "epoch : 2000/5000, loss = 0.512716\n",
      "epoch : 3000/5000, loss = 0.377607\n",
      "epoch : 4000/5000, loss = 0.293019\n",
      "epoch : 5000/5000, loss = 0.243224\n",
      "self.error_median=0.2277, self.error_range=0.1300\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.2424, self.error_std=0.0893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "458it [1:26:27, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('25_musk', 0.0, 2), model: Customized, metrics: {'aucroc': 0.859938008523828, 'aucpr': 0.32933210119667955}, fitting time: 78.9364492893219, inference time: 0.0019943714141845703\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "epoch : 1/5000, loss = 60.153448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.696010\n",
      "epoch : 2000/5000, loss = 0.462229\n",
      "epoch : 3000/5000, loss = 0.339987\n",
      "epoch : 4000/5000, loss = 0.252778\n",
      "epoch : 5000/5000, loss = 0.215775\n",
      "self.error_median=0.1996, self.error_range=0.1247\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.2157, self.error_std=0.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "459it [1:27:44, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('25_musk', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9103060829135994, 'aucpr': 0.4465588147680051}, fitting time: 74.45760655403137, inference time: 0.001995086669921875\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "epoch : 1/5000, loss = 2.423248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.017398\n",
      "epoch : 2000/5000, loss = 0.010724\n",
      "epoch : 3000/5000, loss = 0.009556\n",
      "epoch : 4000/5000, loss = 0.008812\n",
      "epoch : 5000/5000, loss = 0.008527\n",
      "self.error_median=0.0074, self.error_range=0.0081\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0085, self.error_std=0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "481it [1:29:02,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('41_Waveform', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7044200731139914, 'aucpr': 0.06397456757966657}, fitting time: 75.93320918083191, inference time: 0.0009970664978027344\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "epoch : 1/5000, loss = 2.397997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.019029\n",
      "epoch : 2000/5000, loss = 0.010456\n",
      "epoch : 3000/5000, loss = 0.009218\n",
      "epoch : 4000/5000, loss = 0.008927\n",
      "epoch : 5000/5000, loss = 0.008646\n",
      "self.error_median=0.0075, self.error_range=0.0081\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0086, self.error_std=0.0053\n",
      "Current experiment parameters: ('41_Waveform', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6190096377534064, 'aucpr': 0.04114499437134071}, fitting time: 76.38209509849548, inference time: 0.0009942054748535156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "482it [1:30:19, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "epoch : 1/5000, loss = 2.291738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.016695\n",
      "epoch : 2000/5000, loss = 0.010181\n",
      "epoch : 3000/5000, loss = 0.008953\n",
      "epoch : 4000/5000, loss = 0.008062\n",
      "epoch : 5000/5000, loss = 0.008385\n",
      "self.error_median=0.0074, self.error_range=0.0076\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0084, self.error_std=0.0051\n",
      "Current experiment parameters: ('41_Waveform', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6331339315387171, 'aucpr': 0.051974640100356476}, fitting time: 76.40066480636597, inference time: 0.0010280609130859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "483it [1:31:37, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "epoch : 1/5000, loss = 107.054954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 8.004434\n",
      "epoch : 2000/5000, loss = 7.533300\n",
      "epoch : 3000/5000, loss = 7.302349\n",
      "epoch : 4000/5000, loss = 7.162745\n",
      "epoch : 5000/5000, loss = 7.083228\n",
      "self.error_median=7.0512, self.error_range=1.0037\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=7.0787, self.error_std=0.5834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "505it [1:33:04,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('36_speech', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5409517973856209, 'aucpr': 0.04896402941136453}, fitting time: 75.88557314872742, inference time: 0.001994609832763672\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "epoch : 1/5000, loss = 108.912597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 8.038413\n",
      "epoch : 2000/5000, loss = 7.646635\n",
      "epoch : 3000/5000, loss = 7.416004\n",
      "epoch : 4000/5000, loss = 7.277067\n",
      "epoch : 5000/5000, loss = 7.185930\n",
      "self.error_median=7.1408, self.error_range=1.0036\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=7.1854, self.error_std=0.6140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "506it [1:34:31, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('36_speech', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6950061274509803, 'aucpr': 0.05591598554152112}, fitting time: 75.71610951423645, inference time: 0.003018617630004883\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "epoch : 1/5000, loss = 107.742854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 7.889500\n",
      "epoch : 2000/5000, loss = 7.463402\n",
      "epoch : 3000/5000, loss = 7.260347\n",
      "epoch : 4000/5000, loss = 7.138710\n",
      "epoch : 5000/5000, loss = 7.068107\n",
      "self.error_median=7.0301, self.error_range=1.0025\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=7.0651, self.error_std=0.5850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "507it [1:35:59, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('36_speech', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6105494281045751, 'aucpr': 0.027551489389606075}, fitting time: 76.52308917045593, inference time: 0.0019943714141845703\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "epoch : 1/5000, loss = 0.247300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000142\n",
      "epoch : 2000/5000, loss = 0.000057\n",
      "epoch : 3000/5000, loss = 0.000050\n",
      "epoch : 4000/5000, loss = 0.000021\n",
      "epoch : 5000/5000, loss = 0.000006\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "529it [1:37:17,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('38_thyroid', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9601125776397516, 'aucpr': 0.24904638859065073}, fitting time: 76.74594712257385, inference time: 0.0019943714141845703\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "epoch : 1/5000, loss = 0.280741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000096\n",
      "epoch : 2000/5000, loss = 0.000058\n",
      "epoch : 3000/5000, loss = 0.000022\n",
      "epoch : 4000/5000, loss = 0.000010\n",
      "epoch : 5000/5000, loss = 0.000016\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "530it [1:38:35, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('38_thyroid', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9812694099378881, 'aucpr': 0.40840920927332264}, fitting time: 77.16245102882385, inference time: 0.0009968280792236328\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "epoch : 1/5000, loss = 0.188705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000102\n",
      "epoch : 2000/5000, loss = 0.000087\n",
      "epoch : 3000/5000, loss = 0.000032\n",
      "epoch : 4000/5000, loss = 0.000017\n",
      "epoch : 5000/5000, loss = 0.000014\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "531it [1:39:55, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('38_thyroid', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9812047101449276, 'aucpr': 0.4034622239034834}, fitting time: 78.1613495349884, inference time: 0.0009980201721191406\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "epoch : 1/5000, loss = 10.887421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.284254\n",
      "epoch : 2000/5000, loss = 0.219802\n",
      "epoch : 3000/5000, loss = 0.189686\n",
      "epoch : 4000/5000, loss = 0.178780\n",
      "epoch : 5000/5000, loss = 0.172309\n",
      "self.error_median=0.1165, self.error_range=0.1076\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1723, self.error_std=0.1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "553it [1:41:18,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('35_SpamBase', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5405870297174645, 'aucpr': 0.42045316099000096}, fitting time: 74.32569122314453, inference time: 0.0009975433349609375\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "epoch : 1/5000, loss = 11.549117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.293306\n",
      "epoch : 2000/5000, loss = 0.229182\n",
      "epoch : 3000/5000, loss = 0.202839\n",
      "epoch : 4000/5000, loss = 0.187127\n",
      "epoch : 5000/5000, loss = 0.176849\n",
      "self.error_median=0.1175, self.error_range=0.1277\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1767, self.error_std=0.1673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "554it [1:42:39, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('35_SpamBase', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5101689775602819, 'aucpr': 0.3898045448537749}, fitting time: 74.22884058952332, inference time: 0.00096893310546875\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "epoch : 1/5000, loss = 11.381914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.316009\n",
      "epoch : 2000/5000, loss = 0.239129\n",
      "epoch : 3000/5000, loss = 0.206265\n",
      "epoch : 4000/5000, loss = 0.189107\n",
      "epoch : 5000/5000, loss = 0.177867\n",
      "self.error_median=0.1212, self.error_range=0.1037\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1777, self.error_std=0.1646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "555it [1:44:00, 14.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('35_SpamBase', 0.0, 3), model: Customized, metrics: {'aucroc': 0.4848314929836669, 'aucpr': 0.38391777308645836}, fitting time: 74.14678692817688, inference time: 0.0009677410125732422\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "epoch : 1/5000, loss = 0.174373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000040\n",
      "epoch : 2000/5000, loss = 0.000036\n",
      "epoch : 3000/5000, loss = 0.000009\n",
      "epoch : 4000/5000, loss = 0.000037\n",
      "epoch : 5000/5000, loss = 0.000004\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 5. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n",
      "Current experiment parameters: ('44_Wilt', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9687704552569418, 'aucpr': 0.47346928014054135}, fitting time: 76.52658247947693, inference time: 0.000995635986328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "577it [1:45:18,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "epoch : 1/5000, loss = 0.157127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000059\n",
      "epoch : 2000/5000, loss = 0.000030\n",
      "epoch : 3000/5000, loss = 0.000012\n",
      "epoch : 4000/5000, loss = 0.000006\n",
      "epoch : 5000/5000, loss = 0.000003\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 5. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "578it [1:46:36, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('44_Wilt', 0.0, 2), model: Customized, metrics: {'aucroc': 0.978408735165492, 'aucpr': 0.5289895249753633}, fitting time: 76.5564477443695, inference time: 0.0009989738464355469\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "epoch : 1/5000, loss = 0.157428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000018\n",
      "epoch : 2000/5000, loss = 0.000036\n",
      "epoch : 3000/5000, loss = 0.000025\n",
      "epoch : 4000/5000, loss = 0.000025\n",
      "epoch : 5000/5000, loss = 0.000009\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 5. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "579it [1:47:54, 13.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('44_Wilt', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9935302097464259, 'aucpr': 0.7869837392860016}, fitting time: 75.79045963287354, inference time: 0.0009984970092773438\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "epoch : 1/5000, loss = 7.233610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.165101\n",
      "epoch : 2000/5000, loss = 0.109941\n",
      "epoch : 3000/5000, loss = 0.092047\n",
      "epoch : 4000/5000, loss = 0.085772\n",
      "epoch : 5000/5000, loss = 0.080098\n",
      "self.error_median=0.0676, self.error_range=0.0470\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0800, self.error_std=0.0545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [1:49:23,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('26_optdigits', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7910672514619882, 'aucpr': 0.10726947869792512}, fitting time: 75.4937436580658, inference time: 0.0009691715240478516\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "epoch : 1/5000, loss = 6.794080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.189268\n",
      "epoch : 2000/5000, loss = 0.125348\n",
      "epoch : 3000/5000, loss = 0.099932\n",
      "epoch : 4000/5000, loss = 0.090390\n",
      "epoch : 5000/5000, loss = 0.084325\n",
      "self.error_median=0.0698, self.error_range=0.0513\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0843, self.error_std=0.0565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "602it [1:50:50, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('26_optdigits', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7204385964912281, 'aucpr': 0.07431245769177457}, fitting time: 75.13194537162781, inference time: 0.0009686946868896484\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "epoch : 1/5000, loss = 7.193518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.215374\n",
      "epoch : 2000/5000, loss = 0.139760\n",
      "epoch : 3000/5000, loss = 0.110664\n",
      "epoch : 4000/5000, loss = 0.098530\n",
      "epoch : 5000/5000, loss = 0.089556\n",
      "self.error_median=0.0757, self.error_range=0.0546\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0895, self.error_std=0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "603it [1:52:15, 14.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('26_optdigits', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6457017543859649, 'aucpr': 0.04597188742425287}, fitting time: 74.50945115089417, inference time: 0.0009913444519042969\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "epoch : 1/5000, loss = 0.456543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000235\n",
      "epoch : 2000/5000, loss = 0.000212\n",
      "epoch : 3000/5000, loss = 0.000069\n",
      "epoch : 4000/5000, loss = 0.000136\n",
      "epoch : 5000/5000, loss = 0.000039\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0001\n",
      "Current experiment parameters: ('27_PageBlocks', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8935198197595308, 'aucpr': 0.3316404312128965}, fitting time: 75.21735858917236, inference time: 0.0010271072387695312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [1:53:34,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "epoch : 1/5000, loss = 0.591040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000632\n",
      "epoch : 2000/5000, loss = 0.000153\n",
      "epoch : 3000/5000, loss = 0.000154\n",
      "epoch : 4000/5000, loss = 0.000137\n",
      "epoch : 5000/5000, loss = 0.000045\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "626it [1:54:55, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('27_PageBlocks', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8571817350375872, 'aucpr': 0.2726179771869004}, fitting time: 78.45741891860962, inference time: 0.0010020732879638672\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "epoch : 1/5000, loss = 0.995221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001331\n",
      "epoch : 2000/5000, loss = 0.000417\n",
      "epoch : 3000/5000, loss = 0.000201\n",
      "epoch : 4000/5000, loss = 0.000124\n",
      "epoch : 5000/5000, loss = 0.000105\n",
      "self.error_median=0.0000, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "627it [1:56:17, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('27_PageBlocks', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8768118851636219, 'aucpr': 0.2759720304596404}, fitting time: 78.86702942848206, inference time: 0.000997304916381836\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "epoch : 1/5000, loss = 0.854180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.003465\n",
      "epoch : 2000/5000, loss = 0.001835\n",
      "epoch : 3000/5000, loss = 0.001407\n",
      "epoch : 4000/5000, loss = 0.001204\n",
      "epoch : 5000/5000, loss = 0.001054\n",
      "self.error_median=0.0009, self.error_range=0.0006\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0010, self.error_std=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "649it [1:57:40,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('31_satimage-2', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9964008859357696, 'aucpr': 0.6048086361370772}, fitting time: 77.7360360622406, inference time: 0.0009908676147460938\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "epoch : 1/5000, loss = 0.889923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.003159\n",
      "epoch : 2000/5000, loss = 0.002094\n",
      "epoch : 3000/5000, loss = 0.001481\n",
      "epoch : 4000/5000, loss = 0.001211\n",
      "epoch : 5000/5000, loss = 0.001079\n",
      "self.error_median=0.0009, self.error_range=0.0007\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0011, self.error_std=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "650it [1:59:03, 10.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('31_satimage-2', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9962901439645625, 'aucpr': 0.5908475152697121}, fitting time: 77.28561878204346, inference time: 0.0009677410125732422\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "epoch : 1/5000, loss = 0.825334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002509\n",
      "epoch : 2000/5000, loss = 0.001792\n",
      "epoch : 3000/5000, loss = 0.001297\n",
      "epoch : 4000/5000, loss = 0.001119\n",
      "epoch : 5000/5000, loss = 0.000910\n",
      "self.error_median=0.0007, self.error_range=0.0005\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0009, self.error_std=0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "651it [2:00:26, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('31_satimage-2', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9622646733111849, 'aucpr': 0.26871954379385943}, fitting time: 77.41850709915161, inference time: 0.0009927749633789062\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "epoch : 1/5000, loss = 8.279234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.005381\n",
      "epoch : 2000/5000, loss = 0.004035\n",
      "epoch : 3000/5000, loss = 0.002966\n",
      "epoch : 4000/5000, loss = 0.002422\n",
      "epoch : 5000/5000, loss = 0.002045\n",
      "self.error_median=0.0014, self.error_range=0.0022\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0021, self.error_std=0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "673it [2:01:50,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('30_satellite', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9335391558795815, 'aucpr': 0.7855054422651331}, fitting time: 78.01940965652466, inference time: 0.0019822120666503906\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "epoch : 1/5000, loss = 8.474543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.007528\n",
      "epoch : 2000/5000, loss = 0.004608\n",
      "epoch : 3000/5000, loss = 0.004802\n",
      "epoch : 4000/5000, loss = 0.002584\n",
      "epoch : 5000/5000, loss = 0.002093\n",
      "self.error_median=0.0017, self.error_range=0.0017\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0021, self.error_std=0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "674it [2:03:14, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('30_satellite', 0.0, 2), model: Customized, metrics: {'aucroc': 0.866498040966126, 'aucpr': 0.6018109325503789}, fitting time: 78.4057879447937, inference time: 0.0009975433349609375\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "epoch : 1/5000, loss = 8.055686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.005620\n",
      "epoch : 2000/5000, loss = 0.003303\n",
      "epoch : 3000/5000, loss = 0.003524\n",
      "epoch : 4000/5000, loss = 0.002544\n",
      "epoch : 5000/5000, loss = 0.001626\n",
      "self.error_median=0.0013, self.error_range=0.0011\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0016, self.error_std=0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "675it [2:04:37, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('30_satellite', 0.0, 3), model: Customized, metrics: {'aucroc': 0.827215692109309, 'aucpr': 0.5610220231442614}, fitting time: 78.24432516098022, inference time: 0.0019731521606445312\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "epoch : 1/5000, loss = 11.774678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.016046\n",
      "epoch : 2000/5000, loss = 0.011246\n",
      "epoch : 3000/5000, loss = 0.008262\n",
      "epoch : 4000/5000, loss = 0.006381\n",
      "epoch : 5000/5000, loss = 0.004976\n",
      "self.error_median=0.0038, self.error_range=0.0030\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0049, self.error_std=0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "697it [2:06:03,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('19_landsat', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5697844546048334, 'aucpr': 0.25501957278359744}, fitting time: 78.37916779518127, inference time: 0.0019943714141845703\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "epoch : 1/5000, loss = 11.473187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.017548\n",
      "epoch : 2000/5000, loss = 0.011650\n",
      "epoch : 3000/5000, loss = 0.010889\n",
      "epoch : 4000/5000, loss = 0.006325\n",
      "epoch : 5000/5000, loss = 0.005433\n",
      "self.error_median=0.0042, self.error_range=0.0033\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0054, self.error_std=0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "698it [2:07:27, 10.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('19_landsat', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5768745917700849, 'aucpr': 0.2401721576584604}, fitting time: 78.44413232803345, inference time: 0.0009975433349609375\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "epoch : 1/5000, loss = 11.544601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.015466\n",
      "epoch : 2000/5000, loss = 0.012198\n",
      "epoch : 3000/5000, loss = 0.008552\n",
      "epoch : 4000/5000, loss = 0.005566\n",
      "epoch : 5000/5000, loss = 0.005410\n",
      "self.error_median=0.0043, self.error_range=0.0031\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0054, self.error_std=0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "699it [2:08:51, 14.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('19_landsat', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6009993468321359, 'aucpr': 0.2619314558621279}, fitting time: 79.10455369949341, inference time: 0.0019638538360595703\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "epoch : 1/5000, loss = 0.808153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001903\n",
      "epoch : 2000/5000, loss = 0.001023\n",
      "epoch : 3000/5000, loss = 0.000605\n",
      "epoch : 4000/5000, loss = 0.000282\n",
      "epoch : 5000/5000, loss = 0.000134\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "721it [2:10:13,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('28_pendigits', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9204821568171733, 'aucpr': 0.14368678593204673}, fitting time: 79.14376378059387, inference time: 0.0009984970092773438\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "epoch : 1/5000, loss = 0.803105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.003181\n",
      "epoch : 2000/5000, loss = 0.001401\n",
      "epoch : 3000/5000, loss = 0.000744\n",
      "epoch : 4000/5000, loss = 0.000622\n",
      "epoch : 5000/5000, loss = 0.000494\n",
      "self.error_median=0.0003, self.error_range=0.0005\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0005, self.error_std=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "722it [2:11:37, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('28_pendigits', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9243170149379873, 'aucpr': 0.15297074573186498}, fitting time: 79.79286909103394, inference time: 0.001965761184692383\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "epoch : 1/5000, loss = 0.805507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002457\n",
      "epoch : 2000/5000, loss = 0.000890\n",
      "epoch : 3000/5000, loss = 0.000648\n",
      "epoch : 4000/5000, loss = 0.000391\n",
      "epoch : 5000/5000, loss = 0.000141\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "723it [2:12:59, 14.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('28_pendigits', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9814701345897864, 'aucpr': 0.44415523417810965}, fitting time: 80.00353789329529, inference time: 0.001994609832763672\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "epoch : 1/5000, loss = 0.307906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000320\n",
      "epoch : 2000/5000, loss = 0.000074\n",
      "epoch : 3000/5000, loss = 0.000062\n",
      "epoch : 4000/5000, loss = 0.000025\n",
      "epoch : 5000/5000, loss = 0.000013\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "745it [2:14:24,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('2_annthyroid', 0.0, 1), model: Customized, metrics: {'aucroc': 0.978746875, 'aucpr': 0.6044553116090345}, fitting time: 81.70388841629028, inference time: 0.0019948482513427734\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "epoch : 1/5000, loss = 0.330969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000170\n",
      "epoch : 2000/5000, loss = 0.000062\n",
      "epoch : 3000/5000, loss = 0.000037\n",
      "epoch : 4000/5000, loss = 0.000037\n",
      "epoch : 5000/5000, loss = 0.000019\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "746it [2:15:46, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('2_annthyroid', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9789593750000001, 'aucpr': 0.600675157196768}, fitting time: 80.5210428237915, inference time: 0.0019898414611816406\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "epoch : 1/5000, loss = 0.340371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000167\n",
      "epoch : 2000/5000, loss = 0.000049\n",
      "epoch : 3000/5000, loss = 0.000030\n",
      "epoch : 4000/5000, loss = 0.000024\n",
      "epoch : 5000/5000, loss = 0.000038\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "747it [2:17:09, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('2_annthyroid', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9942906250000001, 'aucpr': 0.8600683437380678}, fitting time: 80.82803320884705, inference time: 0.001994609832763672\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "epoch : 1/5000, loss = 30.768191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.559139\n",
      "epoch : 2000/5000, loss = 0.437463\n",
      "epoch : 3000/5000, loss = 0.378897\n",
      "epoch : 4000/5000, loss = 0.346624\n",
      "epoch : 5000/5000, loss = 0.330905\n",
      "self.error_median=0.3094, self.error_range=0.1638\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.3306, self.error_std=0.1178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "769it [2:18:58,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('24_mnist', 0.0, 1), model: Customized, metrics: {'aucroc': 0.658149962061116, 'aucpr': 0.16991703527240487}, fitting time: 83.285897731781, inference time: 0.0029926300048828125\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "epoch : 1/5000, loss = 30.475782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.586924\n",
      "epoch : 2000/5000, loss = 0.447107\n",
      "epoch : 3000/5000, loss = 0.381243\n",
      "epoch : 4000/5000, loss = 0.344306\n",
      "epoch : 5000/5000, loss = 0.325065\n",
      "self.error_median=0.3057, self.error_range=0.1736\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.3250, self.error_std=0.1163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "770it [2:20:48, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('24_mnist', 0.0, 2), model: Customized, metrics: {'aucroc': 0.689174771791865, 'aucpr': 0.18088361387922816}, fitting time: 82.14995121955872, inference time: 0.0019948482513427734\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "epoch : 1/5000, loss = 29.286780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.551850\n",
      "epoch : 2000/5000, loss = 0.424278\n",
      "epoch : 3000/5000, loss = 0.365612\n",
      "epoch : 4000/5000, loss = 0.330377\n",
      "epoch : 5000/5000, loss = 0.307881\n",
      "self.error_median=0.2864, self.error_range=0.1689\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.3080, self.error_std=0.1206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "771it [2:22:35, 17.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('24_mnist', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6114115564139707, 'aucpr': 0.14383538833871812}, fitting time: 82.59159779548645, inference time: 0.0019948482513427734\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1134, 'Anomalies Ratio(%)': 11.34}\n",
      "epoch : 1/5000, loss = 10.496184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.334654\n",
      "epoch : 2000/5000, loss = 0.268032\n",
      "epoch : 3000/5000, loss = 0.241489\n",
      "epoch : 4000/5000, loss = 0.226614\n",
      "epoch : 5000/5000, loss = 0.219711\n",
      "self.error_median=0.2005, self.error_range=0.1673\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.2197, self.error_std=0.1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "793it [2:24:11,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('5_campaign', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5813555948695268, 'aucpr': 0.1447906454749602}, fitting time: 90.00950765609741, inference time: 0.001966238021850586\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "epoch : 1/5000, loss = 10.113009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.342111\n",
      "epoch : 2000/5000, loss = 0.252793\n",
      "epoch : 3000/5000, loss = 0.221540\n",
      "epoch : 4000/5000, loss = 0.205495\n",
      "epoch : 5000/5000, loss = 0.197580\n",
      "self.error_median=0.1772, self.error_range=0.1234\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.1976, self.error_std=0.0926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "794it [2:25:48, 12.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('5_campaign', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5956229997594445, 'aucpr': 0.206170203547561}, fitting time: 89.78132104873657, inference time: 0.0019600391387939453\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "epoch : 1/5000, loss = 10.852773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.357995\n",
      "epoch : 2000/5000, loss = 0.276672\n",
      "epoch : 3000/5000, loss = 0.251051\n",
      "epoch : 4000/5000, loss = 0.232812\n",
      "epoch : 5000/5000, loss = 0.221179\n",
      "self.error_median=0.1997, self.error_range=0.1524\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.2211, self.error_std=0.0991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "795it [2:27:23, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('5_campaign', 0.0, 3), model: Customized, metrics: {'aucroc': 0.561101633005535, 'aucpr': 0.1322559798002828}, fitting time: 89.64921379089355, inference time: 0.001995563507080078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\mixture\\_base.py:268: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 97, 'Anomalies Ratio(%)': 0.97}\n",
      "epoch : 1/5000, loss = 0.420649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000294\n",
      "epoch : 2000/5000, loss = 0.000289\n",
      "epoch : 3000/5000, loss = 0.000130\n",
      "epoch : 4000/5000, loss = 0.000057\n",
      "epoch : 5000/5000, loss = 0.000022\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "817it [2:28:58,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('10_cover', 0.0, 1), model: Customized, metrics: {'aucroc': 0.992653118072401, 'aucpr': 0.3989042624679733}, fitting time: 88.8624804019928, inference time: 0.0019943714141845703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\mixture\\_base.py:268: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\mixture\\_base.py:268: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 116, 'Anomalies Ratio(%)': 1.16}\n",
      "epoch : 1/5000, loss = 0.458446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000826\n",
      "epoch : 2000/5000, loss = 0.000211\n",
      "epoch : 3000/5000, loss = 0.000161\n",
      "epoch : 4000/5000, loss = 0.000033\n",
      "epoch : 5000/5000, loss = 0.000093\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "818it [2:30:33, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('10_cover', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9991134666345458, 'aucpr': 0.8383062631108944}, fitting time: 89.21078515052795, inference time: 0.0019998550415039062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\mixture\\_base.py:268: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\mixture\\_base.py:268: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 95, 'Anomalies Ratio(%)': 0.95}\n",
      "epoch : 1/5000, loss = 0.370132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000304\n",
      "epoch : 2000/5000, loss = 0.000198\n",
      "epoch : 3000/5000, loss = 0.000058\n",
      "epoch : 4000/5000, loss = 0.000040\n",
      "epoch : 5000/5000, loss = 0.000036\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "819it [2:32:07, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('10_cover', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9975245145164391, 'aucpr': 0.649071263449561}, fitting time: 89.12183284759521, inference time: 0.0019948482513427734\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "epoch : 1/5000, loss = 0.332864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000051\n",
      "epoch : 2000/5000, loss = 0.000023\n",
      "epoch : 3000/5000, loss = 0.000049\n",
      "epoch : 4000/5000, loss = 0.000011\n",
      "epoch : 5000/5000, loss = 0.000010\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "841it [2:33:37,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('34_smtp', 0.0, 1), model: Customized, metrics: {'aucroc': 1.0, 'aucpr': 1.0}, fitting time: 88.37515497207642, inference time: 0.001995086669921875\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "epoch : 1/5000, loss = 0.090229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000007\n",
      "epoch : 2000/5000, loss = 0.000007\n",
      "epoch : 3000/5000, loss = 0.000004\n",
      "epoch : 4000/5000, loss = 0.000001\n",
      "epoch : 5000/5000, loss = 0.000001\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "842it [2:35:07, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('34_smtp', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9956652217405801, 'aucpr': 0.07142857142857142}, fitting time: 88.18548154830933, inference time: 0.0020301342010498047\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 5, 'Anomalies Ratio(%)': 0.05}\n",
      "epoch : 1/5000, loss = 0.322731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000065\n",
      "epoch : 2000/5000, loss = 0.000056\n",
      "epoch : 3000/5000, loss = 0.000060\n",
      "epoch : 4000/5000, loss = 0.000021\n",
      "epoch : 5000/5000, loss = 0.000013\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "843it [2:36:37, 16.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('34_smtp', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5, 'aucpr': 0.5003333333333333}, fitting time: 88.2434344291687, inference time: 0.0020303726196289062\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2081, 'Anomalies Ratio(%)': 20.81}\n",
      "epoch : 1/5000, loss = 0.842605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000030\n",
      "epoch : 2000/5000, loss = 0.000021\n",
      "epoch : 3000/5000, loss = 0.000021\n",
      "epoch : 4000/5000, loss = 0.000014\n",
      "epoch : 5000/5000, loss = 0.000003\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "865it [2:38:08,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('33_skin', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6243019133644133, 'aucpr': 0.4119346243173766}, fitting time: 88.9890992641449, inference time: 0.001995086669921875\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2082, 'Anomalies Ratio(%)': 20.82}\n",
      "epoch : 1/5000, loss = 0.754216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000015\n",
      "epoch : 2000/5000, loss = 0.000024\n",
      "epoch : 3000/5000, loss = 0.000043\n",
      "epoch : 4000/5000, loss = 0.000023\n",
      "epoch : 5000/5000, loss = 0.000016\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n",
      "Current experiment parameters: ('33_skin', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5761468631578947, 'aucpr': 0.4605543820832797}, fitting time: 88.73360347747803, inference time: 0.0009975433349609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "866it [2:39:38, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2066, 'Anomalies Ratio(%)': 20.66}\n",
      "epoch : 1/5000, loss = 0.864233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000080\n",
      "epoch : 2000/5000, loss = 0.000042\n",
      "epoch : 3000/5000, loss = 0.000011\n",
      "epoch : 4000/5000, loss = 0.000033\n",
      "epoch : 5000/5000, loss = 0.000027\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "867it [2:41:09, 15.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('33_skin', 0.0, 3), model: Customized, metrics: {'aucroc': 0.642804960693955, 'aucpr': 0.5681350028094573}, fitting time: 89.47079157829285, inference time: 0.0019948482513427734\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 669, 'Anomalies Ratio(%)': 6.69}\n",
      "epoch : 1/5000, loss = 1.400124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000726\n",
      "epoch : 2000/5000, loss = 0.000263\n",
      "epoch : 3000/5000, loss = 0.000203\n",
      "epoch : 4000/5000, loss = 0.000044\n",
      "epoch : 5000/5000, loss = 0.000080\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "889it [2:42:39,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('32_shuttle', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9892587793437244, 'aucpr': 0.7551735971005092}, fitting time: 88.83836698532104, inference time: 0.0019948482513427734\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 697, 'Anomalies Ratio(%)': 6.97}\n",
      "epoch : 1/5000, loss = 1.401406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000800\n",
      "epoch : 2000/5000, loss = 0.000202\n",
      "epoch : 3000/5000, loss = 0.000120\n",
      "epoch : 4000/5000, loss = 0.000093\n",
      "epoch : 5000/5000, loss = 0.000047\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "890it [2:44:09, 11.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('32_shuttle', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9759051222401465, 'aucpr': 0.5492001311539279}, fitting time: 88.88174867630005, inference time: 0.000997781753540039\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 714, 'Anomalies Ratio(%)': 7.14}\n",
      "epoch : 1/5000, loss = 1.609059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000864\n",
      "epoch : 2000/5000, loss = 0.000284\n",
      "epoch : 3000/5000, loss = 0.000253\n",
      "epoch : 4000/5000, loss = 0.000089\n",
      "epoch : 5000/5000, loss = 0.000051\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "891it [2:45:41, 15.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('32_shuttle', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9239102723228961, 'aucpr': 0.3560277507171701}, fitting time: 89.1513683795929, inference time: 0.0019943714141845703\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 222, 'Anomalies Ratio(%)': 2.22}\n",
      "epoch : 1/5000, loss = 3.788649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.069939\n",
      "epoch : 2000/5000, loss = 0.049543\n",
      "epoch : 3000/5000, loss = 0.041554\n",
      "epoch : 4000/5000, loss = 0.038145\n",
      "epoch : 5000/5000, loss = 0.035378\n",
      "self.error_median=0.0309, self.error_range=0.0285\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0353, self.error_std=0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "913it [2:47:17,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('8_celeba', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6576069533003241, 'aucpr': 0.09379622119567099}, fitting time: 88.9611451625824, inference time: 0.0020186901092529297\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 238, 'Anomalies Ratio(%)': 2.38}\n",
      "epoch : 1/5000, loss = 3.783396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.065753\n",
      "epoch : 2000/5000, loss = 0.051972\n",
      "epoch : 3000/5000, loss = 0.041976\n",
      "epoch : 4000/5000, loss = 0.039075\n",
      "epoch : 5000/5000, loss = 0.036919\n",
      "self.error_median=0.0327, self.error_range=0.0288\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0369, self.error_std=0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "914it [2:48:53, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('8_celeba', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6401886910400607, 'aucpr': 0.12150591993990831}, fitting time: 89.50620889663696, inference time: 0.001965045928955078\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 216, 'Anomalies Ratio(%)': 2.16}\n",
      "epoch : 1/5000, loss = 3.816603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.065036\n",
      "epoch : 2000/5000, loss = 0.048597\n",
      "epoch : 3000/5000, loss = 0.044841\n",
      "epoch : 4000/5000, loss = 0.041409\n",
      "epoch : 5000/5000, loss = 0.039679\n",
      "self.error_median=0.0355, self.error_range=0.0314\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0397, self.error_std=0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "915it [2:50:27, 16.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('8_celeba', 0.0, 3), model: Customized, metrics: {'aucroc': 0.67032892150439, 'aucpr': 0.11743868342623628}, fitting time: 88.65352439880371, inference time: 0.001995086669921875\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 230, 'Anomalies Ratio(%)': 2.3}\n",
      "epoch : 1/5000, loss = 0.610439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000676\n",
      "epoch : 2000/5000, loss = 0.000137\n",
      "epoch : 3000/5000, loss = 0.000041\n",
      "epoch : 4000/5000, loss = 0.000085\n",
      "epoch : 5000/5000, loss = 0.000043\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n",
      "Current experiment parameters: ('23_mammography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5279496041811915, 'aucpr': 0.26272898328861816}, fitting time: 88.44227313995361, inference time: 0.002026081085205078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "937it [2:51:57,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 241, 'Anomalies Ratio(%)': 2.41}\n",
      "epoch : 1/5000, loss = 0.679324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000115\n",
      "epoch : 2000/5000, loss = 0.000093\n",
      "epoch : 3000/5000, loss = 0.000080\n",
      "epoch : 4000/5000, loss = 0.000030\n",
      "epoch : 5000/5000, loss = 0.000053\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [2:53:28, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('23_mammography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5719157938676381, 'aucpr': 0.3137269512333065}, fitting time: 88.92843961715698, inference time: 0.0019960403442382812\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 227, 'Anomalies Ratio(%)': 2.27}\n",
      "epoch : 1/5000, loss = 0.512885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000307\n",
      "epoch : 2000/5000, loss = 0.000080\n",
      "epoch : 3000/5000, loss = 0.000063\n",
      "epoch : 4000/5000, loss = 0.000025\n",
      "epoch : 5000/5000, loss = 0.000023\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "939it [2:55:00, 16.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('23_mammography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.587252226948078, 'aucpr': 0.14775633009620504}, fitting time: 89.17141675949097, inference time: 0.0019953250885009766\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3548, 'Anomalies Ratio(%)': 35.48}\n",
      "epoch : 1/5000, loss = 2.040452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002153\n",
      "epoch : 2000/5000, loss = 0.000917\n",
      "epoch : 3000/5000, loss = 0.000620\n",
      "epoch : 4000/5000, loss = 0.000223\n",
      "epoch : 5000/5000, loss = 0.000188\n",
      "self.error_median=0.0001, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "961it [2:56:31,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('22_magic.gamma', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6564572912135711, 'aucpr': 0.49307498134926286}, fitting time: 89.637277841568, inference time: 0.0020253658294677734\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3533, 'Anomalies Ratio(%)': 35.33}\n",
      "epoch : 1/5000, loss = 1.905137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.003117\n",
      "epoch : 2000/5000, loss = 0.000589\n",
      "epoch : 3000/5000, loss = 0.000794\n",
      "epoch : 4000/5000, loss = 0.000501\n",
      "epoch : 5000/5000, loss = 0.000261\n",
      "self.error_median=0.0002, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "962it [2:58:02, 11.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('22_magic.gamma', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6168191985994943, 'aucpr': 0.4384450460369109}, fitting time: 89.21510124206543, inference time: 0.000995635986328125\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3500, 'Anomalies Ratio(%)': 35.0}\n",
      "epoch : 1/5000, loss = 1.999095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002851\n",
      "epoch : 2000/5000, loss = 0.000992\n",
      "epoch : 3000/5000, loss = 0.000565\n",
      "epoch : 4000/5000, loss = 0.000538\n",
      "epoch : 5000/5000, loss = 0.000514\n",
      "self.error_median=0.0004, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0005, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "963it [2:59:34, 16.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('22_magic.gamma', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5810857142857143, 'aucpr': 0.5219535205850061}, fitting time: 89.83441424369812, inference time: 0.001994609832763672\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 315, 'Anomalies Ratio(%)': 3.15}\n",
      "epoch : 1/5000, loss = 3.816659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.030620\n",
      "epoch : 2000/5000, loss = 0.018251\n",
      "epoch : 3000/5000, loss = 0.012621\n",
      "epoch : 4000/5000, loss = 0.010064\n",
      "epoch : 5000/5000, loss = 0.008124\n",
      "self.error_median=0.0028, self.error_range=0.0069\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0081, self.error_std=0.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "985it [3:01:14,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('1_ALOI', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7395410815480811, 'aucpr': 0.059288802784120624}, fitting time: 88.98370409011841, inference time: 0.0019719600677490234\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 334, 'Anomalies Ratio(%)': 3.34}\n",
      "epoch : 1/5000, loss = 3.710972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.031664\n",
      "epoch : 2000/5000, loss = 0.022730\n",
      "epoch : 3000/5000, loss = 0.014407\n",
      "epoch : 4000/5000, loss = 0.012298\n",
      "epoch : 5000/5000, loss = 0.010942\n",
      "self.error_median=0.0043, self.error_range=0.0100\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0109, self.error_std=0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "986it [3:02:56, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('1_ALOI', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8093620689655172, 'aucpr': 0.0942599167241822}, fitting time: 88.97971153259277, inference time: 0.001993894577026367\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 332, 'Anomalies Ratio(%)': 3.32}\n",
      "epoch : 1/5000, loss = 3.439165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.033586\n",
      "epoch : 2000/5000, loss = 0.017254\n",
      "epoch : 3000/5000, loss = 0.014320\n",
      "epoch : 4000/5000, loss = 0.011912\n",
      "epoch : 5000/5000, loss = 0.010777\n",
      "self.error_median=0.0043, self.error_range=0.0100\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0108, self.error_std=0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "987it [3:04:38, 17.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('1_ALOI', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7546482758620691, 'aucpr': 0.08334252014074887}, fitting time: 89.11230635643005, inference time: 0.0019609928131103516\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 46, 'Anomalies Ratio(%)': 0.46}\n",
      "epoch : 1/5000, loss = 0.278743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000041\n",
      "epoch : 2000/5000, loss = 0.000030\n",
      "epoch : 3000/5000, loss = 0.000006\n",
      "epoch : 4000/5000, loss = 0.000012\n",
      "epoch : 5000/5000, loss = 0.000003\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1009it [3:06:08,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('16_http', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9876566835709502, 'aucpr': 0.18370567582413752}, fitting time: 88.46424317359924, inference time: 0.001985311508178711\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 35, 'Anomalies Ratio(%)': 0.35}\n",
      "epoch : 1/5000, loss = 0.326318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000025\n",
      "epoch : 2000/5000, loss = 0.000049\n",
      "epoch : 3000/5000, loss = 0.000007\n",
      "epoch : 4000/5000, loss = 0.000012\n",
      "epoch : 5000/5000, loss = 0.000003\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [3:07:37, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('16_http', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9954849498327759, 'aucpr': 0.26791446857236334}, fitting time: 88.48369216918945, inference time: 0.0019943714141845703\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 34, 'Anomalies Ratio(%)': 0.34}\n",
      "epoch : 1/5000, loss = 0.424634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000068\n",
      "epoch : 2000/5000, loss = 0.000016\n",
      "epoch : 3000/5000, loss = 0.000005\n",
      "epoch : 4000/5000, loss = 0.000004\n",
      "epoch : 5000/5000, loss = 0.000000\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1011it [3:09:08, 16.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('16_http', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8651170568561873, 'aucpr': 0.044080760584375746}, fitting time: 88.94267654418945, inference time: 0.0009980201721191406\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "epoch : 1/5000, loss = 0.463918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002852\n",
      "epoch : 2000/5000, loss = 0.001427\n",
      "epoch : 3000/5000, loss = 0.001181\n",
      "epoch : 4000/5000, loss = 0.000854\n",
      "epoch : 5000/5000, loss = 0.000700\n",
      "self.error_median=0.0004, self.error_range=0.0006\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0007, self.error_std=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1033it [3:10:48,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('13_fraud', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9866488651535381, 'aucpr': 0.06676483548766157}, fitting time: 88.62706279754639, inference time: 0.0019516944885253906\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "epoch : 1/5000, loss = 0.471480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.003349\n",
      "epoch : 2000/5000, loss = 0.001703\n",
      "epoch : 3000/5000, loss = 0.001180\n",
      "epoch : 4000/5000, loss = 0.000879\n",
      "epoch : 5000/5000, loss = 0.000717\n",
      "self.error_median=0.0005, self.error_range=0.0006\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0007, self.error_std=0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1034it [3:12:28, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('13_fraud', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9997328881469115, 'aucpr': 0.885}, fitting time: 89.14178037643433, inference time: 0.001992940902709961\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 13, 'Anomalies Ratio(%)': 0.13}\n",
      "epoch : 1/5000, loss = 0.492956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002797\n",
      "epoch : 2000/5000, loss = 0.001502\n",
      "epoch : 3000/5000, loss = 0.001051\n",
      "epoch : 4000/5000, loss = 0.000847\n",
      "epoch : 5000/5000, loss = 0.000695\n",
      "self.error_median=0.0004, self.error_range=0.0005\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0007, self.error_std=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1035it [3:14:11, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('13_fraud', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9999165554072096, 'aucpr': 0.95}, fitting time: 89.26350021362305, inference time: 0.0019948482513427734\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "epoch : 1/5000, loss = 1.234554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001400\n",
      "epoch : 2000/5000, loss = 0.000195\n",
      "epoch : 3000/5000, loss = 0.000097\n",
      "epoch : 4000/5000, loss = 0.000148\n",
      "epoch : 5000/5000, loss = 0.000122\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1057it [3:15:41,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('11_donors', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9756459123421825, 'aucpr': 0.5819443148196092}, fitting time: 88.85244727134705, inference time: 0.001994609832763672\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 578, 'Anomalies Ratio(%)': 5.78}\n",
      "epoch : 1/5000, loss = 0.917149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001253\n",
      "epoch : 2000/5000, loss = 0.000161\n",
      "epoch : 3000/5000, loss = 0.000115\n",
      "epoch : 4000/5000, loss = 0.000159\n",
      "epoch : 5000/5000, loss = 0.000078\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1058it [3:17:12, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('11_donors', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9810007135978212, 'aucpr': 0.6733484128138232}, fitting time: 88.55650115013123, inference time: 0.0009970664978027344\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 597, 'Anomalies Ratio(%)': 5.97}\n",
      "epoch : 1/5000, loss = 1.115101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002908\n",
      "epoch : 2000/5000, loss = 0.000311\n",
      "epoch : 3000/5000, loss = 0.000110\n",
      "epoch : 4000/5000, loss = 0.000079\n",
      "epoch : 5000/5000, loss = 0.000089\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1059it [3:18:44, 16.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('11_donors', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9843016957812417, 'aucpr': 0.7037394835280725}, fitting time: 90.38803339004517, inference time: 0.0019652843475341797\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 252, 'Anomalies Ratio(%)': 2.52}\n",
      "epoch : 1/5000, loss = 45.269681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.679975\n",
      "epoch : 2000/5000, loss = 2.551827\n",
      "epoch : 3000/5000, loss = 2.500670\n",
      "epoch : 4000/5000, loss = 2.474943\n",
      "epoch : 5000/5000, loss = 2.454095\n",
      "self.error_median=2.4322, self.error_range=0.5193\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.4528, self.error_std=0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1081it [3:20:29,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('3_backdoor', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6746751025991793, 'aucpr': 0.06397536251806203}, fitting time: 95.38838410377502, inference time: 0.0029926300048828125\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 246, 'Anomalies Ratio(%)': 2.46}\n",
      "epoch : 1/5000, loss = 44.549737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.647419\n",
      "epoch : 2000/5000, loss = 2.478885\n",
      "epoch : 3000/5000, loss = 2.406372\n",
      "epoch : 4000/5000, loss = 2.375436\n",
      "epoch : 5000/5000, loss = 2.354284\n",
      "self.error_median=2.3337, self.error_range=0.4963\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.3523, self.error_std=0.3256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1082it [3:22:20, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('3_backdoor', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7468179047126415, 'aucpr': 0.30495729074714945}, fitting time: 94.89271569252014, inference time: 0.0029540061950683594\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 256, 'Anomalies Ratio(%)': 2.56}\n",
      "epoch : 1/5000, loss = 45.845842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.680407\n",
      "epoch : 2000/5000, loss = 2.476556\n",
      "epoch : 3000/5000, loss = 2.417877\n",
      "epoch : 4000/5000, loss = 2.392968\n",
      "epoch : 5000/5000, loss = 2.372801\n",
      "self.error_median=2.3510, self.error_range=0.5328\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.3729, self.error_std=0.3245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1083it [3:24:05, 17.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('3_backdoor', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7436142372851234, 'aucpr': 0.13450517076478555}, fitting time: 95.40324568748474, inference time: 0.003954172134399414\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "epoch : 1/5000, loss = 114.665152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 5.003794\n",
      "epoch : 2000/5000, loss = 4.697517\n",
      "epoch : 3000/5000, loss = 4.467498\n",
      "epoch : 4000/5000, loss = 4.314733\n",
      "epoch : 5000/5000, loss = 4.221968\n",
      "self.error_median=3.9774, self.error_range=3.4529\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=4.2092, self.error_std=1.6325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1105it [3:26:55, 11.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('9_census', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5452853919639, 'aucpr': 0.0815904890956563}, fitting time: 101.84907603263855, inference time: 0.0049877166748046875\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 628, 'Anomalies Ratio(%)': 6.28}\n",
      "epoch : 1/5000, loss = 115.483232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 5.040752\n",
      "epoch : 2000/5000, loss = 4.689158\n",
      "epoch : 3000/5000, loss = 4.436409\n",
      "epoch : 4000/5000, loss = 4.272141\n",
      "epoch : 5000/5000, loss = 4.166390\n",
      "self.error_median=3.9252, self.error_range=3.2006\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=4.1615, self.error_std=1.5563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1106it [3:29:28, 17.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('9_census', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5397158076329409, 'aucpr': 0.09097074951166323}, fitting time: 103.18944668769836, inference time: 0.004986763000488281\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 652, 'Anomalies Ratio(%)': 6.52}\n",
      "epoch : 1/5000, loss = 108.149924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.895049\n",
      "epoch : 2000/5000, loss = 3.578820\n",
      "epoch : 3000/5000, loss = 3.374599\n",
      "epoch : 4000/5000, loss = 3.226788\n",
      "epoch : 5000/5000, loss = 3.141479\n",
      "self.error_median=3.4537, self.error_range=3.0066\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=3.1262, self.error_std=1.4676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1128it [3:32:30, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('9_census', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5665121255349501, 'aucpr': 0.08437863281416973}, fitting time: 101.49891901016235, inference time: 0.00498652458190918\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 97, 'Anomalies Ratio(%)': 0.97}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 116, 'Anomalies Ratio(%)': 1.16}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 95, 'Anomalies Ratio(%)': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 578, 'Anomalies Ratio(%)': 5.78}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 597, 'Anomalies Ratio(%)': 5.97}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 13, 'Anomalies Ratio(%)': 0.13}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 34, 'Anomalies Ratio(%)': 3.4}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 170, 'Anomalies Ratio(%)': 17.0}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 139, 'Anomalies Ratio(%)': 13.9}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 169, 'Anomalies Ratio(%)': 16.9}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 46, 'Anomalies Ratio(%)': 0.46}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 35, 'Anomalies Ratio(%)': 0.35}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 34, 'Anomalies Ratio(%)': 0.34}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 369, 'Anomalies Ratio(%)': 36.9}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 374, 'Anomalies Ratio(%)': 37.4}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 349, 'Anomalies Ratio(%)': 34.9}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 315, 'Anomalies Ratio(%)': 3.15}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 334, 'Anomalies Ratio(%)': 3.34}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 332, 'Anomalies Ratio(%)': 3.32}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 38, 'Anomalies Ratio(%)': 3.8}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 43, 'Anomalies Ratio(%)': 4.3}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3548, 'Anomalies Ratio(%)': 35.48}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3533, 'Anomalies Ratio(%)': 35.33}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3500, 'Anomalies Ratio(%)': 35.0}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 230, 'Anomalies Ratio(%)': 2.3}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 241, 'Anomalies Ratio(%)': 2.41}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 227, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 367, 'Anomalies Ratio(%)': 36.7}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 346, 'Anomalies Ratio(%)': 34.6}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 669, 'Anomalies Ratio(%)': 6.69}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 697, 'Anomalies Ratio(%)': 6.97}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 714, 'Anomalies Ratio(%)': 7.14}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2081, 'Anomalies Ratio(%)': 20.81}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2082, 'Anomalies Ratio(%)': 20.82}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2066, 'Anomalies Ratio(%)': 20.66}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 5, 'Anomalies Ratio(%)': 0.05}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 90, 'Anomalies Ratio(%)': 9.0}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 95, 'Anomalies Ratio(%)': 9.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 100, 'Anomalies Ratio(%)': 10.0}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 123, 'Anomalies Ratio(%)': 12.3}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 133, 'Anomalies Ratio(%)': 13.3}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 252, 'Anomalies Ratio(%)': 2.52}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 246, 'Anomalies Ratio(%)': 2.46}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 256, 'Anomalies Ratio(%)': 2.56}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 35, 'Anomalies Ratio(%)': 3.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 45, 'Anomalies Ratio(%)': 4.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 48, 'Anomalies Ratio(%)': 4.8}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 26, 'Anomalies Ratio(%)': 2.6}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 29, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 27, 'Anomalies Ratio(%)': 2.7}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 75, 'Anomalies Ratio(%)': 7.5}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 80, 'Anomalies Ratio(%)': 8.0}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 88, 'Anomalies Ratio(%)': 8.8}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 239, 'Anomalies Ratio(%)': 23.9}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 224, 'Anomalies Ratio(%)': 22.4}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 225, 'Anomalies Ratio(%)': 22.5}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 348, 'Anomalies Ratio(%)': 34.8}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 336, 'Anomalies Ratio(%)': 33.6}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 364, 'Anomalies Ratio(%)': 36.4}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1134, 'Anomalies Ratio(%)': 11.34}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 222, 'Anomalies Ratio(%)': 2.22}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 238, 'Anomalies Ratio(%)': 2.38}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 216, 'Anomalies Ratio(%)': 2.16}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 628, 'Anomalies Ratio(%)': 6.28}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 652, 'Anomalies Ratio(%)': 6.52}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 215, 'Anomalies Ratio(%)': 21.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 215, 'Anomalies Ratio(%)': 21.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 198, 'Anomalies Ratio(%)': 19.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 251, 'Anomalies Ratio(%)': 25.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 242, 'Anomalies Ratio(%)': 24.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 242, 'Anomalies Ratio(%)': 24.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 304, 'Anomalies Ratio(%)': 30.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 29.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 254, 'Anomalies Ratio(%)': 25.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 227, 'Anomalies Ratio(%)': 22.7}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 213, 'Anomalies Ratio(%)': 21.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 180, 'Anomalies Ratio(%)': 18.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 169, 'Anomalies Ratio(%)': 16.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 174, 'Anomalies Ratio(%)': 17.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 160, 'Anomalies Ratio(%)': 16.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 142, 'Anomalies Ratio(%)': 14.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 259, 'Anomalies Ratio(%)': 25.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 273, 'Anomalies Ratio(%)': 27.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 246, 'Anomalies Ratio(%)': 24.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 284, 'Anomalies Ratio(%)': 28.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 283, 'Anomalies Ratio(%)': 28.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 281, 'Anomalies Ratio(%)': 28.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 314, 'Anomalies Ratio(%)': 31.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 300, 'Anomalies Ratio(%)': 30.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 326, 'Anomalies Ratio(%)': 32.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 240, 'Anomalies Ratio(%)': 24.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 244, 'Anomalies Ratio(%)': 24.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 266, 'Anomalies Ratio(%)': 26.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 227, 'Anomalies Ratio(%)': 22.7}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 231, 'Anomalies Ratio(%)': 23.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 252, 'Anomalies Ratio(%)': 25.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 271, 'Anomalies Ratio(%)': 27.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 285, 'Anomalies Ratio(%)': 28.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 288, 'Anomalies Ratio(%)': 28.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 115, 'Anomalies Ratio(%)': 11.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 135, 'Anomalies Ratio(%)': 13.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 114, 'Anomalies Ratio(%)': 11.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 184, 'Anomalies Ratio(%)': 18.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 189, 'Anomalies Ratio(%)': 18.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 175, 'Anomalies Ratio(%)': 17.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 305, 'Anomalies Ratio(%)': 30.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 304, 'Anomalies Ratio(%)': 30.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 320, 'Anomalies Ratio(%)': 32.0}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 40, 'Anomalies Ratio(%)': 4.0}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "epoch : 1/5000, loss = 37.865936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.857491\n",
      "epoch : 2000/5000, loss = 1.974666\n",
      "epoch : 3000/5000, loss = 1.589279\n",
      "epoch : 4000/5000, loss = 1.351364\n",
      "epoch : 5000/5000, loss = 1.192295\n",
      "self.error_median=0.9826, self.error_range=0.9117\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.1919, self.error_std=0.7372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:14, 74.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_hazelnut', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6833035125718052, 'aucpr': 0.35190077586207247}, fitting time: 74.26191782951355, inference time: 0.0009622573852539062\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 75, 'Anomalies Ratio(%)': 7.5}\n",
      "epoch : 1/5000, loss = 2.599151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.003982\n",
      "epoch : 2000/5000, loss = 0.001626\n",
      "epoch : 3000/5000, loss = 0.000483\n",
      "epoch : 4000/5000, loss = 0.000315\n",
      "epoch : 5000/5000, loss = 0.000119\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [02:43,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('45_wine', 0.0, 1), model: Customized, metrics: {'aucroc': 0.85543870663946, 'aucpr': 0.30549483059622196}, fitting time: 88.78352785110474, inference time: 0.0010292530059814453\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 80, 'Anomalies Ratio(%)': 8.0}\n",
      "epoch : 1/5000, loss = 2.625923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.008687\n",
      "epoch : 2000/5000, loss = 0.002374\n",
      "epoch : 3000/5000, loss = 0.000535\n",
      "epoch : 4000/5000, loss = 0.000459\n",
      "epoch : 5000/5000, loss = 0.000340\n",
      "self.error_median=0.0003, self.error_range=0.0003\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0002\n",
      "Current experiment parameters: ('45_wine', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7706823671497585, 'aucpr': 0.19985493102429297}, fitting time: 88.30722379684448, inference time: 0.000997304916381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [04:12, 10.25s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 88, 'Anomalies Ratio(%)': 8.8}\n",
      "epoch : 1/5000, loss = 2.764294\n",
      "epoch : 1000/5000, loss = 0.005040\n",
      "epoch : 2000/5000, loss = 0.002162\n",
      "epoch : 3000/5000, loss = 0.000855\n",
      "epoch : 4000/5000, loss = 0.000714\n",
      "epoch : 5000/5000, loss = 0.000325\n",
      "self.error_median=0.0003, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [05:40, 15.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('45_wine', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8051656372824256, 'aucpr': 0.20554276977899977}, fitting time: 88.11481428146362, inference time: 0.0009922981262207031\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 123, 'Anomalies Ratio(%)': 12.3}\n",
      "epoch : 1/5000, loss = 0.955283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000660\n",
      "epoch : 2000/5000, loss = 0.000058\n",
      "epoch : 3000/5000, loss = 0.000082\n",
      "epoch : 4000/5000, loss = 0.000027\n",
      "epoch : 5000/5000, loss = 0.000030\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [07:09,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('39_vertebral', 0.0, 1), model: Customized, metrics: {'aucroc': 0.3037714520604254, 'aucpr': 0.08808347924401713}, fitting time: 88.36947727203369, inference time: 0.0019953250885009766\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "epoch : 1/5000, loss = 0.916832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000137\n",
      "epoch : 2000/5000, loss = 0.000172\n",
      "epoch : 3000/5000, loss = 0.000025\n",
      "epoch : 4000/5000, loss = 0.000072\n",
      "epoch : 5000/5000, loss = 0.000078\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:38, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('39_vertebral', 0.0, 2), model: Customized, metrics: {'aucroc': 0.45023071852340146, 'aucpr': 0.17019981648255528}, fitting time: 88.6539740562439, inference time: 0.0009970664978027344\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 133, 'Anomalies Ratio(%)': 13.3}\n",
      "epoch : 1/5000, loss = 0.931705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000441\n",
      "epoch : 2000/5000, loss = 0.000196\n",
      "epoch : 3000/5000, loss = 0.000074\n",
      "epoch : 4000/5000, loss = 0.000069\n",
      "epoch : 5000/5000, loss = 0.000099\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [10:06, 15.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('39_vertebral', 0.0, 3), model: Customized, metrics: {'aucroc': 0.38471153846153844, 'aucpr': 0.10598851774297804}, fitting time: 88.00442481040955, inference time: 0.0010263919830322266\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 239, 'Anomalies Ratio(%)': 23.9}\n",
      "epoch : 1/5000, loss = 4.463392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.062100\n",
      "epoch : 2000/5000, loss = 0.025801\n",
      "epoch : 3000/5000, loss = 0.016470\n",
      "epoch : 4000/5000, loss = 0.011672\n",
      "epoch : 5000/5000, loss = 0.009223\n",
      "self.error_median=0.0073, self.error_range=0.0090\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0092, self.error_std=0.0071\n",
      "Current experiment parameters: ('46_WPBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.44901315789473684, 'aucpr': 0.2181393312656922}, fitting time: 88.34112215042114, inference time: 0.001027822494506836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [11:34,  8.14s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 224, 'Anomalies Ratio(%)': 22.4}\n",
      "epoch : 1/5000, loss = 4.570541\n",
      "epoch : 1000/5000, loss = 0.068248\n",
      "epoch : 2000/5000, loss = 0.031276\n",
      "epoch : 3000/5000, loss = 0.019035\n",
      "epoch : 4000/5000, loss = 0.013828\n",
      "epoch : 5000/5000, loss = 0.010604\n",
      "self.error_median=0.0093, self.error_range=0.0074\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0106, self.error_std=0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [13:03, 11.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.4801101787201333, 'aucpr': 0.25070156576242264}, fitting time: 88.41134071350098, inference time: 0.001986980438232422\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 225, 'Anomalies Ratio(%)': 22.5}\n",
      "epoch : 1/5000, loss = 4.470655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.060335\n",
      "epoch : 2000/5000, loss = 0.029614\n",
      "epoch : 3000/5000, loss = 0.021415\n",
      "epoch : 4000/5000, loss = 0.013698\n",
      "epoch : 5000/5000, loss = 0.010605\n",
      "self.error_median=0.0087, self.error_range=0.0093\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0106, self.error_std=0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [14:33, 15.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5817063894523327, 'aucpr': 0.3230392150177072}, fitting time: 89.23711633682251, inference time: 0.001964569091796875\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 90, 'Anomalies Ratio(%)': 9.0}\n",
      "epoch : 1/5000, loss = 2.133540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002180\n",
      "epoch : 2000/5000, loss = 0.000705\n",
      "epoch : 3000/5000, loss = 0.000651\n",
      "epoch : 4000/5000, loss = 0.000287\n",
      "epoch : 5000/5000, loss = 0.000370\n",
      "self.error_median=0.0003, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [16:01,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 1), model: Customized, metrics: {'aucroc': 0.48514448514448516, 'aucpr': 0.09737626171355761}, fitting time: 88.43145895004272, inference time: 0.001996278762817383\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 95, 'Anomalies Ratio(%)': 9.5}\n",
      "epoch : 1/5000, loss = 2.276993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001489\n",
      "epoch : 2000/5000, loss = 0.000414\n",
      "epoch : 3000/5000, loss = 0.000332\n",
      "epoch : 4000/5000, loss = 0.000306\n",
      "epoch : 5000/5000, loss = 0.000544\n",
      "self.error_median=0.0005, self.error_range=0.0003\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0005, self.error_std=0.0002\n",
      "Current experiment parameters: ('37_Stamps', 0.0, 2), model: Customized, metrics: {'aucroc': 0.45535714285714285, 'aucpr': 0.09778472511426807}, fitting time: 87.94701647758484, inference time: 0.0019941329956054688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [17:29, 11.46s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 100, 'Anomalies Ratio(%)': 10.0}\n",
      "epoch : 1/5000, loss = 2.206263\n",
      "epoch : 1000/5000, loss = 0.001862\n",
      "epoch : 2000/5000, loss = 0.000730\n",
      "epoch : 3000/5000, loss = 0.000301\n",
      "epoch : 4000/5000, loss = 0.000226\n",
      "epoch : 5000/5000, loss = 0.000113\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [18:58, 15.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5288888888888889, 'aucpr': 0.12132085887393519}, fitting time: 88.43644571304321, inference time: 0.0029964447021484375\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 348, 'Anomalies Ratio(%)': 34.8}\n",
      "epoch : 1/5000, loss = 1.384183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001260\n",
      "epoch : 2000/5000, loss = 0.000348\n",
      "epoch : 3000/5000, loss = 0.000711\n",
      "epoch : 4000/5000, loss = 0.000149\n",
      "epoch : 5000/5000, loss = 0.000160\n",
      "self.error_median=0.0000, self.error_range=0.0003\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [20:27,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('4_breastw', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9449568288854003, 'aucpr': 0.8537414146824178}, fitting time: 88.16870546340942, inference time: 0.0009710788726806641\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 336, 'Anomalies Ratio(%)': 33.6}\n",
      "epoch : 1/5000, loss = 1.381212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001181\n",
      "epoch : 2000/5000, loss = 0.000623\n",
      "epoch : 3000/5000, loss = 0.000283\n",
      "epoch : 4000/5000, loss = 0.000133\n",
      "epoch : 5000/5000, loss = 0.000431\n",
      "self.error_median=0.0001, self.error_range=0.0010\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0005, self.error_std=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [21:55, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('4_breastw', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9728344693765859, 'aucpr': 0.8954722236634325}, fitting time: 87.92022776603699, inference time: 0.0009961128234863281\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 364, 'Anomalies Ratio(%)': 36.4}\n",
      "epoch : 1/5000, loss = 1.501609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001484\n",
      "epoch : 2000/5000, loss = 0.001095\n",
      "epoch : 3000/5000, loss = 0.000616\n",
      "epoch : 4000/5000, loss = 0.000491\n",
      "epoch : 5000/5000, loss = 0.000177\n",
      "self.error_median=0.0001, self.error_range=0.0004\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [23:24, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('4_breastw', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9094577069023488, 'aucpr': 0.7448360331899672}, fitting time: 88.81888937950134, inference time: 0.0009975433349609375\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 40, 'Anomalies Ratio(%)': 4.0}\n",
      "epoch : 1/5000, loss = 250.088181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 5.405194\n",
      "epoch : 2000/5000, loss = 3.847006\n",
      "epoch : 3000/5000, loss = 3.114047\n",
      "epoch : 4000/5000, loss = 2.764900\n",
      "epoch : 5000/5000, loss = 2.507437\n",
      "self.error_median=2.3451, self.error_range=1.3954\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.4921, self.error_std=1.0552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145it [24:36,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20news_3', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8096064814814815, 'aucpr': 0.19734723694386622}, fitting time: 71.66150212287903, inference time: 0.0009992122650146484\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 180, 'Anomalies Ratio(%)': 18.0}\n",
      "epoch : 1/5000, loss = 27.666669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.365382\n",
      "epoch : 2000/5000, loss = 1.518985\n",
      "epoch : 3000/5000, loss = 1.174690\n",
      "epoch : 4000/5000, loss = 0.987214\n",
      "epoch : 5000/5000, loss = 0.862932\n",
      "self.error_median=0.7133, self.error_range=0.6780\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.8624, self.error_std=0.5123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [25:49,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_grid', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5778380006022281, 'aucpr': 0.3098501753528509}, fitting time: 73.2665503025055, inference time: 0.001994609832763672\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 305, 'Anomalies Ratio(%)': 30.5}\n",
      "epoch : 1/5000, loss = 36.205273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.599251\n",
      "epoch : 2000/5000, loss = 0.995860\n",
      "epoch : 3000/5000, loss = 0.691889\n",
      "epoch : 4000/5000, loss = 0.559457\n",
      "epoch : 5000/5000, loss = 0.455357\n",
      "self.error_median=0.3138, self.error_range=0.4997\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.4551, self.error_std=0.4197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "193it [27:04,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_zipper', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8158157631841843, 'aucpr': 0.6010477828797078}, fitting time: 74.65761041641235, inference time: 0.0009913444519042969\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 184, 'Anomalies Ratio(%)': 18.4}\n",
      "epoch : 1/5000, loss = 22.162877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.965159\n",
      "epoch : 2000/5000, loss = 1.344473\n",
      "epoch : 3000/5000, loss = 1.063355\n",
      "epoch : 4000/5000, loss = 0.898170\n",
      "epoch : 5000/5000, loss = 0.784260\n",
      "self.error_median=0.5852, self.error_range=0.7700\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.7841, self.error_std=0.6235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "217it [28:20,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_wood', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5518367346938775, 'aucpr': 0.274426411458941}, fitting time: 75.18619775772095, inference time: 0.0009622573852539062\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 367, 'Anomalies Ratio(%)': 36.7}\n",
      "epoch : 1/5000, loss = 1.511400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000468\n",
      "epoch : 2000/5000, loss = 0.000770\n",
      "epoch : 3000/5000, loss = 0.000078\n",
      "epoch : 4000/5000, loss = 0.000160\n",
      "epoch : 5000/5000, loss = 0.000079\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [29:43,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('29_Pima', 0.0, 1), model: Customized, metrics: {'aucroc': 0.683397129186603, 'aucpr': 0.5571927052775539}, fitting time: 82.68314576148987, inference time: 0.0019948482513427734\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 346, 'Anomalies Ratio(%)': 34.6}\n",
      "epoch : 1/5000, loss = 1.422767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000535\n",
      "epoch : 2000/5000, loss = 0.000470\n",
      "epoch : 3000/5000, loss = 0.000148\n",
      "epoch : 4000/5000, loss = 0.000177\n",
      "epoch : 5000/5000, loss = 0.000067\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "242it [31:12,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('29_Pima', 0.0, 2), model: Customized, metrics: {'aucroc': 0.671997645211931, 'aucpr': 0.4970933905219466}, fitting time: 88.72451066970825, inference time: 0.0020232200622558594\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "epoch : 1/5000, loss = 1.331684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001239\n",
      "epoch : 2000/5000, loss = 0.000738\n",
      "epoch : 3000/5000, loss = 0.000088\n",
      "epoch : 4000/5000, loss = 0.000194\n",
      "epoch : 5000/5000, loss = 0.000103\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n",
      "Current experiment parameters: ('29_Pima', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7748223244147157, 'aucpr': 0.5362096656117453}, fitting time: 89.35976147651672, inference time: 0.000990152359008789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "243it [32:41,  7.90s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 115, 'Anomalies Ratio(%)': 11.5}\n",
      "epoch : 1/5000, loss = 33.772094\n",
      "epoch : 1000/5000, loss = 2.254002\n",
      "epoch : 2000/5000, loss = 1.648572\n",
      "epoch : 3000/5000, loss = 1.322896\n",
      "epoch : 4000/5000, loss = 1.091166\n",
      "epoch : 5000/5000, loss = 0.929142\n",
      "self.error_median=0.7240, self.error_range=0.7668\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.9275, self.error_std=0.6219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "265it [33:56,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_transistor', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6721293800539083, 'aucpr': 0.25358259986929677}, fitting time: 74.80692791938782, inference time: 0.0009615421295166016\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 271, 'Anomalies Ratio(%)': 27.1}\n",
      "epoch : 1/5000, loss = 79.990765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.814214\n",
      "epoch : 2000/5000, loss = 1.028462\n",
      "epoch : 3000/5000, loss = 0.690860\n",
      "epoch : 4000/5000, loss = 0.521621\n",
      "epoch : 5000/5000, loss = 0.415688\n",
      "self.error_median=0.3261, self.error_range=0.3067\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.4156, self.error_std=0.2818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "289it [35:11,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_toothbrush', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8336433846327301, 'aucpr': 0.727370564029513}, fitting time: 74.94590878486633, inference time: 0.000997781753540039\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 26, 'Anomalies Ratio(%)': 2.6}\n",
      "epoch : 1/5000, loss = 2.874993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.027155\n",
      "epoch : 2000/5000, loss = 0.011440\n",
      "epoch : 3000/5000, loss = 0.006606\n",
      "epoch : 4000/5000, loss = 0.005604\n",
      "epoch : 5000/5000, loss = 0.003152\n",
      "self.error_median=0.0026, self.error_range=0.0023\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0031, self.error_std=0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [36:34,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.901541095890411, 'aucpr': 0.2141569265757907}, fitting time: 82.4292049407959, inference time: 0.002991914749145508\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 29, 'Anomalies Ratio(%)': 2.9}\n",
      "epoch : 1/5000, loss = 2.746726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.031197\n",
      "epoch : 2000/5000, loss = 0.014059\n",
      "epoch : 3000/5000, loss = 0.007925\n",
      "epoch : 4000/5000, loss = 0.006748\n",
      "epoch : 5000/5000, loss = 0.005378\n",
      "self.error_median=0.0039, self.error_range=0.0044\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0052, self.error_std=0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "314it [38:04,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8995799923634975, 'aucpr': 0.22407589663002656}, fitting time: 89.56055617332458, inference time: 0.0009982585906982422\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 27, 'Anomalies Ratio(%)': 2.7}\n",
      "epoch : 1/5000, loss = 2.816974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.028347\n",
      "epoch : 2000/5000, loss = 0.013326\n",
      "epoch : 3000/5000, loss = 0.009108\n",
      "epoch : 4000/5000, loss = 0.005885\n",
      "epoch : 5000/5000, loss = 0.004737\n",
      "self.error_median=0.0038, self.error_range=0.0032\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0047, self.error_std=0.0036\n",
      "Current experiment parameters: ('43_WDBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7230308219178082, 'aucpr': 0.18206115362031633}, fitting time: 89.06215238571167, inference time: 0.0019943714141845703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "315it [39:33,  8.61s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 240, 'Anomalies Ratio(%)': 24.0}\n",
      "epoch : 1/5000, loss = 30.643940\n",
      "epoch : 1000/5000, loss = 2.425059\n",
      "epoch : 2000/5000, loss = 1.522263\n",
      "epoch : 3000/5000, loss = 1.177365\n",
      "epoch : 4000/5000, loss = 0.995112\n",
      "epoch : 5000/5000, loss = 0.889804\n",
      "self.error_median=0.7259, self.error_range=0.6380\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.8879, self.error_std=0.5258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "337it [40:49,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_screw', 0.0, 1), model: Customized, metrics: {'aucroc': 0.642361111111111, 'aucpr': 0.4328748998481032}, fitting time: 75.03823590278625, inference time: 0.0009701251983642578\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 227, 'Anomalies Ratio(%)': 22.7}\n",
      "epoch : 1/5000, loss = 25.540179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.432959\n",
      "epoch : 2000/5000, loss = 1.648092\n",
      "epoch : 3000/5000, loss = 1.354548\n",
      "epoch : 4000/5000, loss = 1.187648\n",
      "epoch : 5000/5000, loss = 1.043169\n",
      "self.error_median=0.9109, self.error_range=0.6631\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.0421, self.error_std=0.5257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361it [42:04,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_tile', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7763057809330627, 'aucpr': 0.6408817080430154}, fitting time: 74.7521390914917, inference time: 0.0009920597076416016\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 251, 'Anomalies Ratio(%)': 25.1}\n",
      "epoch : 1/5000, loss = 60.292877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.822146\n",
      "epoch : 2000/5000, loss = 2.644666\n",
      "epoch : 3000/5000, loss = 2.062663\n",
      "epoch : 4000/5000, loss = 1.821402\n",
      "epoch : 5000/5000, loss = 1.639710\n",
      "self.error_median=1.4116, self.error_range=1.0922\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.6397, self.error_std=0.7886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "385it [43:19,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_cable', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7057185185185185, 'aucpr': 0.4128408093141174}, fitting time: 74.72080421447754, inference time: 0.0009644031524658203\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 254, 'Anomalies Ratio(%)': 25.4}\n",
      "epoch : 1/5000, loss = 21.671799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.404967\n",
      "epoch : 2000/5000, loss = 1.042021\n",
      "epoch : 3000/5000, loss = 0.824370\n",
      "epoch : 4000/5000, loss = 0.706608\n",
      "epoch : 5000/5000, loss = 0.607472\n",
      "self.error_median=0.4953, self.error_range=0.4437\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.6075, self.error_std=0.4039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "409it [44:34,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_carpet', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6325187969924813, 'aucpr': 0.4381232457256514}, fitting time: 74.77572107315063, inference time: 0.0009672641754150391\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "epoch : 1/5000, loss = 46.545484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.158023\n",
      "epoch : 2000/5000, loss = 0.664632\n",
      "epoch : 3000/5000, loss = 0.529005\n",
      "epoch : 4000/5000, loss = 0.409678\n",
      "epoch : 5000/5000, loss = 0.353629\n",
      "self.error_median=0.2594, self.error_range=0.2443\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.3529, self.error_std=0.3670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "433it [45:49,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_capsule', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6286057692307693, 'aucpr': 0.5288368690825791}, fitting time: 74.8517713546753, inference time: 0.0009708404541015625\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "epoch : 1/5000, loss = 1.840440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000640\n",
      "epoch : 2000/5000, loss = 0.000326\n",
      "epoch : 3000/5000, loss = 0.000430\n",
      "epoch : 4000/5000, loss = 0.000203\n",
      "epoch : 5000/5000, loss = 0.000099\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 7. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "457it [47:10,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('14_glass', 0.0, 1), model: Customized, metrics: {'aucroc': 0.25971589386223537, 'aucpr': 0.03397080241093496}, fitting time: 81.43839693069458, inference time: 0.0019953250885009766\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "epoch : 1/5000, loss = 1.884594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000759\n",
      "epoch : 2000/5000, loss = 0.000301\n",
      "epoch : 3000/5000, loss = 0.000229\n",
      "epoch : 4000/5000, loss = 0.000160\n",
      "epoch : 5000/5000, loss = 0.000108\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 7. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "458it [48:40,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('14_glass', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5306888233717502, 'aucpr': 0.06112061395862519}, fitting time: 89.730135679245, inference time: 0.001992940902709961\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 34, 'Anomalies Ratio(%)': 3.4}\n",
      "epoch : 1/5000, loss = 1.763270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000791\n",
      "epoch : 2000/5000, loss = 0.000203\n",
      "epoch : 3000/5000, loss = 0.000366\n",
      "epoch : 4000/5000, loss = 0.000298\n",
      "epoch : 5000/5000, loss = 0.000074\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 7. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "459it [50:10,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('14_glass', 0.0, 3), model: Customized, metrics: {'aucroc': 0.3893103448275862, 'aucpr': 0.03686905094656207}, fitting time: 88.89731049537659, inference time: 0.0019943714141845703\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 170, 'Anomalies Ratio(%)': 17.0}\n",
      "epoch : 1/5000, loss = 9.404732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.021479\n",
      "epoch : 2000/5000, loss = 0.016740\n",
      "epoch : 3000/5000, loss = 0.002878\n",
      "epoch : 4000/5000, loss = 0.002505\n",
      "epoch : 5000/5000, loss = 0.003245\n",
      "self.error_median=0.0029, self.error_range=0.0026\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0029, self.error_std=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "481it [51:39,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('15_Hepatitis', 0.0, 1), model: Customized, metrics: {'aucroc': 0.21615875265768958, 'aucpr': 0.11692645953575696}, fitting time: 89.5583963394165, inference time: 0.0019941329956054688\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 139, 'Anomalies Ratio(%)': 13.9}\n",
      "epoch : 1/5000, loss = 9.460017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.057457\n",
      "epoch : 2000/5000, loss = 0.013764\n",
      "epoch : 3000/5000, loss = 0.005681\n",
      "epoch : 4000/5000, loss = 0.005392\n",
      "epoch : 5000/5000, loss = 0.001791\n",
      "self.error_median=0.0011, self.error_range=0.0022\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0018, self.error_std=0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "482it [53:09,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('15_Hepatitis', 0.0, 2), model: Customized, metrics: {'aucroc': 0.4010705057216686, 'aucpr': 0.12492822863532294}, fitting time: 89.3519287109375, inference time: 0.0010135173797607422\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 169, 'Anomalies Ratio(%)': 16.9}\n",
      "epoch : 1/5000, loss = 9.674458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.027631\n",
      "epoch : 2000/5000, loss = 0.008069\n",
      "epoch : 3000/5000, loss = 0.002356\n",
      "epoch : 4000/5000, loss = 0.001173\n",
      "epoch : 5000/5000, loss = 0.000913\n",
      "self.error_median=0.0009, self.error_range=0.0008\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0010, self.error_std=0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "483it [54:38, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('15_Hepatitis', 0.0, 3), model: Customized, metrics: {'aucroc': 0.14457831325301207, 'aucpr': 0.10681808664481447}, fitting time: 89.06273460388184, inference time: 0.00202178955078125\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 314, 'Anomalies Ratio(%)': 31.4}\n",
      "epoch : 1/5000, loss = 54.423022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.912485\n",
      "epoch : 2000/5000, loss = 0.990752\n",
      "epoch : 3000/5000, loss = 0.797485\n",
      "epoch : 4000/5000, loss = 0.658144\n",
      "epoch : 5000/5000, loss = 0.571275\n",
      "self.error_median=0.4451, self.error_range=0.4572\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.5712, self.error_std=0.4255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "505it [55:54,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_pill', 0.0, 1), model: Customized, metrics: {'aucroc': 0.734352406527577, 'aucpr': 0.583331160210221}, fitting time: 75.00158095359802, inference time: 0.000997304916381836\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 35, 'Anomalies Ratio(%)': 3.5}\n",
      "epoch : 1/5000, loss = 0.447399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000139\n",
      "epoch : 2000/5000, loss = 0.000152\n",
      "epoch : 3000/5000, loss = 0.000499\n",
      "epoch : 4000/5000, loss = 0.000059\n",
      "epoch : 5000/5000, loss = 0.000073\n",
      "self.error_median=0.0000, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "529it [57:20,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.976551724137931, 'aucpr': 0.4882327586206896}, fitting time: 86.12723517417908, inference time: 0.001995563507080078\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 45, 'Anomalies Ratio(%)': 4.5}\n",
      "epoch : 1/5000, loss = 0.504750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000437\n",
      "epoch : 2000/5000, loss = 0.000495\n",
      "epoch : 3000/5000, loss = 0.000211\n",
      "epoch : 4000/5000, loss = 0.000014\n",
      "epoch : 5000/5000, loss = 0.000103\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "530it [58:49,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9535464535464535, 'aucpr': 0.3894654217962489}, fitting time: 89.0060338973999, inference time: 0.0010190010070800781\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 48, 'Anomalies Ratio(%)': 4.8}\n",
      "epoch : 1/5000, loss = 0.526123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000381\n",
      "epoch : 2000/5000, loss = 0.000146\n",
      "epoch : 3000/5000, loss = 0.000067\n",
      "epoch : 4000/5000, loss = 0.000081\n",
      "epoch : 5000/5000, loss = 0.000077\n",
      "self.error_median=0.0000, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "531it [1:00:19, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9750249750249751, 'aucpr': 0.5995769703762511}, fitting time: 89.44126176834106, inference time: 0.0009946823120117188\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 215, 'Anomalies Ratio(%)': 21.5}\n",
      "epoch : 1/5000, loss = 91.934512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.205117\n",
      "epoch : 2000/5000, loss = 1.190693\n",
      "epoch : 3000/5000, loss = 0.799647\n",
      "epoch : 4000/5000, loss = 0.616539\n",
      "epoch : 5000/5000, loss = 0.491337\n",
      "self.error_median=0.2987, self.error_range=0.3771\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.4911, self.error_std=0.5156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "553it [1:01:34,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_bottle', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9404909983633387, 'aucpr': 0.9213508800655522}, fitting time: 75.26831007003784, inference time: 0.000997304916381836\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 259, 'Anomalies Ratio(%)': 25.9}\n",
      "epoch : 1/5000, loss = 25.239915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.147456\n",
      "epoch : 2000/5000, loss = 0.677656\n",
      "epoch : 3000/5000, loss = 0.502762\n",
      "epoch : 4000/5000, loss = 0.359347\n",
      "epoch : 5000/5000, loss = 0.284901\n",
      "self.error_median=0.0894, self.error_range=0.3568\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.2842, self.error_std=0.4675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "577it [1:02:49,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_leather', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9472741972741971, 'aucpr': 0.8974496856765771}, fitting time: 74.3684663772583, inference time: 0.0009696483612060547\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "epoch : 1/5000, loss = 3.260522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.008747\n",
      "epoch : 2000/5000, loss = 0.002843\n",
      "epoch : 3000/5000, loss = 0.001037\n",
      "epoch : 4000/5000, loss = 0.000461\n",
      "epoch : 5000/5000, loss = 0.000843\n",
      "self.error_median=0.0007, self.error_range=0.0006\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0008, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [1:04:11,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6041275797373358, 'aucpr': 0.0693502727522112}, fitting time: 81.5493233203888, inference time: 0.0009975433349609375\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 38, 'Anomalies Ratio(%)': 3.8}\n",
      "epoch : 1/5000, loss = 3.328677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.010484\n",
      "epoch : 2000/5000, loss = 0.004312\n",
      "epoch : 3000/5000, loss = 0.001263\n",
      "epoch : 4000/5000, loss = 0.001118\n",
      "epoch : 5000/5000, loss = 0.000844\n",
      "self.error_median=0.0007, self.error_range=0.0006\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0008, self.error_std=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "602it [1:05:42,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.597986788298207, 'aucpr': 0.06909702452866155}, fitting time: 90.45313334465027, inference time: 0.0019943714141845703\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 43, 'Anomalies Ratio(%)': 4.3}\n",
      "epoch : 1/5000, loss = 3.311298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.009936\n",
      "epoch : 2000/5000, loss = 0.001908\n",
      "epoch : 3000/5000, loss = 0.001642\n",
      "epoch : 4000/5000, loss = 0.000502\n",
      "epoch : 5000/5000, loss = 0.000542\n",
      "self.error_median=0.0005, self.error_range=0.0005\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0005, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "603it [1:07:12,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5111230233181452, 'aucpr': 0.06539879915103901}, fitting time: 89.74402928352356, inference time: 0.0009980201721191406\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 284, 'Anomalies Ratio(%)': 28.4}\n",
      "epoch : 1/5000, loss = 47.409743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.184343\n",
      "epoch : 2000/5000, loss = 2.095384\n",
      "epoch : 3000/5000, loss = 1.657216\n",
      "epoch : 4000/5000, loss = 1.433088\n",
      "epoch : 5000/5000, loss = 1.286862\n",
      "self.error_median=1.0948, self.error_range=0.9111\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.2857, self.error_std=0.7669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [1:08:28,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MVTec-AD_metal_nut', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6528043775649796, 'aucpr': 0.43813796346715994}, fitting time: 75.64506888389587, inference time: 0.0009686946868896484\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 369, 'Anomalies Ratio(%)': 36.9}\n",
      "epoch : 1/5000, loss = 14.755227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.312304\n",
      "epoch : 2000/5000, loss = 0.162569\n",
      "epoch : 3000/5000, loss = 0.097213\n",
      "epoch : 4000/5000, loss = 0.062943\n",
      "epoch : 5000/5000, loss = 0.043840\n",
      "self.error_median=0.0216, self.error_range=0.0609\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0437, self.error_std=0.0580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "649it [1:09:53,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('18_Ionosphere', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7021783688450355, 'aucpr': 0.6519457203622627}, fitting time: 85.11952924728394, inference time: 0.0020241737365722656\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 374, 'Anomalies Ratio(%)': 37.4}\n",
      "epoch : 1/5000, loss = 14.896237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.387453\n",
      "epoch : 2000/5000, loss = 0.225376\n",
      "epoch : 3000/5000, loss = 0.150279\n",
      "epoch : 4000/5000, loss = 0.100221\n",
      "epoch : 5000/5000, loss = 0.074415\n",
      "self.error_median=0.0337, self.error_range=0.0951\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0740, self.error_std=0.1074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "650it [1:11:23,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('18_Ionosphere', 0.0, 2), model: Customized, metrics: {'aucroc': 0.806136018237082, 'aucpr': 0.7585323586150594}, fitting time: 89.55112648010254, inference time: 0.0019850730895996094\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 349, 'Anomalies Ratio(%)': 34.9}\n",
      "epoch : 1/5000, loss = 14.521025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.314417\n",
      "epoch : 2000/5000, loss = 0.182845\n",
      "epoch : 3000/5000, loss = 0.121433\n",
      "epoch : 4000/5000, loss = 0.085889\n",
      "epoch : 5000/5000, loss = 0.058329\n",
      "self.error_median=0.0250, self.error_range=0.0845\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0584, self.error_std=0.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "651it [1:12:52, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('18_Ionosphere', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8352625152625152, 'aucpr': 0.8083320467797556}, fitting time: 89.20512700080872, inference time: 0.0009911060333251953\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "epoch : 1/5000, loss = 3.222102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.006163\n",
      "epoch : 2000/5000, loss = 0.002670\n",
      "epoch : 3000/5000, loss = 0.000433\n",
      "epoch : 4000/5000, loss = 0.000324\n",
      "epoch : 5000/5000, loss = 0.000194\n",
      "self.error_median=0.0002, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 12. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "673it [1:14:21,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('40_vowels', 0.0, 1), model: Customized, metrics: {'aucroc': 0.909478672985782, 'aucpr': 0.21223696856543228}, fitting time: 88.81761407852173, inference time: 0.0010154247283935547\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "epoch : 1/5000, loss = 3.323353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.008846\n",
      "epoch : 2000/5000, loss = 0.002802\n",
      "epoch : 3000/5000, loss = 0.001090\n",
      "epoch : 4000/5000, loss = 0.000691\n",
      "epoch : 5000/5000, loss = 0.000214\n",
      "self.error_median=0.0002, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 12. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "674it [1:15:45,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('40_vowels', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8886255924170616, 'aucpr': 0.26553075292224376}, fitting time: 83.06251573562622, inference time: 0.0010066032409667969\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "epoch : 1/5000, loss = 3.079985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.005945\n",
      "epoch : 2000/5000, loss = 0.001605\n",
      "epoch : 3000/5000, loss = 0.000584\n",
      "epoch : 4000/5000, loss = 0.000510\n",
      "epoch : 5000/5000, loss = 0.000482\n",
      "self.error_median=0.0004, self.error_range=0.0003\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 12. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0004, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "675it [1:17:10, 12.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('40_vowels', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8450236966824646, 'aucpr': 0.14818720065809965}, fitting time: 85.60636639595032, inference time: 0.0009937286376953125\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "epoch : 1/5000, loss = 1.119527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000677\n",
      "epoch : 2000/5000, loss = 0.000187\n",
      "epoch : 3000/5000, loss = 0.000173\n",
      "epoch : 4000/5000, loss = 0.000080\n",
      "epoch : 5000/5000, loss = 0.000048\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "697it [1:18:32,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('47_yeast', 0.0, 1), model: Customized, metrics: {'aucroc': 0.4496285356247762, 'aucpr': 0.30134569397989}, fitting time: 81.08923244476318, inference time: 0.0019941329956054688\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "epoch : 1/5000, loss = 1.247125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000815\n",
      "epoch : 2000/5000, loss = 0.000471\n",
      "epoch : 3000/5000, loss = 0.000125\n",
      "epoch : 4000/5000, loss = 0.000051\n",
      "epoch : 5000/5000, loss = 0.000107\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "698it [1:19:48, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('47_yeast', 0.0, 2), model: Customized, metrics: {'aucroc': 0.4900644468313641, 'aucpr': 0.3232509084806173}, fitting time: 76.41756534576416, inference time: 0.000997304916381836\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "epoch : 1/5000, loss = 1.227429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000560\n",
      "epoch : 2000/5000, loss = 0.000162\n",
      "epoch : 3000/5000, loss = 0.000182\n",
      "epoch : 4000/5000, loss = 0.000065\n",
      "epoch : 5000/5000, loss = 0.000194\n",
      "self.error_median=0.0002, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "699it [1:21:10, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('47_yeast', 0.0, 3), model: Customized, metrics: {'aucroc': 0.4175170068027211, 'aucpr': 0.2898686418055658}, fitting time: 81.08452725410461, inference time: 0.000993967056274414\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "epoch : 1/5000, loss = 258.155492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 4.552229\n",
      "epoch : 2000/5000, loss = 3.033431\n",
      "epoch : 3000/5000, loss = 2.383730\n",
      "epoch : 4000/5000, loss = 2.086125\n",
      "epoch : 5000/5000, loss = 1.890430\n",
      "self.error_median=1.7026, self.error_range=1.0981\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.8793, self.error_std=0.8463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "721it [1:22:29,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20news_5', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5435777534573674, 'aucpr': 0.06210316158339586}, fitting time: 78.79775953292847, inference time: 0.0019638538360595703\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "epoch : 1/5000, loss = 7.131524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.126247\n",
      "epoch : 2000/5000, loss = 0.087894\n",
      "epoch : 3000/5000, loss = 0.074266\n",
      "epoch : 4000/5000, loss = 0.066136\n",
      "epoch : 5000/5000, loss = 0.054908\n",
      "self.error_median=0.0435, self.error_range=0.0544\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0549, self.error_std=0.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "745it [1:23:44,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20_letter', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8204444444444444, 'aucpr': 0.20912175307777153}, fitting time: 74.96374702453613, inference time: 0.0009970664978027344\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "epoch : 1/5000, loss = 7.327292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.148437\n",
      "epoch : 2000/5000, loss = 0.097540\n",
      "epoch : 3000/5000, loss = 0.083708\n",
      "epoch : 4000/5000, loss = 0.074184\n",
      "epoch : 5000/5000, loss = 0.063893\n",
      "self.error_median=0.0493, self.error_range=0.0563\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0640, self.error_std=0.0587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "746it [1:24:59,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20_letter', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7688148148148148, 'aucpr': 0.21890549989577066}, fitting time: 74.15937662124634, inference time: 0.0009980201721191406\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "epoch : 1/5000, loss = 7.247627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.148275\n",
      "epoch : 2000/5000, loss = 0.104222\n",
      "epoch : 3000/5000, loss = 0.084346\n",
      "epoch : 4000/5000, loss = 0.070737\n",
      "epoch : 5000/5000, loss = 0.060586\n",
      "self.error_median=0.0455, self.error_range=0.0579\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0605, self.error_std=0.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "747it [1:26:12,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20_letter', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8445185185185184, 'aucpr': 0.209571150102551}, fitting time: 73.23217964172363, inference time: 0.0010008811950683594\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "epoch : 1/5000, loss = 253.535780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 5.164025\n",
      "epoch : 2000/5000, loss = 3.603378\n",
      "epoch : 3000/5000, loss = 2.918316\n",
      "epoch : 4000/5000, loss = 2.563729\n",
      "epoch : 5000/5000, loss = 2.344872\n",
      "self.error_median=2.0927, self.error_range=1.2727\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.3161, self.error_std=1.1204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "769it [1:27:31,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20news_4', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5907822410147991, 'aucpr': 0.0843023791129968}, fitting time: 78.67451930046082, inference time: 0.0019664764404296875\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "epoch : 1/5000, loss = 3.217962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.017983\n",
      "epoch : 2000/5000, loss = 0.007417\n",
      "epoch : 3000/5000, loss = 0.004440\n",
      "epoch : 4000/5000, loss = 0.003008\n",
      "epoch : 5000/5000, loss = 0.002366\n",
      "self.error_median=0.0018, self.error_range=0.0015\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0022, self.error_std=0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "793it [1:28:46,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('6_cardio', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8192551535628868, 'aucpr': 0.3358197691071536}, fitting time: 74.63428854942322, inference time: 0.0009942054748535156\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "epoch : 1/5000, loss = 3.165030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.020783\n",
      "epoch : 2000/5000, loss = 0.008762\n",
      "epoch : 3000/5000, loss = 0.004957\n",
      "epoch : 4000/5000, loss = 0.003286\n",
      "epoch : 5000/5000, loss = 0.002711\n",
      "self.error_median=0.0019, self.error_range=0.0023\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0028, self.error_std=0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "794it [1:30:00,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('6_cardio', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7916555939410045, 'aucpr': 0.3716197643878636}, fitting time: 74.15721011161804, inference time: 0.0009970664978027344\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "epoch : 1/5000, loss = 3.263132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.026790\n",
      "epoch : 2000/5000, loss = 0.010987\n",
      "epoch : 3000/5000, loss = 0.005594\n",
      "epoch : 4000/5000, loss = 0.003178\n",
      "epoch : 5000/5000, loss = 0.002859\n",
      "self.error_median=0.0017, self.error_range=0.0026\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0029, self.error_std=0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "795it [1:31:14,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('6_cardio', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7836832314642572, 'aucpr': 0.3412943397500958}, fitting time: 73.8500497341156, inference time: 0.0009965896606445312\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "epoch : 1/5000, loss = 6.533206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.043575\n",
      "epoch : 2000/5000, loss = 0.022624\n",
      "epoch : 3000/5000, loss = 0.011412\n",
      "epoch : 4000/5000, loss = 0.005918\n",
      "epoch : 5000/5000, loss = 0.004717\n",
      "self.error_median=0.0036, self.error_range=0.0031\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0048, self.error_std=0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "817it [1:32:29,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('12_fault', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6213066188508615, 'aucpr': 0.42874919672890793}, fitting time: 74.39438223838806, inference time: 0.000997304916381836\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "epoch : 1/5000, loss = 6.311234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.029759\n",
      "epoch : 2000/5000, loss = 0.013159\n",
      "epoch : 3000/5000, loss = 0.009868\n",
      "epoch : 4000/5000, loss = 0.007383\n",
      "epoch : 5000/5000, loss = 0.004773\n",
      "self.error_median=0.0036, self.error_range=0.0029\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0048, self.error_std=0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "818it [1:33:44,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('12_fault', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5977495387334009, 'aucpr': 0.4184099194657992}, fitting time: 74.42928910255432, inference time: 0.0009970664978027344\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "epoch : 1/5000, loss = 6.434962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.051469\n",
      "epoch : 2000/5000, loss = 0.015743\n",
      "epoch : 3000/5000, loss = 0.009866\n",
      "epoch : 4000/5000, loss = 0.006791\n",
      "epoch : 5000/5000, loss = 0.004801\n",
      "self.error_median=0.0036, self.error_range=0.0031\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0047, self.error_std=0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "819it [1:34:58, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('12_fault', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6568956108209246, 'aucpr': 0.48244720750280007}, fitting time: 74.16860103607178, inference time: 0.0009970664978027344\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "epoch : 1/5000, loss = 14.283973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 6.663764\n",
      "epoch : 2000/5000, loss = 5.829790\n",
      "epoch : 3000/5000, loss = 5.394384\n",
      "epoch : 4000/5000, loss = 5.068756\n",
      "epoch : 5000/5000, loss = 4.842883\n",
      "self.error_median=4.5356, self.error_range=4.6493\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=4.8396, self.error_std=2.8311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "841it [1:36:15,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('17_InternetAds', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5485795454545455, 'aucpr': 0.19803653551920086}, fitting time: 76.18155407905579, inference time: 0.0019652843475341797\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "epoch : 1/5000, loss = 14.219814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 6.922732\n",
      "epoch : 2000/5000, loss = 6.057940\n",
      "epoch : 3000/5000, loss = 5.549528\n",
      "epoch : 4000/5000, loss = 5.234158\n",
      "epoch : 5000/5000, loss = 5.016495\n",
      "self.error_median=4.6592, self.error_range=4.7801\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=5.0137, self.error_std=2.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "842it [1:37:32,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('17_InternetAds', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6201704545454545, 'aucpr': 0.29656931085906835}, fitting time: 76.8055067062378, inference time: 0.0029921531677246094\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "epoch : 1/5000, loss = 14.041930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 6.646077\n",
      "epoch : 2000/5000, loss = 5.863724\n",
      "epoch : 3000/5000, loss = 5.435180\n",
      "epoch : 4000/5000, loss = 5.150499\n",
      "epoch : 5000/5000, loss = 4.965709\n",
      "self.error_median=4.6330, self.error_range=4.9730\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=4.9641, self.error_std=2.9278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "843it [1:38:50, 12.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('17_InternetAds', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6210037878787878, 'aucpr': 0.32257610535588777}, fitting time: 77.56209325790405, inference time: 0.0030221939086914062\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "epoch : 1/5000, loss = 3.200457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.021931\n",
      "epoch : 2000/5000, loss = 0.007613\n",
      "epoch : 3000/5000, loss = 0.003676\n",
      "epoch : 4000/5000, loss = 0.002629\n",
      "epoch : 5000/5000, loss = 0.001615\n",
      "self.error_median=0.0008, self.error_range=0.0015\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0016, self.error_std=0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "865it [1:40:05,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('7_Cardiotocography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5828860028860028, 'aucpr': 0.39707487979563183}, fitting time: 75.25093531608582, inference time: 0.0009970664978027344\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "epoch : 1/5000, loss = 3.104593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.016121\n",
      "epoch : 2000/5000, loss = 0.007829\n",
      "epoch : 3000/5000, loss = 0.005837\n",
      "epoch : 4000/5000, loss = 0.002171\n",
      "epoch : 5000/5000, loss = 0.002269\n",
      "self.error_median=0.0017, self.error_range=0.0016\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0023, self.error_std=0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "866it [1:41:22,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('7_Cardiotocography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5996031746031746, 'aucpr': 0.311385168457259}, fitting time: 76.14663314819336, inference time: 0.0010280609130859375\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "epoch : 1/5000, loss = 3.228470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.022507\n",
      "epoch : 2000/5000, loss = 0.008065\n",
      "epoch : 3000/5000, loss = 0.005217\n",
      "epoch : 4000/5000, loss = 0.003844\n",
      "epoch : 5000/5000, loss = 0.002239\n",
      "self.error_median=0.0010, self.error_range=0.0021\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0023, self.error_std=0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "867it [1:42:37, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('7_Cardiotocography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5233621933621933, 'aucpr': 0.28690650304164494}, fitting time: 75.2585780620575, inference time: 0.0009968280792236328\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "epoch : 1/5000, loss = 252.429871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 4.411500\n",
      "epoch : 2000/5000, loss = 2.940865\n",
      "epoch : 3000/5000, loss = 2.308031\n",
      "epoch : 4000/5000, loss = 2.019429\n",
      "epoch : 5000/5000, loss = 1.880175\n",
      "self.error_median=1.6258, self.error_range=1.1534\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.8384, self.error_std=0.9937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "889it [1:43:55,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20news_2', 0.0, 1), model: Customized, metrics: {'aucroc': 0.509211174709071, 'aucpr': 0.06646347010604267}, fitting time: 77.62198805809021, inference time: 0.0019948482513427734\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "epoch : 1/5000, loss = 253.406072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 4.654261\n",
      "epoch : 2000/5000, loss = 3.109887\n",
      "epoch : 3000/5000, loss = 2.555011\n",
      "epoch : 4000/5000, loss = 2.230468\n",
      "epoch : 5000/5000, loss = 2.037707\n",
      "self.error_median=1.9056, self.error_range=1.2844\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.0743, self.error_std=1.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "913it [1:45:12,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20news_1', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6376715848197901, 'aucpr': 0.0863782685090605}, fitting time: 76.99544095993042, inference time: 0.002991914749145508\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "epoch : 1/5000, loss = 39.357337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.189885\n",
      "epoch : 2000/5000, loss = 1.362319\n",
      "epoch : 3000/5000, loss = 1.072915\n",
      "epoch : 4000/5000, loss = 0.938857\n",
      "epoch : 5000/5000, loss = 0.855333\n",
      "self.error_median=0.7990, self.error_range=0.4110\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.8533, self.error_std=0.2888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "937it [1:46:29,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('25_musk', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9609066253390158, 'aucpr': 0.7164609329338978}, fitting time: 75.83529996871948, inference time: 0.001965045928955078\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "epoch : 1/5000, loss = 39.688488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.387485\n",
      "epoch : 2000/5000, loss = 1.406876\n",
      "epoch : 3000/5000, loss = 1.147705\n",
      "epoch : 4000/5000, loss = 1.002405\n",
      "epoch : 5000/5000, loss = 0.903831\n",
      "self.error_median=0.8500, self.error_range=0.4249\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.9028, self.error_std=0.3012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [1:47:45,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('25_musk', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9637349864393646, 'aucpr': 0.6531506075528865}, fitting time: 75.8244252204895, inference time: 0.0010209083557128906\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "epoch : 1/5000, loss = 39.634045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.503327\n",
      "epoch : 2000/5000, loss = 1.463961\n",
      "epoch : 3000/5000, loss = 1.143262\n",
      "epoch : 4000/5000, loss = 1.004997\n",
      "epoch : 5000/5000, loss = 0.918498\n",
      "self.error_median=0.8575, self.error_range=0.4468\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.9161, self.error_std=0.3097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "939it [1:49:00,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('25_musk', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9579620302208447, 'aucpr': 0.6803639132600613}, fitting time: 75.37846803665161, inference time: 0.001996278762817383\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "epoch : 1/5000, loss = 258.651887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.533894\n",
      "epoch : 2000/5000, loss = 2.362911\n",
      "epoch : 3000/5000, loss = 1.923925\n",
      "epoch : 4000/5000, loss = 1.649536\n",
      "epoch : 5000/5000, loss = 1.473117\n",
      "self.error_median=1.2386, self.error_range=0.9617\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.4297, self.error_std=0.8719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "961it [1:50:17,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('20news_0', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7930464393229038, 'aucpr': 0.17922493157669628}, fitting time: 76.2651436328888, inference time: 0.0029633045196533203\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "epoch : 1/5000, loss = 5.807466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.073345\n",
      "epoch : 2000/5000, loss = 0.051226\n",
      "epoch : 3000/5000, loss = 0.046965\n",
      "epoch : 4000/5000, loss = 0.043417\n",
      "epoch : 5000/5000, loss = 0.041790\n",
      "self.error_median=0.0362, self.error_range=0.0423\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0418, self.error_std=0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "985it [1:51:32,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('41_Waveform', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6014955134596212, 'aucpr': 0.0432798804336471}, fitting time: 74.86119651794434, inference time: 0.000997781753540039\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "epoch : 1/5000, loss = 5.722779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.077585\n",
      "epoch : 2000/5000, loss = 0.047964\n",
      "epoch : 3000/5000, loss = 0.045446\n",
      "epoch : 4000/5000, loss = 0.044801\n",
      "epoch : 5000/5000, loss = 0.043141\n",
      "self.error_median=0.0375, self.error_range=0.0416\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0430, self.error_std=0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "986it [1:52:48,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('41_Waveform', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5380525091392488, 'aucpr': 0.03267478252314843}, fitting time: 75.47500467300415, inference time: 0.0009968280792236328\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "epoch : 1/5000, loss = 5.669968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.068034\n",
      "epoch : 2000/5000, loss = 0.051513\n",
      "epoch : 3000/5000, loss = 0.050482\n",
      "epoch : 4000/5000, loss = 0.047450\n",
      "epoch : 5000/5000, loss = 0.046665\n",
      "self.error_median=0.0419, self.error_range=0.0448\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0467, self.error_std=0.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "987it [1:54:03,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('41_Waveform', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6018943170488533, 'aucpr': 0.09449311880799059}, fitting time: 75.0714807510376, inference time: 0.0010254383087158203\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "epoch : 1/5000, loss = 107.974170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 7.365136\n",
      "epoch : 2000/5000, loss = 6.990137\n",
      "epoch : 3000/5000, loss = 6.801407\n",
      "epoch : 4000/5000, loss = 6.679947\n",
      "epoch : 5000/5000, loss = 6.606248\n",
      "self.error_median=6.6657, self.error_range=3.5221\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=6.6019, self.error_std=1.8072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1009it [1:55:21,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('36_speech', 0.0, 1), model: Customized, metrics: {'aucroc': 0.4946384803921569, 'aucpr': 0.020700626806918025}, fitting time: 77.20629453659058, inference time: 0.0019659996032714844\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "epoch : 1/5000, loss = 109.277786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 7.352984\n",
      "epoch : 2000/5000, loss = 7.083887\n",
      "epoch : 3000/5000, loss = 6.878587\n",
      "epoch : 4000/5000, loss = 6.753998\n",
      "epoch : 5000/5000, loss = 6.665502\n",
      "self.error_median=6.7531, self.error_range=3.5681\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=6.6651, self.error_std=1.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [1:56:38,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('36_speech', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5185355392156863, 'aucpr': 0.02218043391052367}, fitting time: 77.18997693061829, inference time: 0.0019643306732177734\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "epoch : 1/5000, loss = 107.659320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 7.240250\n",
      "epoch : 2000/5000, loss = 6.973193\n",
      "epoch : 3000/5000, loss = 6.791040\n",
      "epoch : 4000/5000, loss = 6.656401\n",
      "epoch : 5000/5000, loss = 6.585226\n",
      "self.error_median=6.7001, self.error_range=3.5305\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=6.5845, self.error_std=1.8152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1011it [1:57:56, 11.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('36_speech', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5033700980392157, 'aucpr': 0.01871570084739141}, fitting time: 77.03523206710815, inference time: 0.001975536346435547\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "epoch : 1/5000, loss = 0.655402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000166\n",
      "epoch : 2000/5000, loss = 0.000148\n",
      "epoch : 3000/5000, loss = 0.000086\n",
      "epoch : 4000/5000, loss = 0.000140\n",
      "epoch : 5000/5000, loss = 0.000052\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1033it [1:59:11,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('38_thyroid', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7648162525879917, 'aucpr': 0.16624297083710465}, fitting time: 74.86630439758301, inference time: 0.001987934112548828\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "epoch : 1/5000, loss = 0.625535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000220\n",
      "epoch : 2000/5000, loss = 0.000107\n",
      "epoch : 3000/5000, loss = 0.000118\n",
      "epoch : 4000/5000, loss = 0.000089\n",
      "epoch : 5000/5000, loss = 0.000075\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1034it [2:00:26,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('38_thyroid', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8491847826086957, 'aucpr': 0.25899852987995664}, fitting time: 74.84961009025574, inference time: 0.0009970664978027344\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "epoch : 1/5000, loss = 0.626725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000207\n",
      "epoch : 2000/5000, loss = 0.000093\n",
      "epoch : 3000/5000, loss = 0.000079\n",
      "epoch : 4000/5000, loss = 0.000107\n",
      "epoch : 5000/5000, loss = 0.000050\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1035it [2:01:41, 12.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('38_thyroid', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8780408902691511, 'aucpr': 0.24943262499957297}, fitting time: 75.05720162391663, inference time: 0.001965045928955078\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "epoch : 1/5000, loss = 0.232206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.040054\n",
      "epoch : 2000/5000, loss = 0.025917\n",
      "epoch : 3000/5000, loss = 0.020046\n",
      "epoch : 4000/5000, loss = 0.016362\n",
      "epoch : 5000/5000, loss = 0.013681\n",
      "self.error_median=0.0071, self.error_range=0.0146\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0136, self.error_std=0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1057it [2:02:58,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('35_SpamBase', 0.0, 1), model: Customized, metrics: {'aucroc': 0.492066106196541, 'aucpr': 0.3771548034274439}, fitting time: 76.37591195106506, inference time: 0.0019676685333251953\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "epoch : 1/5000, loss = 0.259924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.047082\n",
      "epoch : 2000/5000, loss = 0.031201\n",
      "epoch : 3000/5000, loss = 0.024139\n",
      "epoch : 4000/5000, loss = 0.019776\n",
      "epoch : 5000/5000, loss = 0.016782\n",
      "self.error_median=0.0086, self.error_range=0.0169\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0168, self.error_std=0.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1058it [2:04:15,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('35_SpamBase', 0.0, 2), model: Customized, metrics: {'aucroc': 0.4962591756070017, 'aucpr': 0.38258033472415465}, fitting time: 76.87746572494507, inference time: 0.0019648075103759766\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "epoch : 1/5000, loss = 0.229799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.040983\n",
      "epoch : 2000/5000, loss = 0.027585\n",
      "epoch : 3000/5000, loss = 0.021820\n",
      "epoch : 4000/5000, loss = 0.017803\n",
      "epoch : 5000/5000, loss = 0.015097\n",
      "self.error_median=0.0078, self.error_range=0.0154\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0151, self.error_std=0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1059it [2:05:32, 13.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('35_SpamBase', 0.0, 3), model: Customized, metrics: {'aucroc': 0.49998954346780433, 'aucpr': 0.39739562218621466}, fitting time: 77.09527063369751, inference time: 0.000997304916381836\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "epoch : 1/5000, loss = 0.612238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000065\n",
      "epoch : 2000/5000, loss = 0.000100\n",
      "epoch : 3000/5000, loss = 0.000036\n",
      "epoch : 4000/5000, loss = 0.000040\n",
      "epoch : 5000/5000, loss = 0.000021\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 5. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1081it [2:06:52,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('44_Wilt', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9489626516653544, 'aucpr': 0.35053086091222374}, fitting time: 79.1280779838562, inference time: 0.0009982585906982422\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "epoch : 1/5000, loss = 0.606284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000085\n",
      "epoch : 2000/5000, loss = 0.000065\n",
      "epoch : 3000/5000, loss = 0.000100\n",
      "epoch : 4000/5000, loss = 0.000043\n",
      "epoch : 5000/5000, loss = 0.000034\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 5. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1082it [2:08:12, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('44_Wilt', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9259863584187908, 'aucpr': 0.30484630147284764}, fitting time: 79.69721293449402, inference time: 0.0010004043579101562\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "epoch : 1/5000, loss = 0.612795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000071\n",
      "epoch : 2000/5000, loss = 0.000055\n",
      "epoch : 3000/5000, loss = 0.000078\n",
      "epoch : 4000/5000, loss = 0.000044\n",
      "epoch : 5000/5000, loss = 0.000023\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 5. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1083it [2:09:30, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('44_Wilt', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9280733875328471, 'aucpr': 0.3270271834123066}, fitting time: 78.5396888256073, inference time: 0.0019948482513427734\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 17.275018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.136252\n",
      "epoch : 2000/5000, loss = 2.448172\n",
      "epoch : 3000/5000, loss = 2.222742\n",
      "epoch : 4000/5000, loss = 2.113063\n",
      "epoch : 5000/5000, loss = 2.024992\n",
      "self.error_median=1.5462, self.error_range=1.5864\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.0230, self.error_std=1.5484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1105it [2:10:50,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('SVHN_9', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5679348876773769, 'aucpr': 0.07014592506088}, fitting time: 78.85983490943909, inference time: 0.0030205249786376953\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 16.524185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.995809\n",
      "epoch : 2000/5000, loss = 2.443340\n",
      "epoch : 3000/5000, loss = 2.251312\n",
      "epoch : 4000/5000, loss = 2.140093\n",
      "epoch : 5000/5000, loss = 2.043565\n",
      "self.error_median=1.6244, self.error_range=1.5879\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.0394, self.error_std=1.4764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1129it [2:12:12,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('SVHN_0', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5980143313476647, 'aucpr': 0.07082652092255676}, fitting time: 82.35953378677368, inference time: 0.002986431121826172\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "epoch : 1/5000, loss = 15.408199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.983466\n",
      "epoch : 2000/5000, loss = 0.733897\n",
      "epoch : 3000/5000, loss = 0.628183\n",
      "epoch : 4000/5000, loss = 0.563200\n",
      "epoch : 5000/5000, loss = 0.523064\n",
      "self.error_median=0.4691, self.error_range=0.3585\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.5215, self.error_std=0.2604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1153it [2:13:28,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('26_optdigits', 0.0, 1), model: Customized, metrics: {'aucroc': 0.4924269005847953, 'aucpr': 0.02851940423547511}, fitting time: 76.00676274299622, inference time: 0.0019943714141845703\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "epoch : 1/5000, loss = 15.079761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.947151\n",
      "epoch : 2000/5000, loss = 0.722499\n",
      "epoch : 3000/5000, loss = 0.630667\n",
      "epoch : 4000/5000, loss = 0.575955\n",
      "epoch : 5000/5000, loss = 0.530180\n",
      "self.error_median=0.4818, self.error_range=0.3565\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.5288, self.error_std=0.2545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1154it [2:14:46,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('26_optdigits', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5079239766081871, 'aucpr': 0.03071311977237149}, fitting time: 77.72125148773193, inference time: 0.002961397171020508\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "epoch : 1/5000, loss = 15.241395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.006605\n",
      "epoch : 2000/5000, loss = 0.784802\n",
      "epoch : 3000/5000, loss = 0.691453\n",
      "epoch : 4000/5000, loss = 0.620086\n",
      "epoch : 5000/5000, loss = 0.575468\n",
      "self.error_median=0.5169, self.error_range=0.3873\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.5744, self.error_std=0.2717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1155it [2:16:04,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('26_optdigits', 0.0, 3), model: Customized, metrics: {'aucroc': 0.44491228070175437, 'aucpr': 0.027380271105611656}, fitting time: 77.66829085350037, inference time: 0.0009968280792236328\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 14.904829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.727456\n",
      "epoch : 2000/5000, loss = 3.099952\n",
      "epoch : 3000/5000, loss = 2.963344\n",
      "epoch : 4000/5000, loss = 2.863035\n",
      "epoch : 5000/5000, loss = 2.763024\n",
      "self.error_median=2.2958, self.error_range=1.9771\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.7610, self.error_std=1.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1177it [2:17:26,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('CIFAR10_9', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7022616033755275, 'aucpr': 0.1205601567820569}, fitting time: 80.98119759559631, inference time: 0.0029909610748291016\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 14.561859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.510000\n",
      "epoch : 2000/5000, loss = 2.994337\n",
      "epoch : 3000/5000, loss = 2.810711\n",
      "epoch : 4000/5000, loss = 2.714884\n",
      "epoch : 5000/5000, loss = 2.638246\n",
      "self.error_median=2.1203, self.error_range=2.0661\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.6357, self.error_std=1.7020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [2:18:49,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('CIFAR10_8', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7459324894514768, 'aucpr': 0.13840534818276815}, fitting time: 82.81957912445068, inference time: 0.002963542938232422\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 15.092242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.806784\n",
      "epoch : 2000/5000, loss = 3.121653\n",
      "epoch : 3000/5000, loss = 2.945703\n",
      "epoch : 4000/5000, loss = 2.867138\n",
      "epoch : 5000/5000, loss = 2.795836\n",
      "self.error_median=2.3079, self.error_range=1.9692\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.7912, self.error_std=1.7357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1225it [2:20:12,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('CIFAR10_7', 0.0, 1), model: Customized, metrics: {'aucroc': 0.556717299578059, 'aucpr': 0.09092148350614065}, fitting time: 82.61697697639465, inference time: 0.002992391586303711\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 14.223758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.330596\n",
      "epoch : 2000/5000, loss = 2.833760\n",
      "epoch : 3000/5000, loss = 2.664291\n",
      "epoch : 4000/5000, loss = 2.566088\n",
      "epoch : 5000/5000, loss = 2.479095\n",
      "self.error_median=1.9598, self.error_range=2.1726\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.4773, self.error_std=1.7190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1249it [2:21:36,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('CIFAR10_6', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7026540084388186, 'aucpr': 0.13172094419329877}, fitting time: 84.07598042488098, inference time: 0.0029859542846679688\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 14.937074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.756332\n",
      "epoch : 2000/5000, loss = 3.165164\n",
      "epoch : 3000/5000, loss = 3.013021\n",
      "epoch : 4000/5000, loss = 2.933256\n",
      "epoch : 5000/5000, loss = 2.857104\n",
      "self.error_median=2.3774, self.error_range=2.1421\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.8548, self.error_std=1.6882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1273it [2:23:00,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('CIFAR10_3', 0.0, 1), model: Customized, metrics: {'aucroc': 0.577957805907173, 'aucpr': 0.09212025649462915}, fitting time: 83.15852046012878, inference time: 0.002964496612548828\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 13.149710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.216978\n",
      "epoch : 2000/5000, loss = 2.673078\n",
      "epoch : 3000/5000, loss = 2.520051\n",
      "epoch : 4000/5000, loss = 2.438519\n",
      "epoch : 5000/5000, loss = 2.366710\n",
      "self.error_median=1.8738, self.error_range=1.9133\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.3653, self.error_std=1.6314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1297it [2:24:23,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('CIFAR10_4', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7585654008438818, 'aucpr': 0.20876214014808386}, fitting time: 82.94200158119202, inference time: 0.0029985904693603516\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 13.918900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.562962\n",
      "epoch : 2000/5000, loss = 3.026057\n",
      "epoch : 3000/5000, loss = 2.911638\n",
      "epoch : 4000/5000, loss = 2.799256\n",
      "epoch : 5000/5000, loss = 2.702967\n",
      "self.error_median=2.2502, self.error_range=2.0362\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.7006, self.error_std=1.6866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1321it [2:25:47,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('CIFAR10_2', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6146919831223628, 'aucpr': 0.07990251968231987}, fitting time: 83.33423638343811, inference time: 0.0029921531677246094\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 15.801096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.936172\n",
      "epoch : 2000/5000, loss = 3.294898\n",
      "epoch : 3000/5000, loss = 3.126521\n",
      "epoch : 4000/5000, loss = 3.008095\n",
      "epoch : 5000/5000, loss = 2.899316\n",
      "self.error_median=2.4093, self.error_range=2.0914\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.8947, self.error_std=1.7055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1345it [2:27:10,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('CIFAR10_1', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6363291139240507, 'aucpr': 0.08673591960923778}, fitting time: 82.90527629852295, inference time: 0.002994060516357422\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 13.845004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.413332\n",
      "epoch : 2000/5000, loss = 2.903976\n",
      "epoch : 3000/5000, loss = 2.786359\n",
      "epoch : 4000/5000, loss = 2.685121\n",
      "epoch : 5000/5000, loss = 2.596240\n",
      "self.error_median=2.1103, self.error_range=1.9906\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.5917, self.error_std=1.7186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1369it [2:28:33,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('CIFAR10_0', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7252236286919831, 'aucpr': 0.12268053701948085}, fitting time: 82.73425221443176, inference time: 0.002973794937133789\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 15.559394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.833866\n",
      "epoch : 2000/5000, loss = 3.243523\n",
      "epoch : 3000/5000, loss = 3.110820\n",
      "epoch : 4000/5000, loss = 3.002032\n",
      "epoch : 5000/5000, loss = 2.927796\n",
      "self.error_median=2.4698, self.error_range=2.0684\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.9260, self.error_std=1.6288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1393it [2:29:56,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('CIFAR10_5', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5833502109704641, 'aucpr': 0.10544971731678053}, fitting time: 82.43937015533447, inference time: 0.003961086273193359\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 17.189718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.055513\n",
      "epoch : 2000/5000, loss = 2.370087\n",
      "epoch : 3000/5000, loss = 2.124926\n",
      "epoch : 4000/5000, loss = 2.023348\n",
      "epoch : 5000/5000, loss = 1.953882\n",
      "self.error_median=1.5263, self.error_range=1.4137\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.9492, self.error_std=1.5223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1417it [2:31:19,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('SVHN_8', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6330882352941175, 'aucpr': 0.1077654459509573}, fitting time: 82.88229942321777, inference time: 0.002962827682495117\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "epoch : 1/5000, loss = 0.843094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000227\n",
      "epoch : 2000/5000, loss = 0.000205\n",
      "epoch : 3000/5000, loss = 0.000120\n",
      "epoch : 4000/5000, loss = 0.000026\n",
      "epoch : 5000/5000, loss = 0.000057\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1441it [2:32:35,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('27_PageBlocks', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8220705346985211, 'aucpr': 0.5283380530156396}, fitting time: 75.47988295555115, inference time: 0.0019948482513427734\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "epoch : 1/5000, loss = 0.835422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000700\n",
      "epoch : 2000/5000, loss = 0.000355\n",
      "epoch : 3000/5000, loss = 0.000075\n",
      "epoch : 4000/5000, loss = 0.000059\n",
      "epoch : 5000/5000, loss = 0.000069\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1442it [2:33:50,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('27_PageBlocks', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7778491601418726, 'aucpr': 0.45304070025489135}, fitting time: 74.96913027763367, inference time: 0.000997304916381836\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "epoch : 1/5000, loss = 0.849770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000364\n",
      "epoch : 2000/5000, loss = 0.000267\n",
      "epoch : 3000/5000, loss = 0.000069\n",
      "epoch : 4000/5000, loss = 0.000045\n",
      "epoch : 5000/5000, loss = 0.000032\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1443it [2:35:05,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('27_PageBlocks', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8259965647237281, 'aucpr': 0.4596793423806252}, fitting time: 75.36621928215027, inference time: 0.0009975433349609375\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "epoch : 1/5000, loss = 10.181480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.048493\n",
      "epoch : 2000/5000, loss = 0.032620\n",
      "epoch : 3000/5000, loss = 0.023701\n",
      "epoch : 4000/5000, loss = 0.019970\n",
      "epoch : 5000/5000, loss = 0.017873\n",
      "self.error_median=0.0150, self.error_range=0.0113\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0178, self.error_std=0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1465it [2:36:23,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('31_satimage-2', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8653100775193797, 'aucpr': 0.15824440072821835}, fitting time: 77.24392008781433, inference time: 0.0009622573852539062\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "epoch : 1/5000, loss = 10.297011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.056171\n",
      "epoch : 2000/5000, loss = 0.039769\n",
      "epoch : 3000/5000, loss = 0.027045\n",
      "epoch : 4000/5000, loss = 0.021666\n",
      "epoch : 5000/5000, loss = 0.019808\n",
      "self.error_median=0.0166, self.error_range=0.0121\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0198, self.error_std=0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1466it [2:37:40,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('31_satimage-2', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8679955703211517, 'aucpr': 0.15171861011323634}, fitting time: 76.56408858299255, inference time: 0.0009725093841552734\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "epoch : 1/5000, loss = 10.117304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.053663\n",
      "epoch : 2000/5000, loss = 0.037047\n",
      "epoch : 3000/5000, loss = 0.027207\n",
      "epoch : 4000/5000, loss = 0.022199\n",
      "epoch : 5000/5000, loss = 0.019120\n",
      "self.error_median=0.0162, self.error_range=0.0114\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0191, self.error_std=0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1467it [2:38:56,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('31_satimage-2', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8881782945736434, 'aucpr': 0.29267361838646305}, fitting time: 76.4788007736206, inference time: 0.0019636154174804688\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 13.756996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.862567\n",
      "epoch : 2000/5000, loss = 2.303195\n",
      "epoch : 3000/5000, loss = 2.171898\n",
      "epoch : 4000/5000, loss = 2.083455\n",
      "epoch : 5000/5000, loss = 2.007082\n",
      "self.error_median=1.5608, self.error_range=1.6742\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.0052, self.error_std=1.5934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1489it [2:40:23,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('SVHN_7', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7076723157723753, 'aucpr': 0.116092502425345}, fitting time: 86.17977714538574, inference time: 0.0029833316802978516\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 16.451010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.011328\n",
      "epoch : 2000/5000, loss = 2.319727\n",
      "epoch : 3000/5000, loss = 2.148434\n",
      "epoch : 4000/5000, loss = 2.044366\n",
      "epoch : 5000/5000, loss = 1.957265\n",
      "self.error_median=1.5119, self.error_range=1.5058\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.9507, self.error_std=1.4387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1513it [2:41:50,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('SVHN_6', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5826384849072459, 'aucpr': 0.07910293106314273}, fitting time: 86.45461893081665, inference time: 0.003989696502685547\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 19.259342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.194270\n",
      "epoch : 2000/5000, loss = 1.674759\n",
      "epoch : 3000/5000, loss = 1.503532\n",
      "epoch : 4000/5000, loss = 1.403489\n",
      "epoch : 5000/5000, loss = 1.327979\n",
      "self.error_median=0.9177, self.error_range=1.0785\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.3264, self.error_std=1.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1537it [2:43:17,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('FashionMNIST_9', 0.0, 1), model: Customized, metrics: {'aucroc': 0.949514619883041, 'aucpr': 0.453715128962358}, fitting time: 87.24763822555542, inference time: 0.0029630661010742188\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 18.416663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.455817\n",
      "epoch : 2000/5000, loss = 1.898118\n",
      "epoch : 3000/5000, loss = 1.649276\n",
      "epoch : 4000/5000, loss = 1.544468\n",
      "epoch : 5000/5000, loss = 1.471794\n",
      "self.error_median=1.0242, self.error_range=1.2366\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.4689, self.error_std=1.4160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1561it [2:44:45,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('FashionMNIST_5', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9463801169590644, 'aucpr': 0.5207533334119958}, fitting time: 87.13099193572998, inference time: 0.002992391586303711\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 18.426575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.938764\n",
      "epoch : 2000/5000, loss = 1.453240\n",
      "epoch : 3000/5000, loss = 1.272469\n",
      "epoch : 4000/5000, loss = 1.183056\n",
      "epoch : 5000/5000, loss = 1.123064\n",
      "self.error_median=0.7800, self.error_range=0.8491\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.1227, self.error_std=1.2514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1585it [2:46:14,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('FashionMNIST_7', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9653508771929825, 'aucpr': 0.6833055276849781}, fitting time: 88.45877265930176, inference time: 0.0029609203338623047\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 19.753673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.976475\n",
      "epoch : 2000/5000, loss = 2.273639\n",
      "epoch : 3000/5000, loss = 2.028406\n",
      "epoch : 4000/5000, loss = 1.878202\n",
      "epoch : 5000/5000, loss = 1.779566\n",
      "self.error_median=1.3284, self.error_range=1.7148\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.7737, self.error_std=1.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1609it [2:47:42,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('FashionMNIST_0', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8858830409356725, 'aucpr': 0.2883644242101342}, fitting time: 88.29087710380554, inference time: 0.002939939498901367\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 21.890480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.573173\n",
      "epoch : 2000/5000, loss = 1.879627\n",
      "epoch : 3000/5000, loss = 1.617362\n",
      "epoch : 4000/5000, loss = 1.479615\n",
      "epoch : 5000/5000, loss = 1.379466\n",
      "self.error_median=0.9386, self.error_range=1.1249\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.3743, self.error_std=1.4308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1633it [2:49:10,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('FashionMNIST_1', 0.0, 1), model: Customized, metrics: {'aucroc': 0.958327485380117, 'aucpr': 0.4593621762470237}, fitting time: 87.69504499435425, inference time: 0.003961086273193359\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 18.203312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.102703\n",
      "epoch : 2000/5000, loss = 2.443108\n",
      "epoch : 3000/5000, loss = 2.219910\n",
      "epoch : 4000/5000, loss = 2.098215\n",
      "epoch : 5000/5000, loss = 2.006005\n",
      "self.error_median=1.6157, self.error_range=1.6249\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.0016, self.error_std=1.3441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1657it [2:50:38,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('FashionMNIST_8', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8316783625730995, 'aucpr': 0.15327826424571098}, fitting time: 87.07267117500305, inference time: 0.0029599666595458984\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 25.312968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.112245\n",
      "epoch : 2000/5000, loss = 2.292304\n",
      "epoch : 3000/5000, loss = 2.025546\n",
      "epoch : 4000/5000, loss = 1.887199\n",
      "epoch : 5000/5000, loss = 1.793770\n",
      "self.error_median=1.3381, self.error_range=1.4798\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.7888, self.error_std=1.4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1681it [2:52:06,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('FashionMNIST_4', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8427485380116959, 'aucpr': 0.26017225978258507}, fitting time: 87.83051872253418, inference time: 0.0029900074005126953\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 24.062680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.135638\n",
      "epoch : 2000/5000, loss = 2.365059\n",
      "epoch : 3000/5000, loss = 2.067237\n",
      "epoch : 4000/5000, loss = 1.909228\n",
      "epoch : 5000/5000, loss = 1.792406\n",
      "self.error_median=1.3787, self.error_range=1.5528\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.7861, self.error_std=1.3758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1705it [2:53:34,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('FashionMNIST_2', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8572573099415204, 'aucpr': 0.19422578457866113}, fitting time: 87.42196989059448, inference time: 0.0039827823638916016\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 19.011563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.853307\n",
      "epoch : 2000/5000, loss = 2.221143\n",
      "epoch : 3000/5000, loss = 1.995168\n",
      "epoch : 4000/5000, loss = 1.869989\n",
      "epoch : 5000/5000, loss = 1.772385\n",
      "self.error_median=1.3587, self.error_range=1.4792\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.7651, self.error_std=1.3392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1729it [2:55:01,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('FashionMNIST_3', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8979766081871345, 'aucpr': 0.30555258468424973}, fitting time: 87.48190546035767, inference time: 0.003960847854614258\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 21.047587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 3.354522\n",
      "epoch : 2000/5000, loss = 2.555976\n",
      "epoch : 3000/5000, loss = 2.287025\n",
      "epoch : 4000/5000, loss = 2.128433\n",
      "epoch : 5000/5000, loss = 2.032481\n",
      "self.error_median=1.6921, self.error_range=1.6671\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=2.0246, self.error_std=1.3279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1753it [2:56:29,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('FashionMNIST_6', 0.0, 1), model: Customized, metrics: {'aucroc': 0.762748538011696, 'aucpr': 0.13260957512971244}, fitting time: 87.63287019729614, inference time: 0.00398707389831543\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "epoch : 1/5000, loss = 9.832660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.047141\n",
      "epoch : 2000/5000, loss = 0.031240\n",
      "epoch : 3000/5000, loss = 0.023600\n",
      "epoch : 4000/5000, loss = 0.019521\n",
      "epoch : 5000/5000, loss = 0.018027\n",
      "self.error_median=0.0151, self.error_range=0.0119\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0180, self.error_std=0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1777it [2:57:48,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('19_landsat', 0.0, 1), model: Customized, metrics: {'aucroc': 0.48807315480078384, 'aucpr': 0.19778855388975303}, fitting time: 78.46081256866455, inference time: 0.0019483566284179688\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "epoch : 1/5000, loss = 9.782788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.064818\n",
      "epoch : 2000/5000, loss = 0.036920\n",
      "epoch : 3000/5000, loss = 0.027557\n",
      "epoch : 4000/5000, loss = 0.022673\n",
      "epoch : 5000/5000, loss = 0.020643\n",
      "self.error_median=0.0171, self.error_range=0.0135\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0205, self.error_std=0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1778it [2:59:07,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('19_landsat', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5020770738079686, 'aucpr': 0.20954547491378356}, fitting time: 78.3822693824768, inference time: 0.0009975433349609375\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "epoch : 1/5000, loss = 9.918882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.051742\n",
      "epoch : 2000/5000, loss = 0.033038\n",
      "epoch : 3000/5000, loss = 0.024423\n",
      "epoch : 4000/5000, loss = 0.021092\n",
      "epoch : 5000/5000, loss = 0.018820\n",
      "self.error_median=0.0156, self.error_range=0.0124\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0189, self.error_std=0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1779it [3:00:25,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('19_landsat', 0.0, 3), model: Customized, metrics: {'aucroc': 0.5112524493794905, 'aucpr': 0.2081880656977047}, fitting time: 78.12553715705872, inference time: 0.0019948482513427734\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "epoch : 1/5000, loss = 9.748083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.047722\n",
      "epoch : 2000/5000, loss = 0.030330\n",
      "epoch : 3000/5000, loss = 0.024410\n",
      "epoch : 4000/5000, loss = 0.022998\n",
      "epoch : 5000/5000, loss = 0.018703\n",
      "self.error_median=0.0155, self.error_range=0.0120\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0186, self.error_std=0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1801it [3:01:44,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('30_satellite', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6076799087437386, 'aucpr': 0.4444034338188164}, fitting time: 78.9327404499054, inference time: 0.000997304916381836\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "epoch : 1/5000, loss = 9.880050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.062134\n",
      "epoch : 2000/5000, loss = 0.032404\n",
      "epoch : 3000/5000, loss = 0.027134\n",
      "epoch : 4000/5000, loss = 0.023519\n",
      "epoch : 5000/5000, loss = 0.020454\n",
      "self.error_median=0.0167, self.error_range=0.0137\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0204, self.error_std=0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1802it [3:03:03,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('30_satellite', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6004947180479095, 'aucpr': 0.43716205005483466}, fitting time: 78.17733860015869, inference time: 0.0019676685333251953\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "epoch : 1/5000, loss = 10.038908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.053032\n",
      "epoch : 2000/5000, loss = 0.035284\n",
      "epoch : 3000/5000, loss = 0.025514\n",
      "epoch : 4000/5000, loss = 0.023551\n",
      "epoch : 5000/5000, loss = 0.018580\n",
      "self.error_median=0.0156, self.error_range=0.0123\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0185, self.error_std=0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1803it [3:04:22, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('30_satellite', 0.0, 3), model: Customized, metrics: {'aucroc': 0.615405693597183, 'aucpr': 0.4552858014828785}, fitting time: 79.04447221755981, inference time: 0.000997781753540039\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "epoch : 1/5000, loss = 5.975496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.017694\n",
      "epoch : 2000/5000, loss = 0.008255\n",
      "epoch : 3000/5000, loss = 0.005448\n",
      "epoch : 4000/5000, loss = 0.004244\n",
      "epoch : 5000/5000, loss = 0.002216\n",
      "self.error_median=0.0017, self.error_range=0.0016\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0022, self.error_std=0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1825it [3:05:43,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('28_pendigits', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7455259988590505, 'aucpr': 0.06187991486676878}, fitting time: 80.43340921401978, inference time: 0.0019731521606445312\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "epoch : 1/5000, loss = 5.895151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.018359\n",
      "epoch : 2000/5000, loss = 0.010199\n",
      "epoch : 3000/5000, loss = 0.005174\n",
      "epoch : 4000/5000, loss = 0.005263\n",
      "epoch : 5000/5000, loss = 0.001723\n",
      "self.error_median=0.0011, self.error_range=0.0015\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0017, self.error_std=0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1826it [3:07:03,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('28_pendigits', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7897166642016522, 'aucpr': 0.08325029759491129}, fitting time: 80.04658126831055, inference time: 0.0019948482513427734\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "epoch : 1/5000, loss = 6.062894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.023243\n",
      "epoch : 2000/5000, loss = 0.011875\n",
      "epoch : 3000/5000, loss = 0.004444\n",
      "epoch : 4000/5000, loss = 0.002378\n",
      "epoch : 5000/5000, loss = 0.002232\n",
      "self.error_median=0.0015, self.error_range=0.0015\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0022, self.error_std=0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1827it [3:08:24, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('28_pendigits', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7260136491368929, 'aucpr': 0.06285017371654905}, fitting time: 80.46984028816223, inference time: 0.0019652843475341797\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "epoch : 1/5000, loss = 0.551483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000108\n",
      "epoch : 2000/5000, loss = 0.000153\n",
      "epoch : 3000/5000, loss = 0.000036\n",
      "epoch : 4000/5000, loss = 0.000017\n",
      "epoch : 5000/5000, loss = 0.000026\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1849it [3:09:45,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('2_annthyroid', 0.0, 1), model: Customized, metrics: {'aucroc': 0.682075, 'aucpr': 0.1715424129924319}, fitting time: 80.99042201042175, inference time: 0.0009980201721191406\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "epoch : 1/5000, loss = 0.560312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000156\n",
      "epoch : 2000/5000, loss = 0.000089\n",
      "epoch : 3000/5000, loss = 0.000067\n",
      "epoch : 4000/5000, loss = 0.000069\n",
      "epoch : 5000/5000, loss = 0.000043\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1850it [3:11:06,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('2_annthyroid', 0.0, 2), model: Customized, metrics: {'aucroc': 0.60036875, 'aucpr': 0.11876611804572422}, fitting time: 80.90862035751343, inference time: 0.0009951591491699219\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "epoch : 1/5000, loss = 0.601522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000326\n",
      "epoch : 2000/5000, loss = 0.000160\n",
      "epoch : 3000/5000, loss = 0.000120\n",
      "epoch : 4000/5000, loss = 0.000067\n",
      "epoch : 5000/5000, loss = 0.000029\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1851it [3:12:28, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('2_annthyroid', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6235031249999999, 'aucpr': 0.13858597792490968}, fitting time: 81.13946986198425, inference time: 0.0010268688201904297\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 16.516203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.747466\n",
      "epoch : 2000/5000, loss = 2.211434\n",
      "epoch : 3000/5000, loss = 1.965941\n",
      "epoch : 4000/5000, loss = 1.837836\n",
      "epoch : 5000/5000, loss = 1.752911\n",
      "self.error_median=1.3184, self.error_range=1.3677\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.7467, self.error_std=1.4190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1873it [3:14:00,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('SVHN_5', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6910456049936691, 'aucpr': 0.15276765373415396}, fitting time: 92.02899074554443, inference time: 0.003988981246948242\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "epoch : 1/5000, loss = 15.732006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.836589\n",
      "epoch : 2000/5000, loss = 1.473379\n",
      "epoch : 3000/5000, loss = 1.320181\n",
      "epoch : 4000/5000, loss = 1.191777\n",
      "epoch : 5000/5000, loss = 1.108634\n",
      "self.error_median=0.9648, self.error_range=0.8324\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.0990, self.error_std=0.5899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1897it [3:15:25,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('24_mnist', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8349520590466992, 'aucpr': 0.3943825772576758}, fitting time: 84.14147543907166, inference time: 0.0020067691802978516\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "epoch : 1/5000, loss = 15.596438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.978012\n",
      "epoch : 2000/5000, loss = 1.469290\n",
      "epoch : 3000/5000, loss = 1.339254\n",
      "epoch : 4000/5000, loss = 1.233241\n",
      "epoch : 5000/5000, loss = 1.139025\n",
      "self.error_median=0.9958, self.error_range=0.8800\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.1281, self.error_std=0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1898it [3:16:50,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('24_mnist', 0.0, 2), model: Customized, metrics: {'aucroc': 0.762557770573222, 'aucpr': 0.3360754012835722}, fitting time: 84.71650815010071, inference time: 0.001987457275390625\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "epoch : 1/5000, loss = 15.576675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.820856\n",
      "epoch : 2000/5000, loss = 1.385344\n",
      "epoch : 3000/5000, loss = 1.264542\n",
      "epoch : 4000/5000, loss = 1.179156\n",
      "epoch : 5000/5000, loss = 1.115472\n",
      "self.error_median=0.9691, self.error_range=0.8521\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.1051, self.error_std=0.5990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1899it [3:18:14, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('24_mnist', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7856154146834977, 'aucpr': 0.3138683973402661}, fitting time: 83.82348775863647, inference time: 0.001965045928955078\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "epoch : 1/5000, loss = 13.563378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.594305\n",
      "epoch : 2000/5000, loss = 2.153324\n",
      "epoch : 3000/5000, loss = 1.956269\n",
      "epoch : 4000/5000, loss = 1.854891\n",
      "epoch : 5000/5000, loss = 1.773792\n",
      "self.error_median=1.3119, self.error_range=1.5268\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.7683, self.error_std=1.5132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1921it [3:19:47,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('SVHN_4', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6025813930581969, 'aucpr': 0.07502582661123638}, fitting time: 93.26728963851929, inference time: 0.004986763000488281\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 15.426327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.589869\n",
      "epoch : 2000/5000, loss = 2.094385\n",
      "epoch : 3000/5000, loss = 1.948757\n",
      "epoch : 4000/5000, loss = 1.851794\n",
      "epoch : 5000/5000, loss = 1.751459\n",
      "self.error_median=1.3208, self.error_range=1.4115\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.7436, self.error_std=1.4361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1945it [3:21:28,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('SVHN_3', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6270939420544336, 'aucpr': 0.0758572069492115}, fitting time: 100.3766918182373, inference time: 0.003953218460083008\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 15.187682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.570653\n",
      "epoch : 2000/5000, loss = 2.081387\n",
      "epoch : 3000/5000, loss = 1.885925\n",
      "epoch : 4000/5000, loss = 1.788727\n",
      "epoch : 5000/5000, loss = 1.721901\n",
      "self.error_median=1.2981, self.error_range=1.3710\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.7159, self.error_std=1.4081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1969it [3:23:13,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('SVHN_2', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6460771929824561, 'aucpr': 0.10267059376534757}, fitting time: 104.89234113693237, inference time: 0.0049860477447509766\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 261.408732\n",
      "epoch : 1000/5000, loss = 3.401997\n",
      "epoch : 2000/5000, loss = 2.645103\n",
      "epoch : 3000/5000, loss = 2.141506\n",
      "epoch : 4000/5000, loss = 1.871489\n",
      "epoch : 5000/5000, loss = 1.741552\n",
      "self.error_median=1.5781, self.error_range=1.0204\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.7746, self.error_std=0.8572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1993it [3:25:09,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('agnews_0', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6199251461988304, 'aucpr': 0.07845620000495081}, fitting time: 114.86919641494751, inference time: 0.007950305938720703\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 261.188241\n",
      "epoch : 1000/5000, loss = 3.472321\n",
      "epoch : 2000/5000, loss = 2.478638\n",
      "epoch : 3000/5000, loss = 1.929240\n",
      "epoch : 4000/5000, loss = 1.733990\n",
      "epoch : 5000/5000, loss = 1.572342\n",
      "self.error_median=1.3960, self.error_range=0.8746\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.5714, self.error_std=0.7578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017it [3:27:04,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('agnews_1', 0.0, 1), model: Customized, metrics: {'aucroc': 0.67113216374269, 'aucpr': 0.08787519092905449}, fitting time: 114.94553685188293, inference time: 0.006985187530517578\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 259.186250\n",
      "epoch : 1000/5000, loss = 3.332604\n",
      "epoch : 2000/5000, loss = 2.229079\n",
      "epoch : 3000/5000, loss = 1.885461\n",
      "epoch : 4000/5000, loss = 1.588070\n",
      "epoch : 5000/5000, loss = 1.453432\n",
      "self.error_median=1.2132, self.error_range=0.9069\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.4231, self.error_std=0.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2041it [3:28:59,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('agnews_2', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7930900584795321, 'aucpr': 0.16556012522658164}, fitting time: 114.18486976623535, inference time: 0.0059506893157958984\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 262.155884\n",
      "epoch : 1000/5000, loss = 3.526395\n",
      "epoch : 2000/5000, loss = 2.452759\n",
      "epoch : 3000/5000, loss = 2.008432\n",
      "epoch : 4000/5000, loss = 1.779027\n",
      "epoch : 5000/5000, loss = 1.572722\n",
      "self.error_median=1.4105, self.error_range=0.9371\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.6011, self.error_std=0.7898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2065it [3:30:54,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('agnews_3', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6420982456140352, 'aucpr': 0.08832494292113971}, fitting time: 114.44366645812988, inference time: 0.007978677749633789\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 261.022250\n",
      "epoch : 1000/5000, loss = 3.347172\n",
      "epoch : 2000/5000, loss = 2.490416\n",
      "epoch : 3000/5000, loss = 2.027917\n",
      "epoch : 4000/5000, loss = 1.755956\n",
      "epoch : 5000/5000, loss = 1.625885\n",
      "self.error_median=1.4607, self.error_range=0.9091\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.6511, self.error_std=0.9824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2089it [3:32:49,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('amazon', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5823134502923976, 'aucpr': 0.061820146452227775}, fitting time: 115.03876686096191, inference time: 0.0059833526611328125\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 13.130816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.464744\n",
      "epoch : 2000/5000, loss = 2.022674\n",
      "epoch : 3000/5000, loss = 1.878575\n",
      "epoch : 4000/5000, loss = 1.775896\n",
      "epoch : 5000/5000, loss = 1.711402\n",
      "self.error_median=1.2821, self.error_range=1.5178\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.7051, self.error_std=1.4405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2113it [3:34:33,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('SVHN_1', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6536374269005848, 'aucpr': 0.07920243996934295}, fitting time: 103.74268054962158, inference time: 0.005984783172607422\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 97, 'Anomalies Ratio(%)': 0.97}\n",
      "epoch : 1/5000, loss = 2.877545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001604\n",
      "epoch : 2000/5000, loss = 0.001612\n",
      "epoch : 3000/5000, loss = 0.000696\n",
      "epoch : 4000/5000, loss = 0.000331\n",
      "epoch : 5000/5000, loss = 0.000381\n",
      "self.error_median=0.0003, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0004, self.error_std=0.0012\n",
      "Current experiment parameters: ('10_cover', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7316240903445955, 'aucpr': 0.03996609584864516}, fitting time: 88.76679396629333, inference time: 0.002977132797241211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2137it [3:36:02,  4.40s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 116, 'Anomalies Ratio(%)': 1.16}\n",
      "epoch : 1/5000, loss = 2.872643\n",
      "epoch : 1000/5000, loss = 0.002010\n",
      "epoch : 2000/5000, loss = 0.000910\n",
      "epoch : 3000/5000, loss = 0.000757\n",
      "epoch : 4000/5000, loss = 0.000591\n",
      "epoch : 5000/5000, loss = 0.000583\n",
      "self.error_median=0.0005, self.error_range=0.0003\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0006, self.error_std=0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2138it [3:37:31,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('10_cover', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6959190556492412, 'aucpr': 0.04290336018965647}, fitting time: 88.57814931869507, inference time: 0.001997232437133789\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 95, 'Anomalies Ratio(%)': 0.95}\n",
      "epoch : 1/5000, loss = 2.915452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002723\n",
      "epoch : 2000/5000, loss = 0.000944\n",
      "epoch : 3000/5000, loss = 0.000803\n",
      "epoch : 4000/5000, loss = 0.000263\n",
      "epoch : 5000/5000, loss = 0.000564\n",
      "self.error_median=0.0005, self.error_range=0.0003\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0006, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2139it [3:39:00,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('10_cover', 0.0, 3), model: Customized, metrics: {'aucroc': 0.718155162468756, 'aucpr': 0.07714765186897854}, fitting time: 89.1311194896698, inference time: 0.001001596450805664\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 23.614599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.908408\n",
      "epoch : 2000/5000, loss = 2.064884\n",
      "epoch : 3000/5000, loss = 1.876771\n",
      "epoch : 4000/5000, loss = 1.753554\n",
      "epoch : 5000/5000, loss = 1.666360\n",
      "self.error_median=1.3618, self.error_range=1.1549\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.6575, self.error_std=1.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2161it [3:40:45,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_translate', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8075906432748537, 'aucpr': 0.165254374252785}, fitting time: 104.28535985946655, inference time: 0.005973100662231445\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "epoch : 1/5000, loss = 2.915795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.004190\n",
      "epoch : 2000/5000, loss = 0.001615\n",
      "epoch : 3000/5000, loss = 0.000491\n",
      "epoch : 4000/5000, loss = 0.000482\n",
      "epoch : 5000/5000, loss = 0.000402\n",
      "self.error_median=0.0004, self.error_range=0.0004\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0004, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2185it [3:42:15,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('11_donors', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8514252796313186, 'aucpr': 0.1958896945601077}, fitting time: 89.15840220451355, inference time: 0.0020232200622558594\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 578, 'Anomalies Ratio(%)': 5.78}\n",
      "epoch : 1/5000, loss = 2.924366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.003749\n",
      "epoch : 2000/5000, loss = 0.001018\n",
      "epoch : 3000/5000, loss = 0.000383\n",
      "epoch : 4000/5000, loss = 0.000536\n",
      "epoch : 5000/5000, loss = 0.000791\n",
      "self.error_median=0.0006, self.error_range=0.0006\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0007, self.error_std=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2186it [3:43:44,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('11_donors', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8772673088365492, 'aucpr': 0.22310979758035027}, fitting time: 88.97510743141174, inference time: 0.0019884109497070312\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 597, 'Anomalies Ratio(%)': 5.97}\n",
      "epoch : 1/5000, loss = 2.975748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.003680\n",
      "epoch : 2000/5000, loss = 0.000895\n",
      "epoch : 3000/5000, loss = 0.000777\n",
      "epoch : 4000/5000, loss = 0.000333\n",
      "epoch : 5000/5000, loss = 0.000295\n",
      "self.error_median=0.0003, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2187it [3:45:14, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('11_donors', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8854639683617879, 'aucpr': 0.22371202151927497}, fitting time: 89.27086615562439, inference time: 0.001995086669921875\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "epoch : 1/5000, loss = 9.509192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.052475\n",
      "epoch : 2000/5000, loss = 0.027728\n",
      "epoch : 3000/5000, loss = 0.015692\n",
      "epoch : 4000/5000, loss = 0.011238\n",
      "epoch : 5000/5000, loss = 0.008649\n",
      "self.error_median=0.0037, self.error_range=0.0080\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0086, self.error_std=0.0224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2209it [3:46:44,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('13_fraud', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9873998664886514, 'aucpr': 0.06589635854341737}, fitting time: 89.70589303970337, inference time: 0.0029926300048828125\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "epoch : 1/5000, loss = 10.793948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.049889\n",
      "epoch : 2000/5000, loss = 0.025935\n",
      "epoch : 3000/5000, loss = 0.019820\n",
      "epoch : 4000/5000, loss = 0.013756\n",
      "epoch : 5000/5000, loss = 0.011144\n",
      "self.error_median=0.0064, self.error_range=0.0093\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0113, self.error_std=0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2210it [3:48:13,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('13_fraud', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9750918196994992, 'aucpr': 0.11940058479532165}, fitting time: 88.90879106521606, inference time: 0.0019919872283935547\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 13, 'Anomalies Ratio(%)': 0.13}\n",
      "epoch : 1/5000, loss = 9.431655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.056821\n",
      "epoch : 2000/5000, loss = 0.030314\n",
      "epoch : 3000/5000, loss = 0.019275\n",
      "epoch : 4000/5000, loss = 0.013857\n",
      "epoch : 5000/5000, loss = 0.011236\n",
      "self.error_median=0.0046, self.error_range=0.0087\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0112, self.error_std=0.0329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2211it [3:49:43, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('13_fraud', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7876335113484646, 'aucpr': 0.21289635354736425}, fitting time: 89.01802372932434, inference time: 0.001965761184692383\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 46, 'Anomalies Ratio(%)': 0.46}\n",
      "epoch : 1/5000, loss = 0.795186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000065\n",
      "epoch : 2000/5000, loss = 0.000032\n",
      "epoch : 3000/5000, loss = 0.000004\n",
      "epoch : 4000/5000, loss = 0.000007\n",
      "epoch : 5000/5000, loss = 0.000032\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2233it [3:51:12,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('16_http', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9949765572672471, 'aucpr': 0.4827586206896552}, fitting time: 88.61606431007385, inference time: 0.0019943714141845703\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 35, 'Anomalies Ratio(%)': 0.35}\n",
      "epoch : 1/5000, loss = 0.810695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000074\n",
      "epoch : 2000/5000, loss = 0.000048\n",
      "epoch : 3000/5000, loss = 0.000099\n",
      "epoch : 4000/5000, loss = 0.000005\n",
      "epoch : 5000/5000, loss = 0.000013\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2234it [3:52:41, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('16_http', 0.0, 2), model: Customized, metrics: {'aucroc': 0.37501672240802675, 'aucpr': 0.00476454771739296}, fitting time: 89.02181911468506, inference time: 0.0019958019256591797\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 34, 'Anomalies Ratio(%)': 0.34}\n",
      "epoch : 1/5000, loss = 0.799655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000024\n",
      "epoch : 2000/5000, loss = 0.000030\n",
      "epoch : 3000/5000, loss = 0.000011\n",
      "epoch : 4000/5000, loss = 0.000027\n",
      "epoch : 5000/5000, loss = 0.000001\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2235it [3:54:11, 14.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('16_http', 0.0, 3), model: Customized, metrics: {'aucroc': 0.993979933110368, 'aucpr': 0.35714285714285715}, fitting time: 88.78063201904297, inference time: 0.0009915828704833984\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 315, 'Anomalies Ratio(%)': 3.15}\n",
      "epoch : 1/5000, loss = 0.773790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.005073\n",
      "epoch : 2000/5000, loss = 0.002478\n",
      "epoch : 3000/5000, loss = 0.000976\n",
      "epoch : 4000/5000, loss = 0.000677\n",
      "epoch : 5000/5000, loss = 0.000556\n",
      "self.error_median=0.0002, self.error_range=0.0005\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0006, self.error_std=0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2257it [3:55:40,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('1_ALOI', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5673807675974872, 'aucpr': 0.04618764530305514}, fitting time: 89.36954426765442, inference time: 0.002979278564453125\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 334, 'Anomalies Ratio(%)': 3.34}\n",
      "epoch : 1/5000, loss = 0.790042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.005409\n",
      "epoch : 2000/5000, loss = 0.002562\n",
      "epoch : 3000/5000, loss = 0.001232\n",
      "epoch : 4000/5000, loss = 0.000765\n",
      "epoch : 5000/5000, loss = 0.000615\n",
      "self.error_median=0.0002, self.error_range=0.0005\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0006, self.error_std=0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2258it [3:57:10, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('1_ALOI', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5926482758620689, 'aucpr': 0.06292650351271847}, fitting time: 89.7179045677185, inference time: 0.0019953250885009766\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 332, 'Anomalies Ratio(%)': 3.32}\n",
      "epoch : 1/5000, loss = 0.803707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.007677\n",
      "epoch : 2000/5000, loss = 0.002800\n",
      "epoch : 3000/5000, loss = 0.001244\n",
      "epoch : 4000/5000, loss = 0.000797\n",
      "epoch : 5000/5000, loss = 0.000649\n",
      "self.error_median=0.0002, self.error_range=0.0006\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0006, self.error_std=0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2259it [3:58:40, 15.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('1_ALOI', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6060586206896552, 'aucpr': 0.05686454442948457}, fitting time: 89.85693621635437, inference time: 0.001964092254638672\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3548, 'Anomalies Ratio(%)': 35.48}\n",
      "epoch : 1/5000, loss = 1.645497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002352\n",
      "epoch : 2000/5000, loss = 0.000621\n",
      "epoch : 3000/5000, loss = 0.000370\n",
      "epoch : 4000/5000, loss = 0.000231\n",
      "epoch : 5000/5000, loss = 0.000391\n",
      "self.error_median=0.0003, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0004, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2281it [4:00:10,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('22_magic.gamma', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7539577087087553, 'aucpr': 0.6501121758844248}, fitting time: 89.04290914535522, inference time: 0.0009982585906982422\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3533, 'Anomalies Ratio(%)': 35.33}\n",
      "epoch : 1/5000, loss = 1.795117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002417\n",
      "epoch : 2000/5000, loss = 0.001144\n",
      "epoch : 3000/5000, loss = 0.000569\n",
      "epoch : 4000/5000, loss = 0.000245\n",
      "epoch : 5000/5000, loss = 0.000155\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2282it [4:01:39, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('22_magic.gamma', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7281569733514879, 'aucpr': 0.6170384214338744}, fitting time: 89.40773248672485, inference time: 0.001995563507080078\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3500, 'Anomalies Ratio(%)': 35.0}\n",
      "epoch : 1/5000, loss = 1.660590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.002467\n",
      "epoch : 2000/5000, loss = 0.000473\n",
      "epoch : 3000/5000, loss = 0.000553\n",
      "epoch : 4000/5000, loss = 0.000098\n",
      "epoch : 5000/5000, loss = 0.000231\n",
      "self.error_median=0.0002, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 10. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2283it [4:03:08, 15.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('22_magic.gamma', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7580595848595848, 'aucpr': 0.6631411586112952}, fitting time: 88.39180946350098, inference time: 0.001995086669921875\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 230, 'Anomalies Ratio(%)': 2.3}\n",
      "epoch : 1/5000, loss = 0.301503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000144\n",
      "epoch : 2000/5000, loss = 0.000132\n",
      "epoch : 3000/5000, loss = 0.000019\n",
      "epoch : 4000/5000, loss = 0.000017\n",
      "epoch : 5000/5000, loss = 0.000015\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2305it [4:04:37,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('23_mammography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8652089854083533, 'aucpr': 0.16042319753381926}, fitting time: 89.21618676185608, inference time: 0.0009975433349609375\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 241, 'Anomalies Ratio(%)': 2.41}\n",
      "epoch : 1/5000, loss = 0.284657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000132\n",
      "epoch : 2000/5000, loss = 0.000044\n",
      "epoch : 3000/5000, loss = 0.000062\n",
      "epoch : 4000/5000, loss = 0.000004\n",
      "epoch : 5000/5000, loss = 0.000012\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2306it [4:06:07, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('23_mammography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.836855362021858, 'aucpr': 0.17748655188427903}, fitting time: 89.03774046897888, inference time: 0.0010101795196533203\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 227, 'Anomalies Ratio(%)': 2.27}\n",
      "epoch : 1/5000, loss = 0.294388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000227\n",
      "epoch : 2000/5000, loss = 0.000020\n",
      "epoch : 3000/5000, loss = 0.000015\n",
      "epoch : 4000/5000, loss = 0.000009\n",
      "epoch : 5000/5000, loss = 0.000019\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 6. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2307it [4:07:36, 15.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('23_mammography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8381399967899847, 'aucpr': 0.1691464375326652}, fitting time: 88.8342080116272, inference time: 0.0009975433349609375\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 669, 'Anomalies Ratio(%)': 6.69}\n",
      "epoch : 1/5000, loss = 2.103518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000635\n",
      "epoch : 2000/5000, loss = 0.000578\n",
      "epoch : 3000/5000, loss = 0.000264\n",
      "epoch : 4000/5000, loss = 0.000374\n",
      "epoch : 5000/5000, loss = 0.000112\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2329it [4:09:06,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('32_shuttle', 0.0, 1), model: Customized, metrics: {'aucroc': 0.874560743975727, 'aucpr': 0.37194161235934775}, fitting time: 89.537757396698, inference time: 0.000997781753540039\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 697, 'Anomalies Ratio(%)': 6.97}\n",
      "epoch : 1/5000, loss = 1.869622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000616\n",
      "epoch : 2000/5000, loss = 0.000193\n",
      "epoch : 3000/5000, loss = 0.000112\n",
      "epoch : 4000/5000, loss = 0.000164\n",
      "epoch : 5000/5000, loss = 0.000087\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2330it [4:10:35, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('32_shuttle', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8689704947035842, 'aucpr': 0.3677137460866699}, fitting time: 88.89321327209473, inference time: 0.002025604248046875\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 714, 'Anomalies Ratio(%)': 7.14}\n",
      "epoch : 1/5000, loss = 2.067570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000542\n",
      "epoch : 2000/5000, loss = 0.000447\n",
      "epoch : 3000/5000, loss = 0.000359\n",
      "epoch : 4000/5000, loss = 0.000222\n",
      "epoch : 5000/5000, loss = 0.000153\n",
      "self.error_median=0.0001, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2331it [4:12:04, 15.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('32_shuttle', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7886327498641404, 'aucpr': 0.24861741558642175}, fitting time: 89.05270576477051, inference time: 0.002016305923461914\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2081, 'Anomalies Ratio(%)': 20.81}\n",
      "epoch : 1/5000, loss = 0.919649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000208\n",
      "epoch : 2000/5000, loss = 0.000011\n",
      "epoch : 3000/5000, loss = 0.000032\n",
      "epoch : 4000/5000, loss = 0.000026\n",
      "epoch : 5000/5000, loss = 0.000007\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2353it [4:13:33,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('33_skin', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6678240740740742, 'aucpr': 0.2837665390938417}, fitting time: 88.45340418815613, inference time: 0.0009989738464355469\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2082, 'Anomalies Ratio(%)': 20.82}\n",
      "epoch : 1/5000, loss = 0.929850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000045\n",
      "epoch : 2000/5000, loss = 0.000012\n",
      "epoch : 3000/5000, loss = 0.000033\n",
      "epoch : 4000/5000, loss = 0.000011\n",
      "epoch : 5000/5000, loss = 0.000031\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2354it [4:15:02, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('33_skin', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6423848421052631, 'aucpr': 0.3064862926428624}, fitting time: 88.56303548812866, inference time: 0.002023458480834961\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2066, 'Anomalies Ratio(%)': 20.66}\n",
      "epoch : 1/5000, loss = 0.948932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000039\n",
      "epoch : 2000/5000, loss = 0.000040\n",
      "epoch : 3000/5000, loss = 0.000103\n",
      "epoch : 4000/5000, loss = 0.000010\n",
      "epoch : 5000/5000, loss = 0.000014\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2355it [4:16:31, 15.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('33_skin', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6813228517213337, 'aucpr': 0.31362774567037266}, fitting time: 88.70086884498596, inference time: 0.0029709339141845703\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "epoch : 1/5000, loss = 0.661573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000068\n",
      "epoch : 2000/5000, loss = 0.000044\n",
      "epoch : 3000/5000, loss = 0.000021\n",
      "epoch : 4000/5000, loss = 0.000002\n",
      "epoch : 5000/5000, loss = 0.000027\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2377it [4:18:00,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('34_smtp', 0.0, 1), model: Customized, metrics: {'aucroc': 0.999666555518506, 'aucpr': 0.5}, fitting time: 88.89881825447083, inference time: 0.0019948482513427734\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "epoch : 1/5000, loss = 1.036071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000059\n",
      "epoch : 2000/5000, loss = 0.000124\n",
      "epoch : 3000/5000, loss = 0.000048\n",
      "epoch : 4000/5000, loss = 0.000015\n",
      "epoch : 5000/5000, loss = 0.000014\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2378it [4:19:28, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('34_smtp', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7322440813604535, 'aucpr': 0.0012437810945273632}, fitting time: 88.20508456230164, inference time: 0.0019953250885009766\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 5, 'Anomalies Ratio(%)': 0.05}\n",
      "epoch : 1/5000, loss = 1.171521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000222\n",
      "epoch : 2000/5000, loss = 0.000061\n",
      "epoch : 3000/5000, loss = 0.000014\n",
      "epoch : 4000/5000, loss = 0.000059\n",
      "epoch : 5000/5000, loss = 0.000009\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 3. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2379it [4:20:57, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('34_smtp', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9994996664442961, 'aucpr': 0.7}, fitting time: 88.47086572647095, inference time: 0.0020029544830322266\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 252, 'Anomalies Ratio(%)': 2.52}\n",
      "epoch : 1/5000, loss = 5.862828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.236645\n",
      "epoch : 2000/5000, loss = 0.099856\n",
      "epoch : 3000/5000, loss = 0.070695\n",
      "epoch : 4000/5000, loss = 0.056872\n",
      "epoch : 5000/5000, loss = 0.045811\n",
      "self.error_median=0.0107, self.error_range=0.0257\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0458, self.error_std=0.1432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2401it [4:22:33,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('3_backdoor', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8634710922312622, 'aucpr': 0.403093483488517}, fitting time: 95.2160153388977, inference time: 0.003983259201049805\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 246, 'Anomalies Ratio(%)': 2.46}\n",
      "epoch : 1/5000, loss = 5.773275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.205600\n",
      "epoch : 2000/5000, loss = 0.087817\n",
      "epoch : 3000/5000, loss = 0.061602\n",
      "epoch : 4000/5000, loss = 0.050097\n",
      "epoch : 5000/5000, loss = 0.043064\n",
      "self.error_median=0.0103, self.error_range=0.0222\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0431, self.error_std=0.1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2402it [4:24:09, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('3_backdoor', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8500027710554026, 'aucpr': 0.4940134054693272}, fitting time: 95.84187746047974, inference time: 0.003995180130004883\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 256, 'Anomalies Ratio(%)': 2.56}\n",
      "epoch : 1/5000, loss = 5.902673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.288964\n",
      "epoch : 2000/5000, loss = 0.129528\n",
      "epoch : 3000/5000, loss = 0.084896\n",
      "epoch : 4000/5000, loss = 0.067919\n",
      "epoch : 5000/5000, loss = 0.056112\n",
      "self.error_median=0.0144, self.error_range=0.0360\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0560, self.error_std=0.1592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2403it [4:25:45, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('3_backdoor', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8738131522941649, 'aucpr': 0.3889672401221671}, fitting time: 94.96751236915588, inference time: 0.002992868423461914\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1134, 'Anomalies Ratio(%)': 11.34}\n",
      "epoch : 1/5000, loss = 13.064607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.664075\n",
      "epoch : 2000/5000, loss = 1.355299\n",
      "epoch : 3000/5000, loss = 1.128605\n",
      "epoch : 4000/5000, loss = 0.974194\n",
      "epoch : 5000/5000, loss = 0.853375\n",
      "self.error_median=0.6947, self.error_range=1.2270\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.8416, self.error_std=0.6960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2425it [4:27:15,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('5_campaign', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6955252100840336, 'aucpr': 0.2610657496972958}, fitting time: 89.86486077308655, inference time: 0.001994609832763672\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "epoch : 1/5000, loss = 13.100393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.737417\n",
      "epoch : 2000/5000, loss = 1.313093\n",
      "epoch : 3000/5000, loss = 1.154347\n",
      "epoch : 4000/5000, loss = 1.005256\n",
      "epoch : 5000/5000, loss = 0.931067\n",
      "self.error_median=0.6745, self.error_range=1.3487\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.9215, self.error_std=0.8191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2426it [4:28:45, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('5_campaign', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6532820296226828, 'aucpr': 0.1918757334300887}, fitting time: 89.73181223869324, inference time: 0.002017974853515625\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "epoch : 1/5000, loss = 13.216148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.892774\n",
      "epoch : 2000/5000, loss = 1.457316\n",
      "epoch : 3000/5000, loss = 1.187327\n",
      "epoch : 4000/5000, loss = 1.049011\n",
      "epoch : 5000/5000, loss = 0.964998\n",
      "self.error_median=0.8549, self.error_range=1.3269\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.9536, self.error_std=0.7258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2427it [4:30:15, 16.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('5_campaign', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6570034331804643, 'aucpr': 0.21489614127456408}, fitting time: 89.6952314376831, inference time: 0.0020248889923095703\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 222, 'Anomalies Ratio(%)': 2.22}\n",
      "epoch : 1/5000, loss = 29.786468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.549483\n",
      "epoch : 2000/5000, loss = 1.148950\n",
      "epoch : 3000/5000, loss = 0.965232\n",
      "epoch : 4000/5000, loss = 0.827503\n",
      "epoch : 5000/5000, loss = 0.716147\n",
      "self.error_median=0.5388, self.error_range=0.9184\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.6971, self.error_std=0.5680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2449it [4:31:45,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('8_celeba', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7349206914625644, 'aucpr': 0.05374388120227892}, fitting time: 89.06375312805176, inference time: 0.0019943714141845703\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 238, 'Anomalies Ratio(%)': 2.38}\n",
      "epoch : 1/5000, loss = 30.137690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.728018\n",
      "epoch : 2000/5000, loss = 1.380117\n",
      "epoch : 3000/5000, loss = 1.179968\n",
      "epoch : 4000/5000, loss = 0.987947\n",
      "epoch : 5000/5000, loss = 0.847745\n",
      "self.error_median=0.7076, self.error_range=1.0336\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.8363, self.error_std=0.6162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2450it [4:33:14, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('8_celeba', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6545064171302997, 'aucpr': 0.04510053603762326}, fitting time: 89.44635844230652, inference time: 0.0019659996032714844\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 216, 'Anomalies Ratio(%)': 2.16}\n",
      "epoch : 1/5000, loss = 30.190085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 1.620876\n",
      "epoch : 2000/5000, loss = 1.366679\n",
      "epoch : 3000/5000, loss = 1.209792\n",
      "epoch : 4000/5000, loss = 1.076184\n",
      "epoch : 5000/5000, loss = 0.950319\n",
      "self.error_median=0.8139, self.error_range=1.1358\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.9408, self.error_std=0.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2451it [4:34:44, 15.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('8_celeba', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6755444895819683, 'aucpr': 0.03950855731192111}, fitting time: 89.07324290275574, inference time: 0.0019600391387939453\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "epoch : 1/5000, loss = 32.900445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 5.795941\n",
      "epoch : 2000/5000, loss = 4.886744\n",
      "epoch : 3000/5000, loss = 4.553833\n",
      "epoch : 4000/5000, loss = 4.320299\n",
      "epoch : 5000/5000, loss = 4.134952\n",
      "self.error_median=3.9056, self.error_range=5.1683\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=4.1242, self.error_std=2.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2473it [4:36:30,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('9_census', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6963045461091643, 'aucpr': 0.09774037530022053}, fitting time: 104.39736843109131, inference time: 0.00598454475402832\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 628, 'Anomalies Ratio(%)': 6.28}\n",
      "epoch : 1/5000, loss = 32.973263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 5.822273\n",
      "epoch : 2000/5000, loss = 4.847386\n",
      "epoch : 3000/5000, loss = 4.420030\n",
      "epoch : 4000/5000, loss = 4.147519\n",
      "epoch : 5000/5000, loss = 3.955506\n",
      "self.error_median=3.6693, self.error_range=5.0485\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=3.9441, self.error_std=2.9637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2474it [4:38:17, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('9_census', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6755981205169335, 'aucpr': 0.09605314073956428}, fitting time: 104.31022214889526, inference time: 0.004986286163330078\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 652, 'Anomalies Ratio(%)': 6.52}\n",
      "epoch : 1/5000, loss = 32.707508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 5.839615\n",
      "epoch : 2000/5000, loss = 4.935468\n",
      "epoch : 3000/5000, loss = 4.470770\n",
      "epoch : 4000/5000, loss = 4.190683\n",
      "epoch : 5000/5000, loss = 4.014324\n",
      "self.error_median=3.8585, self.error_range=5.0902\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=4.0046, self.error_std=2.9072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2475it [4:40:03, 17.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('9_census', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6844376837753647, 'aucpr': 0.09875282909718011}, fitting time: 103.5590238571167, inference time: 0.0049571990966796875\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 22.900914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.711134\n",
      "epoch : 2000/5000, loss = 2.018008\n",
      "epoch : 3000/5000, loss = 1.817135\n",
      "epoch : 4000/5000, loss = 1.718678\n",
      "epoch : 5000/5000, loss = 1.650274\n",
      "self.error_median=1.3228, self.error_range=1.1436\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.6419, self.error_std=1.0898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2497it [4:41:47,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_zigzag', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9068070175438596, 'aucpr': 0.312154249718666}, fitting time: 103.79996752738953, inference time: 0.00598454475402832\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 254.696893\n",
      "epoch : 1000/5000, loss = 3.491797\n",
      "epoch : 2000/5000, loss = 2.301768\n",
      "epoch : 3000/5000, loss = 2.011898\n",
      "epoch : 4000/5000, loss = 1.694594\n",
      "epoch : 5000/5000, loss = 1.473161\n",
      "self.error_median=1.3153, self.error_range=0.8612\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.5113, self.error_std=0.8118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2521it [4:43:42,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('imdb', 0.0, 1), model: Customized, metrics: {'aucroc': 0.498425730994152, 'aucpr': 0.04716699702107617}, fitting time: 115.01169395446777, inference time: 0.007016181945800781\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 23.141046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.675495\n",
      "epoch : 2000/5000, loss = 1.968770\n",
      "epoch : 3000/5000, loss = 1.720393\n",
      "epoch : 4000/5000, loss = 1.623952\n",
      "epoch : 5000/5000, loss = 1.551058\n",
      "self.error_median=1.2843, self.error_range=1.0843\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.5445, self.error_std=0.9557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2545it [4:45:27,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_canny_edges', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7937777777777777, 'aucpr': 0.1287246979950849}, fitting time: 104.16841197013855, inference time: 0.004987478256225586\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 22.913388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.563079\n",
      "epoch : 2000/5000, loss = 1.919689\n",
      "epoch : 3000/5000, loss = 1.729368\n",
      "epoch : 4000/5000, loss = 1.621674\n",
      "epoch : 5000/5000, loss = 1.553268\n",
      "self.error_median=1.2573, self.error_range=1.0889\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.5457, self.error_std=1.0219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2569it [4:47:11,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_dotted_line', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8697707602339182, 'aucpr': 0.27311200943172337}, fitting time: 104.05381178855896, inference time: 0.004981517791748047\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 22.996935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.587228\n",
      "epoch : 2000/5000, loss = 1.909917\n",
      "epoch : 3000/5000, loss = 1.719294\n",
      "epoch : 4000/5000, loss = 1.618162\n",
      "epoch : 5000/5000, loss = 1.540526\n",
      "self.error_median=1.2736, self.error_range=1.0856\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.5342, self.error_std=0.9422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2593it [4:48:56,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_fog', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8027859649122806, 'aucpr': 0.15137014170399252}, fitting time: 104.74813961982727, inference time: 0.0049555301666259766\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 23.222958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.712299\n",
      "epoch : 2000/5000, loss = 1.938849\n",
      "epoch : 3000/5000, loss = 1.735573\n",
      "epoch : 4000/5000, loss = 1.622026\n",
      "epoch : 5000/5000, loss = 1.533300\n",
      "self.error_median=1.2340, self.error_range=1.0714\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.5272, self.error_std=0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2617it [4:50:41,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_glass_blur', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9208233918128657, 'aucpr': 0.3024805643853775}, fitting time: 104.26346206665039, inference time: 0.004982709884643555\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 23.865052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.941697\n",
      "epoch : 2000/5000, loss = 2.070563\n",
      "epoch : 3000/5000, loss = 1.833019\n",
      "epoch : 4000/5000, loss = 1.706536\n",
      "epoch : 5000/5000, loss = 1.616164\n",
      "self.error_median=1.3497, self.error_range=1.0974\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.6094, self.error_std=0.9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2641it [4:52:25,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_identity', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5199005847953216, 'aucpr': 0.05126713755008387}, fitting time: 103.9936990737915, inference time: 0.0049855709075927734\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 22.832173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.466295\n",
      "epoch : 2000/5000, loss = 1.904859\n",
      "epoch : 3000/5000, loss = 1.687489\n",
      "epoch : 4000/5000, loss = 1.586244\n",
      "epoch : 5000/5000, loss = 1.511707\n",
      "self.error_median=1.2277, self.error_range=1.0871\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.5055, self.error_std=0.9792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2665it [4:54:10,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_impulse_noise', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8719812865497076, 'aucpr': 0.26180087613352865}, fitting time: 104.67697477340698, inference time: 0.00498652458190918\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 23.264683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.901284\n",
      "epoch : 2000/5000, loss = 2.102192\n",
      "epoch : 3000/5000, loss = 1.868706\n",
      "epoch : 4000/5000, loss = 1.724028\n",
      "epoch : 5000/5000, loss = 1.612183\n",
      "self.error_median=1.3082, self.error_range=1.1298\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.6064, self.error_std=1.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2689it [4:55:55,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_motion_blur', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8816070175438596, 'aucpr': 0.2657294100383734}, fitting time: 103.9079065322876, inference time: 0.00498652458190918\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 23.851667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.811371\n",
      "epoch : 2000/5000, loss = 2.001046\n",
      "epoch : 3000/5000, loss = 1.793384\n",
      "epoch : 4000/5000, loss = 1.684070\n",
      "epoch : 5000/5000, loss = 1.609890\n",
      "self.error_median=1.3336, self.error_range=1.1041\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.6029, self.error_std=0.9541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2713it [4:57:39,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_rotate', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6328350877192983, 'aucpr': 0.07308406836742737}, fitting time: 104.34157705307007, inference time: 0.00495600700378418\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 23.563626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.779564\n",
      "epoch : 2000/5000, loss = 2.033511\n",
      "epoch : 3000/5000, loss = 1.816644\n",
      "epoch : 4000/5000, loss = 1.698006\n",
      "epoch : 5000/5000, loss = 1.611507\n",
      "self.error_median=1.3374, self.error_range=1.0806\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.6049, self.error_std=0.9655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2737it [4:59:25,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_scale', 0.0, 1), model: Customized, metrics: {'aucroc': 0.5982970760233918, 'aucpr': 0.06265922934738871}, fitting time: 105.2793972492218, inference time: 0.004986286163330078\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 23.471513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.647395\n",
      "epoch : 2000/5000, loss = 2.049973\n",
      "epoch : 3000/5000, loss = 1.853836\n",
      "epoch : 4000/5000, loss = 1.718783\n",
      "epoch : 5000/5000, loss = 1.620400\n",
      "self.error_median=1.3374, self.error_range=1.1118\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.6130, self.error_std=0.9741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2761it [5:01:10,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_shear', 0.0, 1), model: Customized, metrics: {'aucroc': 0.75413567251462, 'aucpr': 0.17471290200573775}, fitting time: 104.16339468955994, inference time: 0.004986286163330078\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 23.322023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.884077\n",
      "epoch : 2000/5000, loss = 2.024747\n",
      "epoch : 3000/5000, loss = 1.811962\n",
      "epoch : 4000/5000, loss = 1.698682\n",
      "epoch : 5000/5000, loss = 1.617945\n",
      "self.error_median=1.3290, self.error_range=1.1537\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.6105, self.error_std=0.9943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2785it [5:02:54,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_shot_noise', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8271087719298246, 'aucpr': 0.19403271829578447}, fitting time: 104.3404221534729, inference time: 0.00498652458190918\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 22.858147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.604992\n",
      "epoch : 2000/5000, loss = 1.934982\n",
      "epoch : 3000/5000, loss = 1.709376\n",
      "epoch : 4000/5000, loss = 1.592641\n",
      "epoch : 5000/5000, loss = 1.519060\n",
      "self.error_median=1.2242, self.error_range=1.0720\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.5132, self.error_std=0.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2809it [5:04:40,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_spatter', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8492187134502924, 'aucpr': 0.2647028700268281}, fitting time: 105.12996888160706, inference time: 0.004985809326171875\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 22.385015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.742681\n",
      "epoch : 2000/5000, loss = 2.024004\n",
      "epoch : 3000/5000, loss = 1.727104\n",
      "epoch : 4000/5000, loss = 1.578117\n",
      "epoch : 5000/5000, loss = 1.492282\n",
      "self.error_median=1.1997, self.error_range=1.0517\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.4856, self.error_std=0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2833it [5:06:25,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_stripe', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9234058479532165, 'aucpr': 0.3519921812940652}, fitting time: 104.34539771080017, inference time: 0.004987478256225586\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "epoch : 1/5000, loss = 23.454656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 2.623284\n",
      "epoch : 2000/5000, loss = 1.929855\n",
      "epoch : 3000/5000, loss = 1.733728\n",
      "epoch : 4000/5000, loss = 1.636886\n",
      "epoch : 5000/5000, loss = 1.561950\n",
      "self.error_median=1.3004, self.error_range=1.0830\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.5552, self.error_std=0.9477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2857it [5:08:10,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('MNIST-C_brightness', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7773380116959066, 'aucpr': 0.132845045095667}, fitting time: 105.25012755393982, inference time: 0.004986763000488281\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 249.841661\n",
      "epoch : 1000/5000, loss = 3.714405\n",
      "epoch : 2000/5000, loss = 2.778218\n",
      "epoch : 3000/5000, loss = 2.283553\n",
      "epoch : 4000/5000, loss = 1.967189\n",
      "epoch : 5000/5000, loss = 1.774168\n",
      "self.error_median=1.6135, self.error_range=0.9708\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=1.7841, self.error_std=0.9049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2904it [5:10:05,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('yelp', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6800982456140352, 'aucpr': 0.08700561950242068}, fitting time: 114.87469005584717, inference time: 0.005951642990112305\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 97, 'Anomalies Ratio(%)': 0.97}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 116, 'Anomalies Ratio(%)': 1.16}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 95, 'Anomalies Ratio(%)': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 578, 'Anomalies Ratio(%)': 5.78}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 597, 'Anomalies Ratio(%)': 5.97}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 1941, 'Features': 27, 'Anomalies': 673, 'Anomalies Ratio(%)': 34.67}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 13, 'Anomalies Ratio(%)': 0.13}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 42, 'Anomalies Ratio(%)': 4.2}\n",
      "{'Samples': 1000, 'Features': 7, 'Anomalies': 34, 'Anomalies Ratio(%)': 3.4}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 170, 'Anomalies Ratio(%)': 17.0}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 139, 'Anomalies Ratio(%)': 13.9}\n",
      "{'Samples': 1000, 'Features': 19, 'Anomalies': 169, 'Anomalies Ratio(%)': 16.9}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 46, 'Anomalies Ratio(%)': 0.46}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 35, 'Anomalies Ratio(%)': 0.35}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 34, 'Anomalies Ratio(%)': 0.34}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1966, 'Features': 1555, 'Anomalies': 368, 'Anomalies Ratio(%)': 18.72}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 369, 'Anomalies Ratio(%)': 36.9}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 374, 'Anomalies Ratio(%)': 37.4}\n",
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 349, 'Anomalies Ratio(%)': 34.9}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 1333, 'Anomalies Ratio(%)': 20.71}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 315, 'Anomalies Ratio(%)': 3.15}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 334, 'Anomalies Ratio(%)': 3.34}\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 332, 'Anomalies Ratio(%)': 3.32}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1600, 'Features': 32, 'Anomalies': 100, 'Anomalies Ratio(%)': 6.25}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 38, 'Anomalies Ratio(%)': 3.8}\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 43, 'Anomalies Ratio(%)': 4.3}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3548, 'Anomalies Ratio(%)': 35.48}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3533, 'Anomalies Ratio(%)': 35.33}\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3500, 'Anomalies Ratio(%)': 35.0}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 230, 'Anomalies Ratio(%)': 2.3}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 241, 'Anomalies Ratio(%)': 2.41}\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 227, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5216, 'Features': 64, 'Anomalies': 150, 'Anomalies Ratio(%)': 2.88}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 5393, 'Features': 10, 'Anomalies': 510, 'Anomalies Ratio(%)': 9.46}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 6870, 'Features': 16, 'Anomalies': 156, 'Anomalies Ratio(%)': 2.27}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 367, 'Anomalies Ratio(%)': 36.7}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 346, 'Anomalies Ratio(%)': 34.6}\n",
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 6435, 'Features': 36, 'Anomalies': 2036, 'Anomalies Ratio(%)': 31.64}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 5803, 'Features': 36, 'Anomalies': 71, 'Anomalies Ratio(%)': 1.22}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 669, 'Anomalies Ratio(%)': 6.69}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 697, 'Anomalies Ratio(%)': 6.97}\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 714, 'Anomalies Ratio(%)': 7.14}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2081, 'Anomalies Ratio(%)': 20.81}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2082, 'Anomalies Ratio(%)': 20.82}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2066, 'Anomalies Ratio(%)': 20.66}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 5, 'Anomalies Ratio(%)': 0.05}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 4207, 'Features': 57, 'Anomalies': 1679, 'Anomalies Ratio(%)': 39.91}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 3686, 'Features': 400, 'Anomalies': 61, 'Anomalies Ratio(%)': 1.65}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 90, 'Anomalies Ratio(%)': 9.0}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 95, 'Anomalies Ratio(%)': 9.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 100, 'Anomalies Ratio(%)': 10.0}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 123, 'Anomalies Ratio(%)': 12.3}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "{'Samples': 1000, 'Features': 6, 'Anomalies': 133, 'Anomalies Ratio(%)': 13.3}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 252, 'Anomalies Ratio(%)': 2.52}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 246, 'Anomalies Ratio(%)': 2.46}\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 256, 'Anomalies Ratio(%)': 2.56}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 3443, 'Features': 21, 'Anomalies': 100, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 35, 'Anomalies Ratio(%)': 3.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 45, 'Anomalies Ratio(%)': 4.5}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 48, 'Anomalies Ratio(%)': 4.8}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 26, 'Anomalies Ratio(%)': 2.6}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 29, 'Anomalies Ratio(%)': 2.9}\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 27, 'Anomalies Ratio(%)': 2.7}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 4819, 'Features': 5, 'Anomalies': 257, 'Anomalies Ratio(%)': 5.33}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 75, 'Anomalies Ratio(%)': 7.5}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 80, 'Anomalies Ratio(%)': 8.0}\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 88, 'Anomalies Ratio(%)': 8.8}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 239, 'Anomalies Ratio(%)': 23.9}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 224, 'Anomalies Ratio(%)': 22.4}\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 225, 'Anomalies Ratio(%)': 22.5}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1484, 'Features': 8, 'Anomalies': 507, 'Anomalies Ratio(%)': 34.16}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 348, 'Anomalies Ratio(%)': 34.8}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 336, 'Anomalies Ratio(%)': 33.6}\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 364, 'Anomalies Ratio(%)': 36.4}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1134, 'Anomalies Ratio(%)': 11.34}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 2114, 'Features': 21, 'Anomalies': 466, 'Anomalies Ratio(%)': 22.04}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 222, 'Anomalies Ratio(%)': 2.22}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 238, 'Anomalies Ratio(%)': 2.38}\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 216, 'Anomalies Ratio(%)': 2.16}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 628, 'Anomalies Ratio(%)': 6.28}\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 652, 'Anomalies Ratio(%)': 6.52}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 5263, 'Features': 512, 'Anomalies': 263, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6315, 'Features': 512, 'Anomalies': 315, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 215, 'Anomalies Ratio(%)': 21.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 215, 'Anomalies Ratio(%)': 21.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 198, 'Anomalies Ratio(%)': 19.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 251, 'Anomalies Ratio(%)': 25.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 242, 'Anomalies Ratio(%)': 24.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 242, 'Anomalies Ratio(%)': 24.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 308, 'Anomalies Ratio(%)': 30.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 304, 'Anomalies Ratio(%)': 30.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 29.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 254, 'Anomalies Ratio(%)': 25.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 227, 'Anomalies Ratio(%)': 22.7}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 213, 'Anomalies Ratio(%)': 21.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 180, 'Anomalies Ratio(%)': 18.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 169, 'Anomalies Ratio(%)': 16.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 174, 'Anomalies Ratio(%)': 17.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 138, 'Anomalies Ratio(%)': 13.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 160, 'Anomalies Ratio(%)': 16.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 142, 'Anomalies Ratio(%)': 14.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 259, 'Anomalies Ratio(%)': 25.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 273, 'Anomalies Ratio(%)': 27.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 246, 'Anomalies Ratio(%)': 24.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 284, 'Anomalies Ratio(%)': 28.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 283, 'Anomalies Ratio(%)': 28.3}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 281, 'Anomalies Ratio(%)': 28.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 314, 'Anomalies Ratio(%)': 31.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 300, 'Anomalies Ratio(%)': 30.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 326, 'Anomalies Ratio(%)': 32.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 240, 'Anomalies Ratio(%)': 24.0}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 244, 'Anomalies Ratio(%)': 24.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 266, 'Anomalies Ratio(%)': 26.6}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 227, 'Anomalies Ratio(%)': 22.7}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 231, 'Anomalies Ratio(%)': 23.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 252, 'Anomalies Ratio(%)': 25.2}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 271, 'Anomalies Ratio(%)': 27.1}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 285, 'Anomalies Ratio(%)': 28.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 288, 'Anomalies Ratio(%)': 28.8}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 115, 'Anomalies Ratio(%)': 11.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 135, 'Anomalies Ratio(%)': 13.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 114, 'Anomalies Ratio(%)': 11.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 184, 'Anomalies Ratio(%)': 18.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 189, 'Anomalies Ratio(%)': 18.9}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 175, 'Anomalies Ratio(%)': 17.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 305, 'Anomalies Ratio(%)': 30.5}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 304, 'Anomalies Ratio(%)': 30.4}\n",
      "{'Samples': 1000, 'Features': 512, 'Anomalies': 320, 'Anomalies Ratio(%)': 32.0}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5208, 'Features': 512, 'Anomalies': 260, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 8944, 'Features': 512, 'Anomalies': 447, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7850, 'Features': 512, 'Anomalies': 392, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 7244, 'Features': 512, 'Anomalies': 362, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 6028, 'Features': 512, 'Anomalies': 301, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5889, 'Features': 512, 'Anomalies': 294, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 5310, 'Features': 512, 'Anomalies': 265, 'Anomalies Ratio(%)': 4.99}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 4904, 'Features': 512, 'Anomalies': 245, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 3090, 'Features': 768, 'Anomalies': 154, 'Anomalies Ratio(%)': 4.98}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2514, 'Features': 768, 'Anomalies': 125, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 2497, 'Features': 768, 'Anomalies': 124, 'Anomalies Ratio(%)': 4.97}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 40, 'Anomalies Ratio(%)': 4.0}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1000, 'Features': 768, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1657, 'Features': 768, 'Anomalies': 82, 'Anomalies Ratio(%)': 4.95}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 1532, 'Features': 768, 'Anomalies': 76, 'Anomalies Ratio(%)': 4.96}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 90, 'Anomalies Ratio(%)': 9.0}\n",
      "epoch : 1/5000, loss = 1.958407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001413\n",
      "epoch : 2000/5000, loss = 0.000199\n",
      "epoch : 3000/5000, loss = 0.000600\n",
      "epoch : 4000/5000, loss = 0.000181\n",
      "epoch : 5000/5000, loss = 0.000058\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:21, 81.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8428978428978429, 'aucpr': 0.5498692721608527}, fitting time: 81.0499529838562, inference time: 0.001995086669921875\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 95, 'Anomalies Ratio(%)': 9.5}\n",
      "epoch : 1/5000, loss = 2.249891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.004299\n",
      "epoch : 2000/5000, loss = 0.000736\n",
      "epoch : 3000/5000, loss = 0.000327\n",
      "epoch : 4000/5000, loss = 0.000381\n",
      "epoch : 5000/5000, loss = 0.000293\n",
      "self.error_median=0.0002, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0003\n",
      "Current experiment parameters: ('37_Stamps', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9042804621848739, 'aucpr': 0.6271190095764565}, fitting time: 90.53966641426086, inference time: 0.0010271072387695312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [02:52, 87.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 100, 'Anomalies Ratio(%)': 10.0}\n",
      "epoch : 1/5000, loss = 1.770889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.001396\n",
      "epoch : 2000/5000, loss = 0.000532\n",
      "epoch : 3000/5000, loss = 0.000390\n",
      "epoch : 4000/5000, loss = 0.000083\n",
      "epoch : 5000/5000, loss = 0.000237\n",
      "self.error_median=0.0002, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0002, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [04:21, 88.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('37_Stamps', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7914814814814816, 'aucpr': 0.5479587276073409}, fitting time: 88.35427737236023, inference time: 0.001994609832763672\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 26, 'Anomalies Ratio(%)': 2.6}\n",
      "epoch : 1/5000, loss = 7.351978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.050468\n",
      "epoch : 2000/5000, loss = 0.035772\n",
      "epoch : 3000/5000, loss = 0.021108\n",
      "epoch : 4000/5000, loss = 0.014379\n",
      "epoch : 5000/5000, loss = 0.010871\n",
      "self.error_median=0.0096, self.error_range=0.0071\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0108, self.error_std=0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [05:51,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9970034246575342, 'aucpr': 0.8644345238095238}, fitting time: 89.25497603416443, inference time: 0.0009970664978027344\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 29, 'Anomalies Ratio(%)': 2.9}\n",
      "epoch : 1/5000, loss = 7.304299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.042892\n",
      "epoch : 2000/5000, loss = 0.021118\n",
      "epoch : 3000/5000, loss = 0.014065\n",
      "epoch : 4000/5000, loss = 0.011744\n",
      "epoch : 5000/5000, loss = 0.009352\n",
      "self.error_median=0.0076, self.error_range=0.0064\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0093, self.error_std=0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [07:22, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9969453990072547, 'aucpr': 0.9182098765432101}, fitting time: 90.04060626029968, inference time: 0.0009984970092773438\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 27, 'Anomalies Ratio(%)': 2.7}\n",
      "epoch : 1/5000, loss = 8.274907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.060541\n",
      "epoch : 2000/5000, loss = 0.033232\n",
      "epoch : 3000/5000, loss = 0.020786\n",
      "epoch : 4000/5000, loss = 0.014628\n",
      "epoch : 5000/5000, loss = 0.011545\n",
      "self.error_median=0.0097, self.error_range=0.0089\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0115, self.error_std=0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [08:52, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('43_WDBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9867294520547945, 'aucpr': 0.6407679738562091}, fitting time: 89.29871273040771, inference time: 0.001994609832763672\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 35, 'Anomalies Ratio(%)': 3.5}\n",
      "epoch : 1/5000, loss = 1.775752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000550\n",
      "epoch : 2000/5000, loss = 0.000786\n",
      "epoch : 3000/5000, loss = 0.000339\n",
      "epoch : 4000/5000, loss = 0.000202\n",
      "epoch : 5000/5000, loss = 0.000256\n",
      "self.error_median=0.0002, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [10:21,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7596551724137932, 'aucpr': 0.327046101260872}, fitting time: 88.89657402038574, inference time: 0.0010273456573486328\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 45, 'Anomalies Ratio(%)': 4.5}\n",
      "epoch : 1/5000, loss = 1.503768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000693\n",
      "epoch : 2000/5000, loss = 0.000211\n",
      "epoch : 3000/5000, loss = 0.000226\n",
      "epoch : 4000/5000, loss = 0.000106\n",
      "epoch : 5000/5000, loss = 0.000051\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [11:50, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9595404595404595, 'aucpr': 0.5631720688949604}, fitting time: 88.6027569770813, inference time: 0.002022981643676758\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 48, 'Anomalies Ratio(%)': 4.8}\n",
      "epoch : 1/5000, loss = 0.979097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000489\n",
      "epoch : 2000/5000, loss = 0.000173\n",
      "epoch : 3000/5000, loss = 0.000220\n",
      "epoch : 4000/5000, loss = 0.000207\n",
      "epoch : 5000/5000, loss = 0.000102\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [13:20, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('42_WBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8681318681318682, 'aucpr': 0.5449326752282719}, fitting time: 88.74607539176941, inference time: 0.0009968280792236328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 239, 'Anomalies Ratio(%)': 23.9}\n",
      "epoch : 1/5000, loss = 8.718847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.062933\n",
      "epoch : 2000/5000, loss = 0.037276\n",
      "epoch : 3000/5000, loss = 0.025135\n",
      "epoch : 4000/5000, loss = 0.018802\n",
      "epoch : 5000/5000, loss = 0.013943\n",
      "self.error_median=0.0082, self.error_range=0.0152\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0138, self.error_std=0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [14:49,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9323221247563354, 'aucpr': 0.8164747906978096}, fitting time: 89.24724459648132, inference time: 0.0009963512420654297\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 224, 'Anomalies Ratio(%)': 22.4}\n",
      "epoch : 1/5000, loss = 6.802567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.066104\n",
      "epoch : 2000/5000, loss = 0.035024\n",
      "epoch : 3000/5000, loss = 0.024447\n",
      "epoch : 4000/5000, loss = 0.019404\n",
      "epoch : 5000/5000, loss = 0.016757\n",
      "self.error_median=0.0112, self.error_range=0.0172\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0168, self.error_std=0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [16:19, 11.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('46_WPBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9579142912049196, 'aucpr': 0.8815162943754444}, fitting time: 88.91721153259277, inference time: 0.0009987354278564453\n",
      "{'Samples': 1000, 'Features': 33, 'Anomalies': 225, 'Anomalies Ratio(%)': 22.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/5000, loss = 7.510474\n",
      "epoch : 1000/5000, loss = 0.054429\n",
      "epoch : 2000/5000, loss = 0.031412\n",
      "epoch : 3000/5000, loss = 0.022665\n",
      "epoch : 4000/5000, loss = 0.016621\n",
      "epoch : 5000/5000, loss = 0.013002\n",
      "self.error_median=0.0083, self.error_range=0.0135\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0130, self.error_std=0.0127\n",
      "Current experiment parameters: ('46_WPBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9462474645030425, 'aucpr': 0.8420804108692199}, fitting time: 88.46025800704956, inference time: 0.000997304916381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [17:48, 16.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "epoch : 1/5000, loss = 3.944116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.020241\n",
      "epoch : 2000/5000, loss = 0.009155\n",
      "epoch : 3000/5000, loss = 0.002171\n",
      "epoch : 4000/5000, loss = 0.002196\n",
      "epoch : 5000/5000, loss = 0.002197\n",
      "self.error_median=0.0019, self.error_range=0.0009\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0021, self.error_std=0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [19:16,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9252211203430716, 'aucpr': 0.5805589809888452}, fitting time: 88.10109615325928, inference time: 0.0009961128234863281\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 38, 'Anomalies Ratio(%)': 3.8}\n",
      "epoch : 1/5000, loss = 4.120946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.023111\n",
      "epoch : 2000/5000, loss = 0.007284\n",
      "epoch : 3000/5000, loss = 0.004691\n",
      "epoch : 4000/5000, loss = 0.001842\n",
      "epoch : 5000/5000, loss = 0.001732\n",
      "self.error_median=0.0015, self.error_range=0.0009\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0018, self.error_std=0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [20:45, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9572192513368983, 'aucpr': 0.4317294742294743}, fitting time: 88.08135485649109, inference time: 0.0019948482513427734\n",
      "{'Samples': 1000, 'Features': 18, 'Anomalies': 43, 'Anomalies Ratio(%)': 4.3}\n",
      "epoch : 1/5000, loss = 4.133403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.023562\n",
      "epoch : 2000/5000, loss = 0.007090\n",
      "epoch : 3000/5000, loss = 0.002621\n",
      "epoch : 4000/5000, loss = 0.001163\n",
      "epoch : 5000/5000, loss = 0.001294\n",
      "self.error_median=0.0008, self.error_range=0.0007\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0012, self.error_std=0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [22:14, 15.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('21_Lymphography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9654248190833558, 'aucpr': 0.6436634789477598}, fitting time: 88.85792589187622, inference time: 0.0009958744049072266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 348, 'Anomalies Ratio(%)': 34.8}\n",
      "epoch : 1/5000, loss = 1.547987\n",
      "epoch : 1000/5000, loss = 0.000353\n",
      "epoch : 2000/5000, loss = 0.000342\n",
      "epoch : 3000/5000, loss = 0.000144\n",
      "epoch : 4000/5000, loss = 0.000073\n",
      "epoch : 5000/5000, loss = 0.000089\n",
      "self.error_median=0.0001, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [23:43,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('4_breastw', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6671899529042385, 'aucpr': 0.5959811779948113}, fitting time: 88.06446957588196, inference time: 0.001994609832763672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 336, 'Anomalies Ratio(%)': 33.6}\n",
      "epoch : 1/5000, loss = 1.839826\n",
      "epoch : 1000/5000, loss = 0.003473\n",
      "epoch : 2000/5000, loss = 0.000849\n",
      "epoch : 3000/5000, loss = 0.000230\n",
      "epoch : 4000/5000, loss = 0.000069\n",
      "epoch : 5000/5000, loss = 0.000027\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0000, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [25:11, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('4_breastw', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6979949251206528, 'aucpr': 0.6216030012241686}, fitting time: 88.04013586044312, inference time: 0.0010285377502441406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 364, 'Anomalies Ratio(%)': 36.4}\n",
      "epoch : 1/5000, loss = 1.206644\n",
      "epoch : 1000/5000, loss = 0.001147\n",
      "epoch : 2000/5000, loss = 0.000438\n",
      "epoch : 3000/5000, loss = 0.000228\n",
      "epoch : 4000/5000, loss = 0.000062\n",
      "epoch : 5000/5000, loss = 0.000048\n",
      "self.error_median=0.0000, self.error_range=0.0000\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 9. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0001, self.error_std=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [26:40, 15.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('4_breastw', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7211681636966233, 'aucpr': 0.6375598870803936}, fitting time: 88.47647738456726, inference time: 0.0010259151458740234\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 75, 'Anomalies Ratio(%)': 7.5}\n",
      "epoch : 1/5000, loss = 2.820987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.008379\n",
      "epoch : 2000/5000, loss = 0.002742\n",
      "epoch : 3000/5000, loss = 0.000449\n",
      "epoch : 4000/5000, loss = 0.000368\n",
      "epoch : 5000/5000, loss = 0.000318\n",
      "self.error_median=0.0003, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145it [28:09,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('45_wine', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8562235127923403, 'aucpr': 0.6235563064038864}, fitting time: 88.08621287345886, inference time: 0.0009975433349609375\n",
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 80, 'Anomalies Ratio(%)': 8.0}\n",
      "epoch : 1/5000, loss = 3.035707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.010168\n",
      "epoch : 2000/5000, loss = 0.002526\n",
      "epoch : 3000/5000, loss = 0.000241\n",
      "epoch : 4000/5000, loss = 0.000311\n",
      "epoch : 5000/5000, loss = 0.000769\n",
      "self.error_median=0.0008, self.error_range=0.0002\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0008, self.error_std=0.0002\n",
      "Current experiment parameters: ('45_wine', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9184782608695653, 'aucpr': 0.8287584531871564}, fitting time: 87.98162269592285, inference time: 0.0009970664978027344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146it [29:37, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 13, 'Anomalies': 88, 'Anomalies Ratio(%)': 8.8}\n",
      "epoch : 1/5000, loss = 3.390557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.013557\n",
      "epoch : 2000/5000, loss = 0.004812\n",
      "epoch : 3000/5000, loss = 0.001426\n",
      "epoch : 4000/5000, loss = 0.000132\n",
      "epoch : 5000/5000, loss = 0.000384\n",
      "self.error_median=0.0003, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 13. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0004, self.error_std=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "147it [31:07, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('45_wine', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8794216732172937, 'aucpr': 0.6876299390853221}, fitting time: 88.7341673374176, inference time: 0.0019958019256591797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 369, 'Anomalies Ratio(%)': 36.9}\n",
      "epoch : 1/5000, loss = 10.414998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.083093\n",
      "epoch : 2000/5000, loss = 0.048230\n",
      "epoch : 3000/5000, loss = 0.030848\n",
      "epoch : 4000/5000, loss = 0.025760\n",
      "epoch : 5000/5000, loss = 0.020103\n",
      "self.error_median=0.0117, self.error_range=0.0251\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0201, self.error_std=0.0211\n",
      "Current experiment parameters: ('18_Ionosphere', 0.0, 1), model: Customized, metrics: {'aucroc': 0.955574622241289, 'aucpr': 0.9451626864066954}, fitting time: 88.26750564575195, inference time: 0.000997304916381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [32:35,  8.39s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 374, 'Anomalies Ratio(%)': 37.4}\n",
      "epoch : 1/5000, loss = 10.135671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.095192\n",
      "epoch : 2000/5000, loss = 0.057765\n",
      "epoch : 3000/5000, loss = 0.035953\n",
      "epoch : 4000/5000, loss = 0.027316\n",
      "epoch : 5000/5000, loss = 0.022339\n",
      "self.error_median=0.0140, self.error_range=0.0279\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0225, self.error_std=0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [34:04, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('18_Ionosphere', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9446238601823708, 'aucpr': 0.938578671035911}, fitting time: 88.75934720039368, inference time: 0.0009975433349609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 32, 'Anomalies': 349, 'Anomalies Ratio(%)': 34.9}\n",
      "epoch : 1/5000, loss = 10.165210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.075457\n",
      "epoch : 2000/5000, loss = 0.044173\n",
      "epoch : 3000/5000, loss = 0.029384\n",
      "epoch : 4000/5000, loss = 0.021701\n",
      "epoch : 5000/5000, loss = 0.017849\n",
      "self.error_median=0.0107, self.error_range=0.0211\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0177, self.error_std=0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171it [35:33, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('18_Ionosphere', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9691330891330892, 'aucpr': 0.9518879691579412}, fitting time: 88.3176817893982, inference time: 0.000997304916381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 367, 'Anomalies Ratio(%)': 36.7}\n",
      "epoch : 1/5000, loss = 1.898853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/5000, loss = 0.000731\n",
      "epoch : 2000/5000, loss = 0.000454\n",
      "epoch : 3000/5000, loss = 0.000107\n",
      "epoch : 4000/5000, loss = 0.000240\n",
      "epoch : 5000/5000, loss = 0.000274\n",
      "self.error_median=0.0003, self.error_range=0.0001\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 8. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=0.0003, self.error_std=0.0001\n",
      "Current experiment parameters: ('29_Pima', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7804306220095694, 'aucpr': 0.771789060801062}, fitting time: 88.35006093978882, inference time: 0.0010097026824951172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "193it [37:02,  8.40s/it]d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "d:\\conda\\venv\\adbench\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 1000, 'Features': 8, 'Anomalies': 346, 'Anomalies Ratio(%)': 34.6}\n",
      "epoch : 1/5000, loss = 1.935344\n",
      "epoch : 1000/5000, loss = 0.002203\n",
      "epoch : 2000/5000, loss = 0.000205\n",
      "epoch : 3000/5000, loss = 0.000122\n",
      "epoch : 4000/5000, loss = 0.000366\n"
     ]
    }
   ],
   "source": [
    "for mode in [\n",
    "                #None,\n",
    "                'dependency',\n",
    "                'cluster',\n",
    "                None,\n",
    "                'local',\n",
    "                'global',\n",
    "            ]:\n",
    "    pipeline = RunPipeline(suffix='ADBench', parallel='unsupervise', realistic_synthetic_mode=mode, noise_type=None, num_seed=3)\n",
    "    #results = pipeline.run(clf=VAE)\n",
    "    results = pipeline.run(clf=SimpleAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in ['cluster',\n",
    "            'local',\n",
    "            'global',\n",
    "            'dependency',\n",
    "            None,\n",
    "            ]:\n",
    "    pipeline = RunPipeline(suffix='ADBench', parallel='unsupervise', realistic_synthetic_mode=mode, noise_type=None, num_seed=1)\n",
    "    #results = pipeline.run(clf=VAE)\n",
    "    results = pipeline.run(clf=DOCAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your customized algorithm on customized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adbench.baseline.Bagging.run import Bagging\n",
    "from adbench.baseline.AADOCAE.run import AADOCAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on customized dataset...\n",
      "{'Samples': 1000, 'Features': 20, 'Anomalies': 498, 'Anomalies Ratio(%)': 49.8}\n",
      "epoch : 1/12, loss = 5.524560\n",
      "self.error_median=3.8629, self.error_range=0.8937, self.latent_error_median_=0.6489, self.latent_error_range_=0.1544\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=3.8807, self.error_std=0.5358, self.latent_error_mu_=0.6518, self.latent_error_sigma_=0.0945; alpha = 1.0000\n",
      "Current experiment parameters: (None, 0.0, 1), model: Customized, metrics: {'aucroc': 0.4888661718298591, 'aucpr': 0.48867482615817526}, fitting time: 0.2572813034057617, inference time: 0.0019817352294921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.5086; AUCPR=0.5066\n",
      "Deviation AUCROC=0.4798; AUCPR=0.4729\n",
      "Max(rec, dev) AUCROC=0.5086; AUCPR=0.5066\n",
      "\n",
      "Sum of squared error AUCROC=0.5076; AUCPR=0.5058\n",
      "\n",
      "Testing on customized dataset...\n",
      "{'Samples': 1000, 'Features': 20, 'Anomalies': 498, 'Anomalies Ratio(%)': 49.8}\n",
      "epoch : 1/12, loss = 5.673854\n",
      "self.error_median=5.0582, self.error_range=1.1281, self.latent_error_median_=0.1390, self.latent_error_range_=0.0487\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=5.0629, self.error_std=0.6781, self.latent_error_mu_=0.1409, self.latent_error_sigma_=0.0290; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: (None, 0.0, 2), model: Customized, metrics: {'aucroc': 0.4651317836348282, 'aucpr': 0.47213899486085287}, fitting time: 0.17455291748046875, inference time: 0.0019958019256591797\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.4769; AUCPR=0.4771\n",
      "Deviation AUCROC=0.4565; AUCPR=0.4785\n",
      "Max(rec, dev) AUCROC=0.4769; AUCPR=0.4771\n",
      "\n",
      "Sum of squared error AUCROC=0.4769; AUCPR=0.4770\n",
      "\n",
      "Testing on customized dataset...\n",
      "{'Samples': 1000, 'Features': 20, 'Anomalies': 498, 'Anomalies Ratio(%)': 49.8}\n",
      "epoch : 1/12, loss = 5.687943\n",
      "self.error_median=4.8010, self.error_range=1.0662, self.latent_error_median_=0.2704, self.latent_error_range_=0.0737\n",
      "Model result scaling scheme:  True\n",
      "Latent dim= 16. Weight Decay = 0.000001\n",
      "Using cuda\n",
      "self.error_mu=4.8202, self.error_std=0.6516, self.latent_error_mu_=0.2692, self.latent_error_sigma_=0.0447; alpha = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 17.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: (None, 0.0, 3), model: Customized, metrics: {'aucroc': 0.5135783812613894, 'aucpr': 0.5175445014161114}, fitting time: 0.17716336250305176, inference time: 0.0019948482513427734\n",
      "\n",
      "Model performance:\n",
      "Reconstruction AUCROC=0.5043; AUCPR=0.4993\n",
      "Deviation AUCROC=0.5219; AUCPR=0.5329\n",
      "Max(rec, dev) AUCROC=0.5043; AUCPR=0.4993\n",
      "\n",
      "Sum of squared error AUCROC=0.5044; AUCPR=0.4993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# customized model on customized dataset\n",
    "import numpy as np\n",
    "dataset = {}\n",
    "dataset['X'] = np.random.randn(1000, 20)\n",
    "dataset['y'] = np.random.choice([0, 1], 1000)\n",
    "#print(dataset['y'])\n",
    "RunPipeline(suffix='ADBench', parallel='unsupervise', realistic_synthetic_mode=None, noise_type=None, num_seed=1)\n",
    "results = pipeline.run(dataset=dataset, clf=AADOCAE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import AD algorithms from ADBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit transform: X shape before:  (1000, 4)\n",
      "[[0. 1. 1. 1.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 1. 0.]]\n",
      "Train data shape after filter corrcoef:  (1000, 1)\n",
      "epoch : 1000/3000, loss = 1.000339\n",
      "epoch : 2000/3000, loss = 1.000902\n",
      "epoch : 3000/3000, loss = 1.001148\n",
      "(100, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' from adbench.baseline.PReNet.run import PReNet\\nmodel = PReNet(seed=42)\\nmodel.fit(X_train, y_train)  # fit\\nscore = model.predict_score(X_test)  # predict '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = np.random.randn(1000, 1)\n",
    "X_train = np.concatenate((X_train, X_train, X_train, X_train), axis=-1)\n",
    "y_train = np.random.choice([0, 1], 1000)\n",
    "X_test = np.random.randn(100, 4)\n",
    "y_test = np.random.choice([0, 1], 100)\n",
    "\n",
    "# Directly import AD algorithms from the existing toolkits like PyOD\n",
    "#from adbench.baseline.PyOD import PYOD\n",
    "#model = PYOD(seed=42, model_name='XGBOD')  # initialization\n",
    "model = SimpleAE(seed=42)\n",
    "model.fit(X_train, y_train)  # fit\n",
    "score = model.predict_score(X_test)  # predict\n",
    "print(score.shape)\n",
    "\n",
    "# Import deep learning AD algorithms from our ADBench\n",
    "\"\"\" from adbench.baseline.PReNet.run import PReNet\n",
    "model = PReNet(seed=42)\n",
    "model.fit(X_train, y_train)  # fit\n",
    "score = model.predict_score(X_test)  # predict \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
