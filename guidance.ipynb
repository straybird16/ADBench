{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step-by-step Guidence on How to Install and Use ADBench**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install ADBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T15:56:47.229748Z",
     "start_time": "2023-07-19T15:56:35.675200Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install adbench\n",
    "#!pip install --upgrade adbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T16:06:57.104897Z",
     "start_time": "2023-07-19T16:06:57.092930Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xxd/Documents/PhD/AD/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# download datasets in ADBench from the remote github repo\n",
    "from adbench.myutils import Utils\n",
    "utils = Utils()\n",
    "# we recommend jihulab for China mainland user and github otherwise\n",
    "#utils.download_datasets(repo='github')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run ADBench "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T15:33:13.848925Z",
     "start_time": "2023-07-17T15:33:13.833498Z"
    }
   },
   "source": [
    "## Run ADBench experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T14:44:03.627289Z",
     "start_time": "2023-07-19T14:26:41.551958Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nParams:\\nsuffix: file name suffix;\\n\\nparallel: running either 'unsupervise', 'semi-supervise', or 'supervise' (AD) algorithms,\\ncorresponding to the Angle I: Availability of Ground Truth Labels (Supervision);\\n\\nrealistic_synthetic_mode: testing on 'local', 'global', 'dependency', and 'cluster' anomalies, \\ncorresponding to the Angle II: Types of Anomalies;\\n\\nnoise type: evaluating algorithms on 'duplicated_anomalies', 'irrelevant_features' and 'label_contamination',\\ncorresponding to the Angle III: Model Robustness with Noisy and Corrupted Data.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adbench.run import RunPipeline\n",
    "\n",
    "'''\n",
    "Params:\n",
    "suffix: file name suffix;\n",
    "\n",
    "parallel: running either 'unsupervise', 'semi-supervise', or 'supervise' (AD) algorithms,\n",
    "corresponding to the Angle I: Availability of Ground Truth Labels (Supervision);\n",
    "\n",
    "realistic_synthetic_mode: testing on 'local', 'global', 'dependency', and 'cluster' anomalies, \n",
    "corresponding to the Angle II: Types of Anomalies;\n",
    "\n",
    "noise type: evaluating algorithms on 'duplicated_anomalies', 'irrelevant_features' and 'label_contamination',\n",
    "corresponding to the Angle III: Model Robustness with Noisy and Corrupted Data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the results including [params, model_name, metrics, time_fit, time_inference]\n",
    "# besides, results will be automatically saved in the dataframe and ouputted as csv file in adbench/result folder\n",
    "\n",
    "pipeline = RunPipeline(suffix='ADBench', parallel='semi-supervise', realistic_synthetic_mode=None, noise_type=None)\n",
    "results = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = RunPipeline(suffix='ADBench', parallel='unsupervise', realistic_synthetic_mode='cluster', noise_type=None)\n",
    "#results = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = RunPipeline(suffix='ADBench', parallel='supervise', realistic_synthetic_mode=None, noise_type='irrelevant_features')\n",
    "#results = pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your customized algorithm on ADBench datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized model on ADBench's datasets\n",
    "from adbench.run import RunPipeline\n",
    "from adbench.baseline.Customized.run import SimpleAE\n",
    "\n",
    "# notice that you should specify the corresponding category of your customized AD algorithm\n",
    "# for example, here we use Logistic Regression as customized clf, which belongs to the supervised algorithm\n",
    "# for your own algorithm, you can realize the same usage as other baselines by modifying the fit.py, model.py, and run.py files in the adbench/baseline/Customized\n",
    "pipeline = RunPipeline(suffix='ADBench', parallel='unsupervise', realistic_synthetic_mode='local', noise_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 26_optdigits...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 64, 'Anomalies': 290, 'Anomalies Ratio(%)': 2.9}\n",
      "generating duplicate samples for dataset 26_optdigits...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 64, 'Anomalies': 284, 'Anomalies Ratio(%)': 2.84}\n",
      "generating duplicate samples for dataset 26_optdigits...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 64, 'Anomalies': 281, 'Anomalies Ratio(%)': 2.81}\n",
      "generating duplicate samples for dataset 42_WBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 424, 'Anomalies Ratio(%)': 4.24}\n",
      "generating duplicate samples for dataset 42_WBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 421, 'Anomalies Ratio(%)': 4.21}\n",
      "generating duplicate samples for dataset 42_WBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 452, 'Anomalies Ratio(%)': 4.52}\n",
      "generating duplicate samples for dataset 21_Lymphography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 18, 'Anomalies': 387, 'Anomalies Ratio(%)': 3.87}\n",
      "generating duplicate samples for dataset 21_Lymphography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 18, 'Anomalies': 388, 'Anomalies Ratio(%)': 3.88}\n",
      "generating duplicate samples for dataset 21_Lymphography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 18, 'Anomalies': 435, 'Anomalies Ratio(%)': 4.35}\n",
      "subsampling for dataset 8_celeba...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 222, 'Anomalies Ratio(%)': 2.22}\n",
      "subsampling for dataset 8_celeba...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 238, 'Anomalies Ratio(%)': 2.38}\n",
      "subsampling for dataset 8_celeba...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 216, 'Anomalies Ratio(%)': 2.16}\n",
      "subsampling for dataset 33_skin...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2081, 'Anomalies Ratio(%)': 20.81}\n",
      "subsampling for dataset 33_skin...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2082, 'Anomalies Ratio(%)': 20.82}\n",
      "subsampling for dataset 33_skin...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2066, 'Anomalies Ratio(%)': 20.66}\n",
      "subsampling for dataset 34_smtp...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "subsampling for dataset 34_smtp...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "subsampling for dataset 34_smtp...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 5, 'Anomalies Ratio(%)': 0.05}\n",
      "generating duplicate samples for dataset 28_pendigits...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 16, 'Anomalies': 206, 'Anomalies Ratio(%)': 2.06}\n",
      "generating duplicate samples for dataset 28_pendigits...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 16, 'Anomalies': 228, 'Anomalies Ratio(%)': 2.28}\n",
      "generating duplicate samples for dataset 28_pendigits...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 16, 'Anomalies': 238, 'Anomalies Ratio(%)': 2.38}\n",
      "generating duplicate samples for dataset 39_vertebral...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 1268, 'Anomalies Ratio(%)': 12.68}\n",
      "generating duplicate samples for dataset 39_vertebral...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 1307, 'Anomalies Ratio(%)': 13.07}\n",
      "generating duplicate samples for dataset 39_vertebral...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 1287, 'Anomalies Ratio(%)': 12.87}\n",
      "subsampling for dataset 11_donors...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "subsampling for dataset 11_donors...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 578, 'Anomalies Ratio(%)': 5.78}\n",
      "subsampling for dataset 11_donors...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 597, 'Anomalies Ratio(%)': 5.97}\n",
      "generating duplicate samples for dataset 43_WDBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 30, 'Anomalies': 264, 'Anomalies Ratio(%)': 2.64}\n",
      "generating duplicate samples for dataset 43_WDBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 30, 'Anomalies': 275, 'Anomalies Ratio(%)': 2.75}\n",
      "generating duplicate samples for dataset 43_WDBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 30, 'Anomalies': 261, 'Anomalies Ratio(%)': 2.61}\n",
      "generating duplicate samples for dataset 7_Cardiotocography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 2139, 'Anomalies Ratio(%)': 21.39}\n",
      "generating duplicate samples for dataset 7_Cardiotocography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 2231, 'Anomalies Ratio(%)': 22.31}\n",
      "generating duplicate samples for dataset 7_Cardiotocography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 2255, 'Anomalies Ratio(%)': 22.55}\n",
      "generating duplicate samples for dataset 36_speech...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 400, 'Anomalies': 166, 'Anomalies Ratio(%)': 1.66}\n",
      "generating duplicate samples for dataset 36_speech...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 400, 'Anomalies': 165, 'Anomalies Ratio(%)': 1.65}\n",
      "generating duplicate samples for dataset 36_speech...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 400, 'Anomalies': 158, 'Anomalies Ratio(%)': 1.58}\n",
      "subsampling for dataset 5_campaign...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1134, 'Anomalies Ratio(%)': 11.34}\n",
      "subsampling for dataset 5_campaign...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "subsampling for dataset 5_campaign...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "generating duplicate samples for dataset 44_Wilt...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 5, 'Anomalies': 505, 'Anomalies Ratio(%)': 5.05}\n",
      "generating duplicate samples for dataset 44_Wilt...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 5, 'Anomalies': 575, 'Anomalies Ratio(%)': 5.75}\n",
      "generating duplicate samples for dataset 44_Wilt...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 5, 'Anomalies': 518, 'Anomalies Ratio(%)': 5.18}\n",
      "subsampling for dataset 10_cover...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 97, 'Anomalies Ratio(%)': 0.97}\n",
      "subsampling for dataset 10_cover...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 116, 'Anomalies Ratio(%)': 1.16}\n",
      "subsampling for dataset 10_cover...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 95, 'Anomalies Ratio(%)': 0.95}\n",
      "generating duplicate samples for dataset 46_WPBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 33, 'Anomalies': 2318, 'Anomalies Ratio(%)': 23.18}\n",
      "generating duplicate samples for dataset 46_WPBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 33, 'Anomalies': 2333, 'Anomalies Ratio(%)': 23.33}\n",
      "generating duplicate samples for dataset 46_WPBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 33, 'Anomalies': 2395, 'Anomalies Ratio(%)': 23.95}\n",
      "generating duplicate samples for dataset 37_Stamps...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 908, 'Anomalies Ratio(%)': 9.08}\n",
      "generating duplicate samples for dataset 37_Stamps...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 918, 'Anomalies Ratio(%)': 9.18}\n",
      "generating duplicate samples for dataset 37_Stamps...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 874, 'Anomalies Ratio(%)': 8.74}\n",
      "generating duplicate samples for dataset 2_annthyroid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 695, 'Anomalies Ratio(%)': 6.95}\n",
      "generating duplicate samples for dataset 2_annthyroid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 746, 'Anomalies Ratio(%)': 7.46}\n",
      "generating duplicate samples for dataset 2_annthyroid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 747, 'Anomalies Ratio(%)': 7.47}\n",
      "generating duplicate samples for dataset 27_PageBlocks...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 900, 'Anomalies Ratio(%)': 9.0}\n",
      "generating duplicate samples for dataset 27_PageBlocks...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 936, 'Anomalies Ratio(%)': 9.36}\n",
      "generating duplicate samples for dataset 27_PageBlocks...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 1004, 'Anomalies Ratio(%)': 10.04}\n",
      "generating duplicate samples for dataset 31_satimage-2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 110, 'Anomalies Ratio(%)': 1.1}\n",
      "generating duplicate samples for dataset 31_satimage-2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 126, 'Anomalies Ratio(%)': 1.26}\n",
      "generating duplicate samples for dataset 31_satimage-2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 115, 'Anomalies Ratio(%)': 1.15}\n",
      "subsampling for dataset 3_backdoor...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 252, 'Anomalies Ratio(%)': 2.52}\n",
      "subsampling for dataset 3_backdoor...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 246, 'Anomalies Ratio(%)': 2.46}\n",
      "subsampling for dataset 3_backdoor...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 256, 'Anomalies Ratio(%)': 2.56}\n",
      "generating duplicate samples for dataset 38_thyroid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 252, 'Anomalies Ratio(%)': 2.52}\n",
      "generating duplicate samples for dataset 38_thyroid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 258, 'Anomalies Ratio(%)': 2.58}\n",
      "generating duplicate samples for dataset 38_thyroid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 243, 'Anomalies Ratio(%)': 2.43}\n",
      "generating duplicate samples for dataset 29_Pima...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 8, 'Anomalies': 3452, 'Anomalies Ratio(%)': 34.52}\n",
      "generating duplicate samples for dataset 29_Pima...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 8, 'Anomalies': 3360, 'Anomalies Ratio(%)': 33.6}\n",
      "generating duplicate samples for dataset 29_Pima...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 8, 'Anomalies': 3541, 'Anomalies Ratio(%)': 35.41}\n",
      "generating duplicate samples for dataset 24_mnist...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 100, 'Anomalies': 959, 'Anomalies Ratio(%)': 9.59}\n",
      "generating duplicate samples for dataset 24_mnist...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 100, 'Anomalies': 948, 'Anomalies Ratio(%)': 9.48}\n",
      "generating duplicate samples for dataset 24_mnist...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 100, 'Anomalies': 942, 'Anomalies Ratio(%)': 9.42}\n",
      "generating duplicate samples for dataset 15_Hepatitis...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 19, 'Anomalies': 1613, 'Anomalies Ratio(%)': 16.13}\n",
      "generating duplicate samples for dataset 15_Hepatitis...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 19, 'Anomalies': 1608, 'Anomalies Ratio(%)': 16.08}\n",
      "generating duplicate samples for dataset 15_Hepatitis...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 19, 'Anomalies': 1637, 'Anomalies Ratio(%)': 16.37}\n",
      "subsampling for dataset 22_magic.gamma...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3548, 'Anomalies Ratio(%)': 35.48}\n",
      "subsampling for dataset 22_magic.gamma...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3533, 'Anomalies Ratio(%)': 35.33}\n",
      "subsampling for dataset 22_magic.gamma...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3500, 'Anomalies Ratio(%)': 35.0}\n",
      "subsampling for dataset 16_http...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 46, 'Anomalies Ratio(%)': 0.46}\n",
      "subsampling for dataset 16_http...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 35, 'Anomalies Ratio(%)': 0.35}\n",
      "subsampling for dataset 16_http...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 34, 'Anomalies Ratio(%)': 0.34}\n",
      "subsampling for dataset 32_shuttle...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 669, 'Anomalies Ratio(%)': 6.69}\n",
      "subsampling for dataset 32_shuttle...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 697, 'Anomalies Ratio(%)': 6.97}\n",
      "subsampling for dataset 32_shuttle...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 714, 'Anomalies Ratio(%)': 7.14}\n",
      "generating duplicate samples for dataset 12_fault...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 3499, 'Anomalies Ratio(%)': 34.99}\n",
      "generating duplicate samples for dataset 12_fault...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 3479, 'Anomalies Ratio(%)': 34.79}\n",
      "generating duplicate samples for dataset 12_fault...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 3473, 'Anomalies Ratio(%)': 34.73}\n",
      "generating duplicate samples for dataset 47_yeast...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 8, 'Anomalies': 3398, 'Anomalies Ratio(%)': 33.98}\n",
      "generating duplicate samples for dataset 47_yeast...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 8, 'Anomalies': 3463, 'Anomalies Ratio(%)': 34.63}\n",
      "generating duplicate samples for dataset 47_yeast...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 8, 'Anomalies': 3310, 'Anomalies Ratio(%)': 33.1}\n",
      "subsampling for dataset 13_fraud...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "subsampling for dataset 13_fraud...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "subsampling for dataset 13_fraud...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 13, 'Anomalies Ratio(%)': 0.13}\n",
      "generating duplicate samples for dataset 35_SpamBase...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 57, 'Anomalies': 3980, 'Anomalies Ratio(%)': 39.8}\n",
      "generating duplicate samples for dataset 35_SpamBase...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 57, 'Anomalies': 3946, 'Anomalies Ratio(%)': 39.46}\n",
      "generating duplicate samples for dataset 35_SpamBase...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 57, 'Anomalies': 3970, 'Anomalies Ratio(%)': 39.7}\n",
      "generating duplicate samples for dataset 41_Waveform...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 279, 'Anomalies Ratio(%)': 2.79}\n",
      "generating duplicate samples for dataset 41_Waveform...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 290, 'Anomalies Ratio(%)': 2.9}\n",
      "generating duplicate samples for dataset 41_Waveform...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 286, 'Anomalies Ratio(%)': 2.86}\n",
      "generating duplicate samples for dataset 17_InternetAds...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 1555, 'Anomalies': 1844, 'Anomalies Ratio(%)': 18.44}\n",
      "generating duplicate samples for dataset 17_InternetAds...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 1555, 'Anomalies': 1857, 'Anomalies Ratio(%)': 18.57}\n",
      "generating duplicate samples for dataset 17_InternetAds...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 1555, 'Anomalies': 1881, 'Anomalies Ratio(%)': 18.81}\n",
      "generating duplicate samples for dataset 6_cardio...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 952, 'Anomalies Ratio(%)': 9.52}\n",
      "generating duplicate samples for dataset 6_cardio...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 955, 'Anomalies Ratio(%)': 9.55}\n",
      "generating duplicate samples for dataset 6_cardio...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 1001, 'Anomalies Ratio(%)': 10.01}\n",
      "subsampling for dataset 23_mammography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 230, 'Anomalies Ratio(%)': 2.3}\n",
      "subsampling for dataset 23_mammography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 241, 'Anomalies Ratio(%)': 2.41}\n",
      "subsampling for dataset 23_mammography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 227, 'Anomalies Ratio(%)': 2.27}\n",
      "generating duplicate samples for dataset 40_vowels...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 12, 'Anomalies': 346, 'Anomalies Ratio(%)': 3.46}\n",
      "generating duplicate samples for dataset 40_vowels...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 12, 'Anomalies': 354, 'Anomalies Ratio(%)': 3.54}\n",
      "generating duplicate samples for dataset 40_vowels...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 12, 'Anomalies': 363, 'Anomalies Ratio(%)': 3.63}\n",
      "subsampling for dataset 9_census...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "subsampling for dataset 9_census...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 628, 'Anomalies Ratio(%)': 6.28}\n",
      "subsampling for dataset 9_census...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 652, 'Anomalies Ratio(%)': 6.52}\n",
      "generating duplicate samples for dataset 45_wine...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 13, 'Anomalies': 748, 'Anomalies Ratio(%)': 7.48}\n",
      "generating duplicate samples for dataset 45_wine...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 13, 'Anomalies': 741, 'Anomalies Ratio(%)': 7.41}\n",
      "generating duplicate samples for dataset 45_wine...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 13, 'Anomalies': 751, 'Anomalies Ratio(%)': 7.51}\n",
      "generating duplicate samples for dataset 25_musk...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 166, 'Anomalies': 305, 'Anomalies Ratio(%)': 3.05}\n",
      "generating duplicate samples for dataset 25_musk...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 166, 'Anomalies': 311, 'Anomalies Ratio(%)': 3.11}\n",
      "generating duplicate samples for dataset 25_musk...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 166, 'Anomalies': 324, 'Anomalies Ratio(%)': 3.24}\n",
      "subsampling for dataset 1_ALOI...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 315, 'Anomalies Ratio(%)': 3.15}\n",
      "subsampling for dataset 1_ALOI...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 334, 'Anomalies Ratio(%)': 3.34}\n",
      "subsampling for dataset 1_ALOI...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 332, 'Anomalies Ratio(%)': 3.32}\n",
      "generating duplicate samples for dataset 18_Ionosphere...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 32, 'Anomalies': 3637, 'Anomalies Ratio(%)': 36.37}\n",
      "generating duplicate samples for dataset 18_Ionosphere...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 32, 'Anomalies': 3560, 'Anomalies Ratio(%)': 35.6}\n",
      "generating duplicate samples for dataset 18_Ionosphere...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 32, 'Anomalies': 3611, 'Anomalies Ratio(%)': 36.11}\n",
      "generating duplicate samples for dataset 20_letter...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 32, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "generating duplicate samples for dataset 20_letter...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 32, 'Anomalies': 610, 'Anomalies Ratio(%)': 6.1}\n",
      "generating duplicate samples for dataset 20_letter...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 32, 'Anomalies': 636, 'Anomalies Ratio(%)': 6.36}\n",
      "generating duplicate samples for dataset 19_landsat...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 2052, 'Anomalies Ratio(%)': 20.52}\n",
      "generating duplicate samples for dataset 19_landsat...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 2081, 'Anomalies Ratio(%)': 20.81}\n",
      "generating duplicate samples for dataset 19_landsat...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 1998, 'Anomalies Ratio(%)': 19.98}\n",
      "generating duplicate samples for dataset 14_glass...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 7, 'Anomalies': 412, 'Anomalies Ratio(%)': 4.12}\n",
      "generating duplicate samples for dataset 14_glass...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 7, 'Anomalies': 397, 'Anomalies Ratio(%)': 3.97}\n",
      "generating duplicate samples for dataset 14_glass...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 7, 'Anomalies': 402, 'Anomalies Ratio(%)': 4.02}\n",
      "generating duplicate samples for dataset 30_satellite...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 3138, 'Anomalies Ratio(%)': 31.38}\n",
      "generating duplicate samples for dataset 30_satellite...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 3190, 'Anomalies Ratio(%)': 31.9}\n",
      "generating duplicate samples for dataset 30_satellite...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 3089, 'Anomalies Ratio(%)': 30.89}\n",
      "generating duplicate samples for dataset 4_breastw...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 3483, 'Anomalies Ratio(%)': 34.83}\n",
      "generating duplicate samples for dataset 4_breastw...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 3496, 'Anomalies Ratio(%)': 34.96}\n",
      "generating duplicate samples for dataset 4_breastw...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 3507, 'Anomalies Ratio(%)': 35.07}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_spatter\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_glass_blur\n",
      "generating duplicate samples for dataset MVTec-AD_pill...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 3316, 'Anomalies Ratio(%)': 33.16}\n",
      "generating duplicate samples for dataset MVTec-AD_pill...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 3256, 'Anomalies Ratio(%)': 32.56}\n",
      "generating duplicate samples for dataset MVTec-AD_pill...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 3211, 'Anomalies Ratio(%)': 32.11}\n",
      "remove the dataset MVTec-AD_pill\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_rotate\n",
      "generating duplicate samples for dataset MVTec-AD_screw...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2420, 'Anomalies Ratio(%)': 24.2}\n",
      "generating duplicate samples for dataset MVTec-AD_screw...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2551, 'Anomalies Ratio(%)': 25.51}\n",
      "generating duplicate samples for dataset MVTec-AD_screw...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2517, 'Anomalies Ratio(%)': 25.17}\n",
      "remove the dataset MVTec-AD_screw\n",
      "generating duplicate samples for dataset SVHN_8...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 503, 'Anomalies Ratio(%)': 5.03}\n",
      "generating duplicate samples for dataset SVHN_8...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 509, 'Anomalies Ratio(%)': 5.09}\n",
      "generating duplicate samples for dataset SVHN_8...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 498, 'Anomalies Ratio(%)': 4.98}\n",
      "remove the dataset SVHN_8\n",
      "generating duplicate samples for dataset SVHN_9...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 508, 'Anomalies Ratio(%)': 5.08}\n",
      "generating duplicate samples for dataset SVHN_9...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 512, 'Anomalies Ratio(%)': 5.12}\n",
      "generating duplicate samples for dataset SVHN_9...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 496, 'Anomalies Ratio(%)': 4.96}\n",
      "remove the dataset SVHN_9\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_dotted_line\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_shear\n",
      "generating duplicate samples for dataset FashionMNIST_3...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 511, 'Anomalies Ratio(%)': 5.11}\n",
      "generating duplicate samples for dataset FashionMNIST_3...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 521, 'Anomalies Ratio(%)': 5.21}\n",
      "generating duplicate samples for dataset FashionMNIST_3...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 524, 'Anomalies Ratio(%)': 5.24}\n",
      "remove the dataset FashionMNIST_3\n",
      "generating duplicate samples for dataset MVTec-AD_toothbrush...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2860, 'Anomalies Ratio(%)': 28.6}\n",
      "generating duplicate samples for dataset MVTec-AD_toothbrush...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2956, 'Anomalies Ratio(%)': 29.56}\n",
      "generating duplicate samples for dataset MVTec-AD_toothbrush...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2976, 'Anomalies Ratio(%)': 29.76}\n",
      "remove the dataset MVTec-AD_toothbrush\n",
      "generating duplicate samples for dataset FashionMNIST_2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "generating duplicate samples for dataset FashionMNIST_2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 451, 'Anomalies Ratio(%)': 4.51}\n",
      "generating duplicate samples for dataset FashionMNIST_2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 481, 'Anomalies Ratio(%)': 4.81}\n",
      "remove the dataset FashionMNIST_2\n",
      "generating duplicate samples for dataset FashionMNIST_0...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 512, 'Anomalies Ratio(%)': 5.12}\n",
      "generating duplicate samples for dataset FashionMNIST_0...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 471, 'Anomalies Ratio(%)': 4.71}\n",
      "generating duplicate samples for dataset FashionMNIST_0...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 493, 'Anomalies Ratio(%)': 4.93}\n",
      "remove the dataset FashionMNIST_0\n",
      "generating duplicate samples for dataset FashionMNIST_1...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "generating duplicate samples for dataset FashionMNIST_1...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 473, 'Anomalies Ratio(%)': 4.73}\n",
      "generating duplicate samples for dataset FashionMNIST_1...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 521, 'Anomalies Ratio(%)': 5.21}\n",
      "remove the dataset FashionMNIST_1\n",
      "generating duplicate samples for dataset FashionMNIST_5...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 516, 'Anomalies Ratio(%)': 5.16}\n",
      "generating duplicate samples for dataset FashionMNIST_5...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 509, 'Anomalies Ratio(%)': 5.09}\n",
      "generating duplicate samples for dataset FashionMNIST_5...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 513, 'Anomalies Ratio(%)': 5.13}\n",
      "remove the dataset FashionMNIST_5\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_identity\n",
      "generating duplicate samples for dataset MVTec-AD_leather...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2535, 'Anomalies Ratio(%)': 25.35}\n",
      "generating duplicate samples for dataset MVTec-AD_leather...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2550, 'Anomalies Ratio(%)': 25.5}\n",
      "generating duplicate samples for dataset MVTec-AD_leather...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2405, 'Anomalies Ratio(%)': 24.05}\n",
      "remove the dataset MVTec-AD_leather\n",
      "generating duplicate samples for dataset FashionMNIST_4...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 502, 'Anomalies Ratio(%)': 5.02}\n",
      "generating duplicate samples for dataset FashionMNIST_4...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "generating duplicate samples for dataset FashionMNIST_4...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 501, 'Anomalies Ratio(%)': 5.01}\n",
      "remove the dataset FashionMNIST_4\n",
      "generating duplicate samples for dataset FashionMNIST_6...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 511, 'Anomalies Ratio(%)': 5.11}\n",
      "generating duplicate samples for dataset FashionMNIST_6...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 486, 'Anomalies Ratio(%)': 4.86}\n",
      "generating duplicate samples for dataset FashionMNIST_6...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 491, 'Anomalies Ratio(%)': 4.91}\n",
      "remove the dataset FashionMNIST_6\n",
      "generating duplicate samples for dataset CIFAR10_8...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 491, 'Anomalies Ratio(%)': 4.91}\n",
      "generating duplicate samples for dataset CIFAR10_8...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 467, 'Anomalies Ratio(%)': 4.67}\n",
      "generating duplicate samples for dataset CIFAR10_8...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 502, 'Anomalies Ratio(%)': 5.02}\n",
      "remove the dataset CIFAR10_8\n",
      "generating duplicate samples for dataset CIFAR10_9...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 474, 'Anomalies Ratio(%)': 4.74}\n",
      "generating duplicate samples for dataset CIFAR10_9...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 525, 'Anomalies Ratio(%)': 5.25}\n",
      "generating duplicate samples for dataset CIFAR10_9...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 545, 'Anomalies Ratio(%)': 5.45}\n",
      "remove the dataset CIFAR10_9\n",
      "generating duplicate samples for dataset MVTec-AD_metal_nut...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2847, 'Anomalies Ratio(%)': 28.47}\n",
      "generating duplicate samples for dataset MVTec-AD_metal_nut...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2725, 'Anomalies Ratio(%)': 27.25}\n",
      "generating duplicate samples for dataset MVTec-AD_metal_nut...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2755, 'Anomalies Ratio(%)': 27.55}\n",
      "remove the dataset MVTec-AD_metal_nut\n",
      "generating duplicate samples for dataset FashionMNIST_7...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 535, 'Anomalies Ratio(%)': 5.35}\n",
      "generating duplicate samples for dataset FashionMNIST_7...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 514, 'Anomalies Ratio(%)': 5.14}\n",
      "generating duplicate samples for dataset FashionMNIST_7...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 536, 'Anomalies Ratio(%)': 5.36}\n",
      "remove the dataset FashionMNIST_7\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_motion_blur\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_stripe\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_impulse_noise\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_translate\n",
      "generating duplicate samples for dataset CIFAR10_4...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 515, 'Anomalies Ratio(%)': 5.15}\n",
      "generating duplicate samples for dataset CIFAR10_4...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 498, 'Anomalies Ratio(%)': 4.98}\n",
      "generating duplicate samples for dataset CIFAR10_4...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 510, 'Anomalies Ratio(%)': 5.1}\n",
      "remove the dataset CIFAR10_4\n",
      "generating duplicate samples for dataset CIFAR10_5...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 499, 'Anomalies Ratio(%)': 4.99}\n",
      "generating duplicate samples for dataset CIFAR10_5...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 487, 'Anomalies Ratio(%)': 4.87}\n",
      "generating duplicate samples for dataset CIFAR10_5...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 497, 'Anomalies Ratio(%)': 4.97}\n",
      "remove the dataset CIFAR10_5\n",
      "generating duplicate samples for dataset FashionMNIST_9...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 518, 'Anomalies Ratio(%)': 5.18}\n",
      "generating duplicate samples for dataset FashionMNIST_9...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 523, 'Anomalies Ratio(%)': 5.23}\n",
      "generating duplicate samples for dataset FashionMNIST_9...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 499, 'Anomalies Ratio(%)': 4.99}\n",
      "remove the dataset FashionMNIST_9\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_brightness\n",
      "generating duplicate samples for dataset CIFAR10_7...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 487, 'Anomalies Ratio(%)': 4.87}\n",
      "generating duplicate samples for dataset CIFAR10_7...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 491, 'Anomalies Ratio(%)': 4.91}\n",
      "generating duplicate samples for dataset CIFAR10_7...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 492, 'Anomalies Ratio(%)': 4.92}\n",
      "remove the dataset CIFAR10_7\n",
      "generating duplicate samples for dataset CIFAR10_6...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 485, 'Anomalies Ratio(%)': 4.85}\n",
      "generating duplicate samples for dataset CIFAR10_6...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 488, 'Anomalies Ratio(%)': 4.88}\n",
      "generating duplicate samples for dataset CIFAR10_6...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 489, 'Anomalies Ratio(%)': 4.89}\n",
      "remove the dataset CIFAR10_6\n",
      "generating duplicate samples for dataset FashionMNIST_8...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 483, 'Anomalies Ratio(%)': 4.83}\n",
      "generating duplicate samples for dataset FashionMNIST_8...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 504, 'Anomalies Ratio(%)': 5.04}\n",
      "generating duplicate samples for dataset FashionMNIST_8...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 479, 'Anomalies Ratio(%)': 4.79}\n",
      "remove the dataset FashionMNIST_8\n",
      "generating duplicate samples for dataset CIFAR10_2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 499, 'Anomalies Ratio(%)': 4.99}\n",
      "generating duplicate samples for dataset CIFAR10_2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 489, 'Anomalies Ratio(%)': 4.89}\n",
      "generating duplicate samples for dataset CIFAR10_2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 479, 'Anomalies Ratio(%)': 4.79}\n",
      "remove the dataset CIFAR10_2\n",
      "generating duplicate samples for dataset MVTec-AD_tile...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2370, 'Anomalies Ratio(%)': 23.7}\n",
      "generating duplicate samples for dataset MVTec-AD_tile...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2412, 'Anomalies Ratio(%)': 24.12}\n",
      "generating duplicate samples for dataset MVTec-AD_tile...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2419, 'Anomalies Ratio(%)': 24.19}\n",
      "remove the dataset MVTec-AD_tile\n",
      "generating duplicate samples for dataset CIFAR10_3...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 513, 'Anomalies Ratio(%)': 5.13}\n",
      "generating duplicate samples for dataset CIFAR10_3...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 491, 'Anomalies Ratio(%)': 4.91}\n",
      "generating duplicate samples for dataset CIFAR10_3...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 511, 'Anomalies Ratio(%)': 5.11}\n",
      "remove the dataset CIFAR10_3\n",
      "generating duplicate samples for dataset MVTec-AD_carpet...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2275, 'Anomalies Ratio(%)': 22.75}\n",
      "generating duplicate samples for dataset MVTec-AD_carpet...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2223, 'Anomalies Ratio(%)': 22.23}\n",
      "generating duplicate samples for dataset MVTec-AD_carpet...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2311, 'Anomalies Ratio(%)': 23.11}\n",
      "remove the dataset MVTec-AD_carpet\n",
      "generating duplicate samples for dataset CIFAR10_1...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 521, 'Anomalies Ratio(%)': 5.21}\n",
      "generating duplicate samples for dataset CIFAR10_1...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 501, 'Anomalies Ratio(%)': 5.01}\n",
      "generating duplicate samples for dataset CIFAR10_1...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 512, 'Anomalies Ratio(%)': 5.12}\n",
      "remove the dataset CIFAR10_1\n",
      "generating duplicate samples for dataset MVTec-AD_capsule...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 3123, 'Anomalies Ratio(%)': 31.23}\n",
      "generating duplicate samples for dataset MVTec-AD_capsule...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 3050, 'Anomalies Ratio(%)': 30.5}\n",
      "generating duplicate samples for dataset MVTec-AD_capsule...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 3085, 'Anomalies Ratio(%)': 30.85}\n",
      "remove the dataset MVTec-AD_capsule\n",
      "generating duplicate samples for dataset CIFAR10_0...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 472, 'Anomalies Ratio(%)': 4.72}\n",
      "generating duplicate samples for dataset CIFAR10_0...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 455, 'Anomalies Ratio(%)': 4.55}\n",
      "generating duplicate samples for dataset CIFAR10_0...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 499, 'Anomalies Ratio(%)': 4.99}\n",
      "remove the dataset CIFAR10_0\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_canny_edges\n",
      "generating duplicate samples for dataset SVHN_7...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 510, 'Anomalies Ratio(%)': 5.1}\n",
      "generating duplicate samples for dataset SVHN_7...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 477, 'Anomalies Ratio(%)': 4.77}\n",
      "generating duplicate samples for dataset SVHN_7...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 484, 'Anomalies Ratio(%)': 4.84}\n",
      "remove the dataset SVHN_7\n",
      "generating duplicate samples for dataset MVTec-AD_grid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 1732, 'Anomalies Ratio(%)': 17.32}\n",
      "generating duplicate samples for dataset MVTec-AD_grid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 1641, 'Anomalies Ratio(%)': 16.41}\n",
      "generating duplicate samples for dataset MVTec-AD_grid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 1658, 'Anomalies Ratio(%)': 16.58}\n",
      "remove the dataset MVTec-AD_grid\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_fog\n",
      "generating duplicate samples for dataset MVTec-AD_bottle...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2188, 'Anomalies Ratio(%)': 21.88}\n",
      "generating duplicate samples for dataset MVTec-AD_bottle...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2179, 'Anomalies Ratio(%)': 21.79}\n",
      "generating duplicate samples for dataset MVTec-AD_bottle...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2205, 'Anomalies Ratio(%)': 22.05}\n",
      "remove the dataset MVTec-AD_bottle\n",
      "generating duplicate samples for dataset SVHN_6...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 531, 'Anomalies Ratio(%)': 5.31}\n",
      "generating duplicate samples for dataset SVHN_6...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 488, 'Anomalies Ratio(%)': 4.88}\n",
      "generating duplicate samples for dataset SVHN_6...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 514, 'Anomalies Ratio(%)': 5.14}\n",
      "remove the dataset SVHN_6\n",
      "generating duplicate samples for dataset SVHN_4...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 497, 'Anomalies Ratio(%)': 4.97}\n",
      "generating duplicate samples for dataset SVHN_4...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 496, 'Anomalies Ratio(%)': 4.96}\n",
      "generating duplicate samples for dataset SVHN_4...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 512, 'Anomalies Ratio(%)': 5.12}\n",
      "remove the dataset SVHN_4\n",
      "generating duplicate samples for dataset MVTec-AD_wood...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 1893, 'Anomalies Ratio(%)': 18.93}\n",
      "generating duplicate samples for dataset MVTec-AD_wood...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 1854, 'Anomalies Ratio(%)': 18.54}\n",
      "generating duplicate samples for dataset MVTec-AD_wood...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 1878, 'Anomalies Ratio(%)': 18.78}\n",
      "remove the dataset MVTec-AD_wood\n",
      "generating duplicate samples for dataset MVTec-AD_zipper...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 3130, 'Anomalies Ratio(%)': 31.3}\n",
      "generating duplicate samples for dataset MVTec-AD_zipper...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 3080, 'Anomalies Ratio(%)': 30.8}\n",
      "generating duplicate samples for dataset MVTec-AD_zipper...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2978, 'Anomalies Ratio(%)': 29.78}\n",
      "remove the dataset MVTec-AD_zipper\n",
      "generating duplicate samples for dataset MVTec-AD_cable...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2416, 'Anomalies Ratio(%)': 24.16}\n",
      "generating duplicate samples for dataset MVTec-AD_cable...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2469, 'Anomalies Ratio(%)': 24.69}\n",
      "generating duplicate samples for dataset MVTec-AD_cable...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 2370, 'Anomalies Ratio(%)': 23.7}\n",
      "remove the dataset MVTec-AD_cable\n",
      "generating duplicate samples for dataset SVHN_5...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 516, 'Anomalies Ratio(%)': 5.16}\n",
      "generating duplicate samples for dataset SVHN_5...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 502, 'Anomalies Ratio(%)': 5.02}\n",
      "generating duplicate samples for dataset SVHN_5...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 497, 'Anomalies Ratio(%)': 4.97}\n",
      "remove the dataset SVHN_5\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_zigzag\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset SVHN_1\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_scale\n",
      "generating duplicate samples for dataset SVHN_0...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 499, 'Anomalies Ratio(%)': 4.99}\n",
      "generating duplicate samples for dataset SVHN_0...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 495, 'Anomalies Ratio(%)': 4.95}\n",
      "generating duplicate samples for dataset SVHN_0...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 508, 'Anomalies Ratio(%)': 5.08}\n",
      "remove the dataset SVHN_0\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset SVHN_2\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset MNIST-C_shot_noise\n",
      "generating duplicate samples for dataset MVTec-AD_transistor...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 1283, 'Anomalies Ratio(%)': 12.83}\n",
      "generating duplicate samples for dataset MVTec-AD_transistor...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 1285, 'Anomalies Ratio(%)': 12.85}\n",
      "generating duplicate samples for dataset MVTec-AD_transistor...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 1268, 'Anomalies Ratio(%)': 12.68}\n",
      "remove the dataset MVTec-AD_transistor\n",
      "generating duplicate samples for dataset MVTec-AD_hazelnut...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 1405, 'Anomalies Ratio(%)': 14.05}\n",
      "generating duplicate samples for dataset MVTec-AD_hazelnut...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 1426, 'Anomalies Ratio(%)': 14.26}\n",
      "generating duplicate samples for dataset MVTec-AD_hazelnut...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 1387, 'Anomalies Ratio(%)': 13.87}\n",
      "remove the dataset MVTec-AD_hazelnut\n",
      "generating duplicate samples for dataset SVHN_3...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 484, 'Anomalies Ratio(%)': 4.84}\n",
      "generating duplicate samples for dataset SVHN_3...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 468, 'Anomalies Ratio(%)': 4.68}\n",
      "generating duplicate samples for dataset SVHN_3...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 512, 'Anomalies': 524, 'Anomalies Ratio(%)': 5.24}\n",
      "remove the dataset SVHN_3\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset yelp\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset imdb\n",
      "generating duplicate samples for dataset 20news_4...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 489, 'Anomalies Ratio(%)': 4.89}\n",
      "generating duplicate samples for dataset 20news_4...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 505, 'Anomalies Ratio(%)': 5.05}\n",
      "generating duplicate samples for dataset 20news_4...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 516, 'Anomalies Ratio(%)': 5.16}\n",
      "remove the dataset 20news_4\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset agnews_2\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset agnews_3\n",
      "generating duplicate samples for dataset 20news_5...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 515, 'Anomalies Ratio(%)': 5.15}\n",
      "generating duplicate samples for dataset 20news_5...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 515, 'Anomalies Ratio(%)': 5.15}\n",
      "generating duplicate samples for dataset 20news_5...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 517, 'Anomalies Ratio(%)': 5.17}\n",
      "remove the dataset 20news_5\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset agnews_1\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset agnews_0\n",
      "generating duplicate samples for dataset 20news_2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 488, 'Anomalies Ratio(%)': 4.88}\n",
      "generating duplicate samples for dataset 20news_2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 508, 'Anomalies Ratio(%)': 5.08}\n",
      "generating duplicate samples for dataset 20news_2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 501, 'Anomalies Ratio(%)': 5.01}\n",
      "remove the dataset 20news_2\n",
      "generating duplicate samples for dataset 20news_3...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 465, 'Anomalies Ratio(%)': 4.65}\n",
      "generating duplicate samples for dataset 20news_3...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 506, 'Anomalies Ratio(%)': 5.06}\n",
      "generating duplicate samples for dataset 20news_3...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 536, 'Anomalies Ratio(%)': 5.36}\n",
      "remove the dataset 20news_3\n",
      "generating duplicate samples for dataset 20news_1...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 477, 'Anomalies Ratio(%)': 4.77}\n",
      "generating duplicate samples for dataset 20news_1...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 493, 'Anomalies Ratio(%)': 4.93}\n",
      "generating duplicate samples for dataset 20news_1...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 481, 'Anomalies Ratio(%)': 4.81}\n",
      "remove the dataset 20news_1\n",
      "generating duplicate samples for dataset 20news_0...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 514, 'Anomalies Ratio(%)': 5.14}\n",
      "generating duplicate samples for dataset 20news_0...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 508, 'Anomalies Ratio(%)': 5.08}\n",
      "generating duplicate samples for dataset 20news_0...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 510, 'Anomalies Ratio(%)': 5.1}\n",
      "remove the dataset 20news_0\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 768, 'Anomalies': 500, 'Anomalies Ratio(%)': 5.0}\n",
      "remove the dataset amazon\n",
      "47 datasets, 14 models\n",
      "Experiment results are saved at: /Users/xxd/Documents/PhD/AD/ADBench/adbench/result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 26_optdigits...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 64, 'Anomalies': 290, 'Anomalies Ratio(%)': 2.9}\n",
      "Train data shape after filter corrcoef:  (7000, 64)\n",
      "epoch : 1000/5000, loss = 20.271698\n",
      "epoch : 2000/5000, loss = 17.891395\n",
      "epoch : 3000/5000, loss = 16.551147\n",
      "epoch : 4000/5000, loss = 15.799693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:50, 230.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 15.294242\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9928264498029049, AUC-PR: 0.8040786302669911\n",
      "Current experiment parameters: ('26_optdigits', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9928264498029049, 'aucpr': 0.8040786302669911}, fitting time: 90.61533784866333, inference time: 0.0044748783111572266\n",
      "generating duplicate samples for dataset 26_optdigits...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 64, 'Anomalies': 284, 'Anomalies Ratio(%)': 2.84}\n",
      "Train data shape after filter corrcoef:  (7000, 64)\n",
      "epoch : 1000/5000, loss = 21.450902\n",
      "epoch : 2000/5000, loss = 18.764909\n",
      "epoch : 3000/5000, loss = 17.528881\n",
      "epoch : 4000/5000, loss = 16.744098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [07:23, 220.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 16.250438\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9966098274644335, AUC-PR: 0.9116278200468905\n",
      "Current experiment parameters: ('26_optdigits', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9966098274644335, 'aucpr': 0.9116278200468905}, fitting time: 90.19946694374084, inference time: 0.0037689208984375\n",
      "generating duplicate samples for dataset 26_optdigits...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 64, 'Anomalies': 281, 'Anomalies Ratio(%)': 2.81}\n",
      "Train data shape after filter corrcoef:  (7000, 64)\n",
      "epoch : 1000/5000, loss = 21.417551\n",
      "epoch : 2000/5000, loss = 18.232668\n",
      "epoch : 3000/5000, loss = 16.778739\n",
      "epoch : 4000/5000, loss = 15.917046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [11:12, 224.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 15.406278\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9848169377490366, AUC-PR: 0.4751316897677132\n",
      "Current experiment parameters: ('26_optdigits', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9848169377490366, 'aucpr': 0.4751316897677132}, fitting time: 90.12695598602295, inference time: 0.0047130584716796875\n",
      "subsampling for dataset 22_magic.gamma...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3548, 'Anomalies Ratio(%)': 35.48}\n",
      "Train data shape after filter corrcoef:  (7000, 10)\n",
      "epoch : 1000/5000, loss = 0.777209\n",
      "epoch : 2000/5000, loss = 0.576117\n",
      "epoch : 3000/5000, loss = 0.496512\n",
      "epoch : 4000/5000, loss = 0.448043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [13:44, 21.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.417710\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9032683076492886, AUC-PR: 0.8062380869487534\n",
      "Current experiment parameters: ('22_magic.gamma', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9032683076492886, 'aucpr': 0.8062380869487534}, fitting time: 76.95230674743652, inference time: 0.0028791427612304688\n",
      "subsampling for dataset 22_magic.gamma...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3533, 'Anomalies Ratio(%)': 35.33}\n",
      "Train data shape after filter corrcoef:  (7000, 10)\n",
      "epoch : 1000/5000, loss = 0.886641\n",
      "epoch : 2000/5000, loss = 0.625749\n",
      "epoch : 3000/5000, loss = 0.534810\n",
      "epoch : 4000/5000, loss = 0.477748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [16:32, 29.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.438743\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9120424042015172, AUC-PR: 0.8238348034165572\n",
      "Current experiment parameters: ('22_magic.gamma', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9120424042015172, 'aucpr': 0.8238348034165572}, fitting time: 75.7403621673584, inference time: 0.0028328895568847656\n",
      "subsampling for dataset 22_magic.gamma...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 3500, 'Anomalies Ratio(%)': 35.0}\n",
      "Train data shape after filter corrcoef:  (7000, 10)\n",
      "epoch : 1000/5000, loss = 0.931415\n",
      "epoch : 2000/5000, loss = 0.628172\n",
      "epoch : 3000/5000, loss = 0.531252\n",
      "epoch : 4000/5000, loss = 0.472175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [19:43, 41.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.431457\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.888676923076923, AUC-PR: 0.7989398188715985\n",
      "Current experiment parameters: ('22_magic.gamma', 0.0, 3), model: Customized, metrics: {'aucroc': 0.888676923076923, 'aucpr': 0.7989398188715985}, fitting time: 76.10177206993103, inference time: 0.002664804458618164\n",
      "subsampling for dataset 16_http...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 46, 'Anomalies Ratio(%)': 0.46}\n",
      "Train data shape after filter corrcoef:  (7000, 3)\n",
      "epoch : 1000/5000, loss = 0.300987\n",
      "epoch : 2000/5000, loss = 0.321759\n",
      "epoch : 3000/5000, loss = 0.346848\n",
      "epoch : 4000/5000, loss = 0.486938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [21:00, 14.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.400121\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8076499856473065, AUC-PR: 0.10544088701418365\n",
      "Current experiment parameters: ('16_http', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8076499856473065, 'aucpr': 0.10544088701418365}, fitting time: 74.1927900314331, inference time: 0.0025620460510253906\n",
      "subsampling for dataset 16_http...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 35, 'Anomalies Ratio(%)': 0.35}\n",
      "Train data shape after filter corrcoef:  (7000, 3)\n",
      "epoch : 1000/5000, loss = 0.400850\n",
      "epoch : 2000/5000, loss = 0.461556\n",
      "epoch : 3000/5000, loss = 0.199191\n",
      "epoch : 4000/5000, loss = 0.358041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [22:17, 17.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.263759\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.5891973244147157, AUC-PR: 0.011149066811371358\n",
      "Current experiment parameters: ('16_http', 0.0, 2), model: Customized, metrics: {'aucroc': 0.5891973244147157, 'aucpr': 0.011149066811371358}, fitting time: 73.77029609680176, inference time: 0.0026001930236816406\n",
      "subsampling for dataset 16_http...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 34, 'Anomalies Ratio(%)': 0.34}\n",
      "Train data shape after filter corrcoef:  (7000, 3)\n",
      "epoch : 1000/5000, loss = 0.222888\n",
      "epoch : 2000/5000, loss = 0.347997\n",
      "epoch : 3000/5000, loss = 0.315304\n",
      "epoch : 4000/5000, loss = 0.390541\n",
      "epoch : 5000/5000, loss = 0.247272\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.685484949832776, AUC-PR: 0.015548646063891247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [23:33, 20.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('16_http', 0.0, 3), model: Customized, metrics: {'aucroc': 0.685484949832776, 'aucpr': 0.015548646063891247}, fitting time: 73.53047704696655, inference time: 0.0035791397094726562\n",
      "subsampling for dataset 32_shuttle...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 669, 'Anomalies Ratio(%)': 6.69}\n",
      "Train data shape after filter corrcoef:  (7000, 9)\n",
      "epoch : 1000/5000, loss = 0.470768\n",
      "epoch : 2000/5000, loss = 0.180036\n",
      "epoch : 3000/5000, loss = 0.145593\n",
      "epoch : 4000/5000, loss = 0.147136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [25:10, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.116870\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9140791220745148, AUC-PR: 0.5238503315382452\n",
      "Current experiment parameters: ('32_shuttle', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9140791220745148, 'aucpr': 0.5238503315382452}, fitting time: 77.32320785522461, inference time: 0.00475311279296875\n",
      "subsampling for dataset 32_shuttle...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 697, 'Anomalies Ratio(%)': 6.97}\n",
      "Train data shape after filter corrcoef:  (7000, 9)\n",
      "epoch : 1000/5000, loss = 0.358818\n",
      "epoch : 2000/5000, loss = 0.167223\n",
      "epoch : 3000/5000, loss = 0.166830\n",
      "epoch : 4000/5000, loss = 0.118706\n",
      "epoch : 5000/5000, loss = 0.101919\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8586399551531837, AUC-PR: 0.27249656026934876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [27:07, 14.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('32_shuttle', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8586399551531837, 'aucpr': 0.27249656026934876}, fitting time: 82.94563102722168, inference time: 0.010259151458740234\n",
      "subsampling for dataset 32_shuttle...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 714, 'Anomalies Ratio(%)': 7.14}\n",
      "Train data shape after filter corrcoef:  (7000, 9)\n",
      "epoch : 1000/5000, loss = 0.363994\n",
      "epoch : 2000/5000, loss = 0.200208\n",
      "epoch : 3000/5000, loss = 0.178158\n",
      "epoch : 4000/5000, loss = 0.134159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [29:33, 21.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.112367\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.876775399024495, AUC-PR: 0.3094382010903516\n",
      "Current experiment parameters: ('32_shuttle', 0.0, 3), model: Customized, metrics: {'aucroc': 0.876775399024495, 'aucpr': 0.3094382010903516}, fitting time: 78.57950615882874, inference time: 0.0029015541076660156\n",
      "generating duplicate samples for dataset 12_fault...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 3499, 'Anomalies Ratio(%)': 34.99}\n",
      "Train data shape after filter corrcoef:  (7000, 24)\n",
      "epoch : 1000/5000, loss = 3.388688\n",
      "epoch : 2000/5000, loss = 2.438422\n",
      "epoch : 3000/5000, loss = 2.037392\n",
      "epoch : 4000/5000, loss = 1.837609\n",
      "epoch : 5000/5000, loss = 1.710506\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8999409035409035, AUC-PR: 0.8858264060349519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [31:58, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('12_fault', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8999409035409035, 'aucpr': 0.8858264060349519}, fitting time: 81.69319081306458, inference time: 0.012199878692626953\n",
      "generating duplicate samples for dataset 12_fault...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 3479, 'Anomalies Ratio(%)': 34.79}\n",
      "Train data shape after filter corrcoef:  (7000, 25)\n",
      "epoch : 1000/5000, loss = 3.277294\n",
      "epoch : 2000/5000, loss = 2.328708\n",
      "epoch : 3000/5000, loss = 1.964695\n",
      "epoch : 4000/5000, loss = 1.758824\n",
      "epoch : 5000/5000, loss = 1.633619\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.918189635584389, AUC-PR: 0.8856790943313533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [34:26, 17.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('12_fault', 0.0, 2), model: Customized, metrics: {'aucroc': 0.918189635584389, 'aucpr': 0.8856790943313533}, fitting time: 85.69696617126465, inference time: 0.010387897491455078\n",
      "generating duplicate samples for dataset 12_fault...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 3473, 'Anomalies Ratio(%)': 34.73}\n",
      "Train data shape after filter corrcoef:  (7000, 25)\n",
      "epoch : 1000/5000, loss = 3.355896\n",
      "epoch : 2000/5000, loss = 2.616717\n",
      "epoch : 3000/5000, loss = 2.264550\n",
      "epoch : 4000/5000, loss = 2.056617\n",
      "epoch : 5000/5000, loss = 1.942719\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9109166782666319, AUC-PR: 0.8821494566405452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [36:49, 24.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('12_fault', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9109166782666319, 'aucpr': 0.8821494566405452}, fitting time: 84.03064393997192, inference time: 0.003919839859008789\n",
      "generating duplicate samples for dataset 47_yeast...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 8, 'Anomalies': 3398, 'Anomalies Ratio(%)': 33.98}\n",
      "Train data shape after filter corrcoef:  (7000, 8)\n",
      "epoch : 1000/5000, loss = 0.558192\n",
      "epoch : 2000/5000, loss = 0.384821\n",
      "epoch : 3000/5000, loss = 0.313170\n",
      "epoch : 4000/5000, loss = 0.273808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [39:32, 13.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.247780\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8112312305469179, AUC-PR: 0.7210151511200986\n",
      "Current experiment parameters: ('47_yeast', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8112312305469179, 'aucpr': 0.7210151511200986}, fitting time: 84.36310386657715, inference time: 0.004221916198730469\n",
      "generating duplicate samples for dataset 47_yeast...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 8, 'Anomalies': 3463, 'Anomalies Ratio(%)': 34.63}\n",
      "Train data shape after filter corrcoef:  (7000, 8)\n",
      "epoch : 1000/5000, loss = 0.540676\n",
      "epoch : 2000/5000, loss = 0.381871\n",
      "epoch : 3000/5000, loss = 0.311099\n",
      "epoch : 4000/5000, loss = 0.267955\n",
      "epoch : 5000/5000, loss = 0.242834\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8085526280270865, AUC-PR: 0.7391570032362196\n",
      "Current experiment parameters: ('47_yeast', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8085526280270865, 'aucpr': 0.7391570032362196}, fitting time: 80.74558711051941, inference time: 0.0036079883575439453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [42:24, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 47_yeast...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 8, 'Anomalies': 3310, 'Anomalies Ratio(%)': 33.1}\n",
      "Train data shape after filter corrcoef:  (7000, 8)\n",
      "epoch : 1000/5000, loss = 0.535160\n",
      "epoch : 2000/5000, loss = 0.384244\n",
      "epoch : 3000/5000, loss = 0.314272\n",
      "epoch : 4000/5000, loss = 0.273278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [45:25, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.249158\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8102437039345172, AUC-PR: 0.7293256943965913\n",
      "Current experiment parameters: ('47_yeast', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8102437039345172, 'aucpr': 0.7293256943965913}, fitting time: 80.60598611831665, inference time: 0.0025529861450195312\n",
      "subsampling for dataset 13_fraud...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "Train data shape after filter corrcoef:  (7000, 29)\n",
      "epoch : 1000/5000, loss = 9.605180\n",
      "epoch : 2000/5000, loss = 8.043032\n",
      "epoch : 3000/5000, loss = 7.280975\n",
      "epoch : 4000/5000, loss = 6.828752\n",
      "epoch : 5000/5000, loss = 6.505037\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8973631508678238, AUC-PR: 0.014018510598690128\n",
      "Current experiment parameters: ('13_fraud', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8973631508678238, 'aucpr': 0.014018510598690128}, fitting time: 88.41302108764648, inference time: 0.003275156021118164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145it [48:58, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsampling for dataset 13_fraud...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 15, 'Anomalies Ratio(%)': 0.15}\n",
      "Train data shape after filter corrcoef:  (7000, 29)\n",
      "epoch : 1000/5000, loss = 10.227030\n",
      "epoch : 2000/5000, loss = 8.417999\n",
      "epoch : 3000/5000, loss = 7.601528\n",
      "epoch : 4000/5000, loss = 7.135544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146it [52:17, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 6.832746\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9758931552587646, AUC-PR: 0.043129685686681504\n",
      "Current experiment parameters: ('13_fraud', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9758931552587646, 'aucpr': 0.043129685686681504}, fitting time: 86.33028626441956, inference time: 0.0031387805938720703\n",
      "subsampling for dataset 13_fraud...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 13, 'Anomalies Ratio(%)': 0.13}\n",
      "Train data shape after filter corrcoef:  (7000, 29)\n",
      "epoch : 1000/5000, loss = 9.559781\n",
      "epoch : 2000/5000, loss = 7.837322\n",
      "epoch : 3000/5000, loss = 7.005215\n",
      "epoch : 4000/5000, loss = 6.535579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "147it [56:02, 34.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 6.168317\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9610313751668892, AUC-PR: 0.024588166157889575\n",
      "Current experiment parameters: ('13_fraud', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9610313751668892, 'aucpr': 0.024588166157889575}, fitting time: 85.99782204627991, inference time: 0.003116130828857422\n",
      "generating duplicate samples for dataset 35_SpamBase...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 57, 'Anomalies': 3980, 'Anomalies Ratio(%)': 39.8}\n",
      "Train data shape after filter corrcoef:  (7000, 57)\n",
      "epoch : 1000/5000, loss = 28.471886\n",
      "epoch : 2000/5000, loss = 24.931372\n",
      "epoch : 3000/5000, loss = 23.213867\n",
      "epoch : 4000/5000, loss = 22.343385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [1:00:11, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 21.630673\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9164037240465894, AUC-PR: 0.8578747355765189\n",
      "Current experiment parameters: ('35_SpamBase', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9164037240465894, 'aucpr': 0.8578747355765189}, fitting time: 97.8935968875885, inference time: 0.003847837448120117\n",
      "generating duplicate samples for dataset 35_SpamBase...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 57, 'Anomalies': 3946, 'Anomalies Ratio(%)': 39.46}\n",
      "Train data shape after filter corrcoef:  (7000, 57)\n",
      "epoch : 1000/5000, loss = 27.374729\n",
      "epoch : 2000/5000, loss = 23.906709\n",
      "epoch : 3000/5000, loss = 22.501094\n",
      "epoch : 4000/5000, loss = 21.652651\n",
      "epoch : 5000/5000, loss = 21.003179\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8913882046969877, AUC-PR: 0.8298265979071724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [1:03:26, 26.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('35_SpamBase', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8913882046969877, 'aucpr': 0.8298265979071724}, fitting time: 96.2340178489685, inference time: 0.012083053588867188\n",
      "generating duplicate samples for dataset 35_SpamBase...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 57, 'Anomalies': 3970, 'Anomalies Ratio(%)': 39.7}\n",
      "Train data shape after filter corrcoef:  (7000, 57)\n",
      "epoch : 1000/5000, loss = 26.894820\n",
      "epoch : 2000/5000, loss = 23.004098\n",
      "epoch : 3000/5000, loss = 21.192082\n",
      "epoch : 4000/5000, loss = 20.303581\n",
      "epoch : 5000/5000, loss = 19.515124\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9538514164878563, AUC-PR: 0.8957146347126943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171it [1:07:51, 39.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('35_SpamBase', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9538514164878563, 'aucpr': 0.8957146347126943}, fitting time: 98.15305805206299, inference time: 0.007096767425537109\n",
      "generating duplicate samples for dataset 41_Waveform...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 279, 'Anomalies Ratio(%)': 2.79}\n",
      "Train data shape after filter corrcoef:  (7000, 21)\n",
      "epoch : 1000/5000, loss = 6.171719\n",
      "epoch : 2000/5000, loss = 5.055603\n",
      "epoch : 3000/5000, loss = 4.585418\n",
      "epoch : 4000/5000, loss = 4.323610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "193it [1:10:20, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 4.131646\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9979791299235744, AUC-PR: 0.9501139447155592\n",
      "Current experiment parameters: ('41_Waveform', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9979791299235744, 'aucpr': 0.9501139447155592}, fitting time: 80.14651608467102, inference time: 0.0032007694244384766\n",
      "generating duplicate samples for dataset 41_Waveform...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 290, 'Anomalies Ratio(%)': 2.9}\n",
      "Train data shape after filter corrcoef:  (7000, 21)\n",
      "epoch : 1000/5000, loss = 5.558377\n",
      "epoch : 2000/5000, loss = 4.703206\n",
      "epoch : 3000/5000, loss = 4.293114\n",
      "epoch : 4000/5000, loss = 4.073629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "194it [1:13:17, 25.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 3.911238\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9953399544649233, AUC-PR: 0.9484154543038684\n",
      "Current experiment parameters: ('41_Waveform', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9953399544649233, 'aucpr': 0.9484154543038684}, fitting time: 83.22583794593811, inference time: 0.00467991828918457\n",
      "generating duplicate samples for dataset 41_Waveform...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 286, 'Anomalies Ratio(%)': 2.86}\n",
      "Train data shape after filter corrcoef:  (7000, 21)\n",
      "epoch : 1000/5000, loss = 5.847266\n",
      "epoch : 2000/5000, loss = 4.847879\n",
      "epoch : 3000/5000, loss = 4.405610\n",
      "epoch : 4000/5000, loss = 4.160652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "195it [1:16:09, 32.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 3.982019\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9990423137699318, AUC-PR: 0.9742927421366651\n",
      "Current experiment parameters: ('41_Waveform', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9990423137699318, 'aucpr': 0.9742927421366651}, fitting time: 85.14748406410217, inference time: 0.003197908401489258\n",
      "generating duplicate samples for dataset 17_InternetAds...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 1555, 'Anomalies': 1844, 'Anomalies Ratio(%)': 18.44}\n",
      "Train data shape after filter corrcoef:  (7000, 852)\n",
      "epoch : 1000/5000, loss = 730.412737\n",
      "epoch : 2000/5000, loss = 699.402777\n",
      "epoch : 3000/5000, loss = 686.067795\n",
      "epoch : 4000/5000, loss = 679.293933\n",
      "epoch : 5000/5000, loss = 674.090205\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 1.0, AUC-PR: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "217it [1:29:49, 35.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('17_InternetAds', 0.0, 1), model: Customized, metrics: {'aucroc': 1.0, 'aucpr': 1.0}, fitting time: 539.3161191940308, inference time: 0.03758525848388672\n",
      "generating duplicate samples for dataset 17_InternetAds...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 1555, 'Anomalies': 1857, 'Anomalies Ratio(%)': 18.57}\n",
      "Train data shape after filter corrcoef:  (7000, 854)\n",
      "epoch : 1000/5000, loss = 745.752125\n",
      "epoch : 2000/5000, loss = 717.713165\n",
      "epoch : 3000/5000, loss = 705.898371\n",
      "epoch : 4000/5000, loss = 699.900094\n",
      "epoch : 5000/5000, loss = 694.784616\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 1.0, AUC-PR: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "218it [1:41:46, 62.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('17_InternetAds', 0.0, 2), model: Customized, metrics: {'aucroc': 1.0, 'aucpr': 1.0}, fitting time: 528.1221849918365, inference time: 0.028120040893554688\n",
      "generating duplicate samples for dataset 17_InternetAds...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 1555, 'Anomalies': 1881, 'Anomalies Ratio(%)': 18.81}\n",
      "Train data shape after filter corrcoef:  (7000, 854)\n",
      "epoch : 1000/5000, loss = 732.363567\n",
      "epoch : 2000/5000, loss = 702.631634\n",
      "epoch : 3000/5000, loss = 690.437496\n",
      "epoch : 4000/5000, loss = 682.758330\n",
      "epoch : 5000/5000, loss = 677.949871\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 1.0, AUC-PR: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "219it [1:53:57, 97.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('17_InternetAds', 0.0, 3), model: Customized, metrics: {'aucroc': 1.0, 'aucpr': 1.0}, fitting time: 537.9146900177002, inference time: 0.03804278373718262\n",
      "generating duplicate samples for dataset 15_Hepatitis...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 19, 'Anomalies': 1613, 'Anomalies Ratio(%)': 16.13}\n",
      "Train data shape after filter corrcoef:  (7000, 19)\n",
      "epoch : 1000/5000, loss = 2.894888\n",
      "epoch : 2000/5000, loss = 1.989043\n",
      "epoch : 3000/5000, loss = 1.650190\n",
      "epoch : 4000/5000, loss = 1.488038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [1:55:28, 39.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.383996\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.823549941531225, AUC-PR: 0.6994851270202818\n",
      "Current experiment parameters: ('15_Hepatitis', 0.0, 1), model: Customized, metrics: {'aucroc': 0.823549941531225, 'aucpr': 0.6994851270202818}, fitting time: 78.87853598594666, inference time: 0.0031440258026123047\n",
      "generating duplicate samples for dataset 15_Hepatitis...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 19, 'Anomalies': 1608, 'Anomalies Ratio(%)': 16.08}\n",
      "Train data shape after filter corrcoef:  (7000, 19)\n",
      "epoch : 1000/5000, loss = 3.327755\n",
      "epoch : 2000/5000, loss = 2.405264\n",
      "epoch : 3000/5000, loss = 2.042062\n",
      "epoch : 4000/5000, loss = 1.794119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "242it [1:56:59, 41.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.655868\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8624468144710781, AUC-PR: 0.7480280141233873\n",
      "Current experiment parameters: ('15_Hepatitis', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8624468144710781, 'aucpr': 0.7480280141233873}, fitting time: 79.20946979522705, inference time: 0.0027828216552734375\n",
      "generating duplicate samples for dataset 15_Hepatitis...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 19, 'Anomalies': 1637, 'Anomalies Ratio(%)': 16.37}\n",
      "Train data shape after filter corrcoef:  (7000, 19)\n",
      "epoch : 1000/5000, loss = 2.293081\n",
      "epoch : 2000/5000, loss = 1.696982\n",
      "epoch : 3000/5000, loss = 1.451320\n",
      "epoch : 4000/5000, loss = 1.310884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "243it [1:58:29, 43.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.206952\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8697771525562963, AUC-PR: 0.7514879962330865\n",
      "Current experiment parameters: ('15_Hepatitis', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8697771525562963, 'aucpr': 0.7514879962330865}, fitting time: 78.60922408103943, inference time: 0.003103017807006836\n",
      "generating duplicate samples for dataset 6_cardio...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 952, 'Anomalies Ratio(%)': 9.52}\n",
      "Train data shape after filter corrcoef:  (7000, 21)\n",
      "epoch : 1000/5000, loss = 3.776387\n",
      "epoch : 2000/5000, loss = 2.890879\n",
      "epoch : 3000/5000, loss = 2.522064\n",
      "epoch : 4000/5000, loss = 2.296148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "265it [2:01:26, 21.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.190693\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9306303497534153, AUC-PR: 0.7160497276620839\n",
      "Current experiment parameters: ('6_cardio', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9306303497534153, 'aucpr': 0.7160497276620839}, fitting time: 79.68836283683777, inference time: 0.0035147666931152344\n",
      "generating duplicate samples for dataset 6_cardio...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 955, 'Anomalies Ratio(%)': 9.55}\n",
      "Train data shape after filter corrcoef:  (7000, 21)\n",
      "epoch : 1000/5000, loss = 4.331330\n",
      "epoch : 2000/5000, loss = 3.477971\n",
      "epoch : 3000/5000, loss = 3.049165\n",
      "epoch : 4000/5000, loss = 2.806621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "266it [2:04:36, 28.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.621914\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9372020757429749, AUC-PR: 0.7294004374796519\n",
      "Current experiment parameters: ('6_cardio', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9372020757429749, 'aucpr': 0.7294004374796519}, fitting time: 79.78367400169373, inference time: 0.0028769969940185547\n",
      "generating duplicate samples for dataset 6_cardio...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 1001, 'Anomalies Ratio(%)': 10.01}\n",
      "Train data shape after filter corrcoef:  (7000, 21)\n",
      "epoch : 1000/5000, loss = 3.504527\n",
      "epoch : 2000/5000, loss = 2.817830\n",
      "epoch : 3000/5000, loss = 2.485431\n",
      "epoch : 4000/5000, loss = 2.294535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "267it [2:08:09, 37.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.152249\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9435666666666667, AUC-PR: 0.7607750379199486\n",
      "Current experiment parameters: ('6_cardio', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9435666666666667, 'aucpr': 0.7607750379199486}, fitting time: 78.14126992225647, inference time: 0.0028901100158691406\n",
      "generating duplicate samples for dataset 40_vowels...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 12, 'Anomalies': 346, 'Anomalies Ratio(%)': 3.46}\n",
      "Train data shape after filter corrcoef:  (7000, 12)\n",
      "epoch : 1000/5000, loss = 1.116434\n",
      "epoch : 2000/5000, loss = 0.898737\n",
      "epoch : 3000/5000, loss = 0.755019\n",
      "epoch : 4000/5000, loss = 0.670663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "289it [2:10:12, 17.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.604276\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.958560215682108, AUC-PR: 0.6466358655053142\n",
      "Current experiment parameters: ('40_vowels', 0.0, 1), model: Customized, metrics: {'aucroc': 0.958560215682108, 'aucpr': 0.6466358655053142}, fitting time: 77.58609199523926, inference time: 0.002652883529663086\n",
      "generating duplicate samples for dataset 40_vowels...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 12, 'Anomalies': 354, 'Anomalies Ratio(%)': 3.54}\n",
      "Train data shape after filter corrcoef:  (7000, 12)\n",
      "epoch : 1000/5000, loss = 0.867939\n",
      "epoch : 2000/5000, loss = 0.643635\n",
      "epoch : 3000/5000, loss = 0.554104\n",
      "epoch : 4000/5000, loss = 0.493205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "290it [2:12:13, 21.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.455031\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9638875487345321, AUC-PR: 0.717983487098261\n",
      "Current experiment parameters: ('40_vowels', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9638875487345321, 'aucpr': 0.717983487098261}, fitting time: 75.42573118209839, inference time: 0.0029129981994628906\n",
      "generating duplicate samples for dataset 40_vowels...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 12, 'Anomalies': 363, 'Anomalies Ratio(%)': 3.63}\n",
      "Train data shape after filter corrcoef:  (7000, 12)\n",
      "epoch : 1000/5000, loss = 0.949773\n",
      "epoch : 2000/5000, loss = 0.724212\n",
      "epoch : 3000/5000, loss = 0.620165\n",
      "epoch : 4000/5000, loss = 0.553218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "291it [2:14:20, 27.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.515710\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9606529596755512, AUC-PR: 0.7104293677358923\n",
      "Current experiment parameters: ('40_vowels', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9606529596755512, 'aucpr': 0.7104293677358923}, fitting time: 76.96865892410278, inference time: 0.002679109573364258\n",
      "subsampling for dataset 9_census...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "Train data shape after filter corrcoef:  (7000, 456)\n",
      "epoch : 1000/5000, loss = 370.932496\n",
      "epoch : 2000/5000, loss = 351.144975\n",
      "epoch : 3000/5000, loss = 343.410609\n",
      "epoch : 4000/5000, loss = 339.402116\n",
      "epoch : 5000/5000, loss = 336.440243\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9980644232154001, AUC-PR: 0.9842415285809781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [2:20:34, 20.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('9_census', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9980644232154001, 'aucpr': 0.9842415285809781}, fitting time: 265.94727087020874, inference time: 0.014777898788452148\n",
      "subsampling for dataset 9_census...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 628, 'Anomalies Ratio(%)': 6.28}\n",
      "Train data shape after filter corrcoef:  (7000, 459)\n",
      "epoch : 1000/5000, loss = 375.399386\n",
      "epoch : 2000/5000, loss = 357.448846\n",
      "epoch : 3000/5000, loss = 349.905944\n",
      "epoch : 4000/5000, loss = 345.836156\n",
      "epoch : 5000/5000, loss = 343.634712\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9977944069489422, AUC-PR: 0.9800178133335457\n",
      "Current experiment parameters: ('9_census', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9977944069489422, 'aucpr': 0.9800178133335457}, fitting time: 270.78877806663513, inference time: 0.012878179550170898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "314it [2:26:18, 33.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsampling for dataset 9_census...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 500, 'Anomalies': 652, 'Anomalies Ratio(%)': 6.52}\n",
      "Train data shape after filter corrcoef:  (7000, 462)\n",
      "epoch : 1000/5000, loss = 359.955493\n",
      "epoch : 2000/5000, loss = 339.228627\n",
      "epoch : 3000/5000, loss = 330.672022\n",
      "epoch : 4000/5000, loss = 326.417904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "315it [2:32:52, 52.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 323.291353\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9573859501004396, AUC-PR: 0.7691611067466434\n",
      "Current experiment parameters: ('9_census', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9573859501004396, 'aucpr': 0.7691611067466434}, fitting time: 269.5576419830322, inference time: 0.012903213500976562\n",
      "generating duplicate samples for dataset 45_wine...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 13, 'Anomalies': 748, 'Anomalies Ratio(%)': 7.48}\n",
      "Train data shape after filter corrcoef:  (7000, 13)\n",
      "epoch : 1000/5000, loss = 2.042385\n",
      "epoch : 2000/5000, loss = 1.622456\n",
      "epoch : 3000/5000, loss = 1.430727\n",
      "epoch : 4000/5000, loss = 1.297346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "337it [2:34:37, 22.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.209146\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9490193366611775, AUC-PR: 0.7771761564603229\n",
      "Current experiment parameters: ('45_wine', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9490193366611775, 'aucpr': 0.7771761564603229}, fitting time: 76.24245095252991, inference time: 0.0026178359985351562\n",
      "generating duplicate samples for dataset 45_wine...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 13, 'Anomalies': 741, 'Anomalies Ratio(%)': 7.41}\n",
      "Train data shape after filter corrcoef:  (7000, 13)\n",
      "epoch : 1000/5000, loss = 2.040326\n",
      "epoch : 2000/5000, loss = 1.603477\n",
      "epoch : 3000/5000, loss = 1.395439\n",
      "epoch : 4000/5000, loss = 1.265572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "338it [2:36:29, 26.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.170732\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9165482977578008, AUC-PR: 0.7080883210581447\n",
      "Current experiment parameters: ('45_wine', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9165482977578008, 'aucpr': 0.7080883210581447}, fitting time: 76.69179701805115, inference time: 0.0027573108673095703\n",
      "generating duplicate samples for dataset 45_wine...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 13, 'Anomalies': 751, 'Anomalies Ratio(%)': 7.51}\n",
      "Train data shape after filter corrcoef:  (7000, 13)\n",
      "epoch : 1000/5000, loss = 2.064597\n",
      "epoch : 2000/5000, loss = 1.617157\n",
      "epoch : 3000/5000, loss = 1.388645\n",
      "epoch : 4000/5000, loss = 1.238096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "339it [2:38:19, 30.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.133536\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9365861861861862, AUC-PR: 0.7707383879144816\n",
      "Current experiment parameters: ('45_wine', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9365861861861862, 'aucpr': 0.7707383879144816}, fitting time: 76.18089866638184, inference time: 0.0027840137481689453\n",
      "generating duplicate samples for dataset 25_musk...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 166, 'Anomalies': 305, 'Anomalies Ratio(%)': 3.05}\n",
      "Train data shape after filter corrcoef:  (7000, 166)\n",
      "epoch : 1000/5000, loss = 39.072848\n",
      "epoch : 2000/5000, loss = 33.439493\n",
      "epoch : 3000/5000, loss = 30.002051\n",
      "epoch : 4000/5000, loss = 27.726237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361it [2:40:59, 16.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 26.225726\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9974358590993362, AUC-PR: 0.9266987890413326\n",
      "Current experiment parameters: ('25_musk', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9974358590993362, 'aucpr': 0.9266987890413326}, fitting time: 132.5462610721588, inference time: 0.006262063980102539\n",
      "generating duplicate samples for dataset 25_musk...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 166, 'Anomalies': 311, 'Anomalies Ratio(%)': 3.11}\n",
      "Train data shape after filter corrcoef:  (7000, 166)\n",
      "epoch : 1000/5000, loss = 37.877518\n",
      "epoch : 2000/5000, loss = 31.525403\n",
      "epoch : 3000/5000, loss = 28.626695\n",
      "epoch : 4000/5000, loss = 26.811966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "362it [2:43:36, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 25.513198\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9987534723378126, AUC-PR: 0.9775024335749356\n",
      "Current experiment parameters: ('25_musk', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9987534723378126, 'aucpr': 0.9775024335749356}, fitting time: 132.01924800872803, inference time: 0.006901979446411133\n",
      "generating duplicate samples for dataset 25_musk...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 166, 'Anomalies': 324, 'Anomalies Ratio(%)': 3.24}\n",
      "Train data shape after filter corrcoef:  (7000, 166)\n",
      "epoch : 1000/5000, loss = 43.147967\n",
      "epoch : 2000/5000, loss = 35.231378\n",
      "epoch : 3000/5000, loss = 31.475421\n",
      "epoch : 4000/5000, loss = 29.373195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "363it [2:46:22, 29.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 27.976669\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.995774012663757, AUC-PR: 0.930964600702223\n",
      "Current experiment parameters: ('25_musk', 0.0, 3), model: Customized, metrics: {'aucroc': 0.995774012663757, 'aucpr': 0.930964600702223}, fitting time: 133.13380575180054, inference time: 0.006186008453369141\n",
      "subsampling for dataset 1_ALOI...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 315, 'Anomalies Ratio(%)': 3.15}\n",
      "Train data shape after filter corrcoef:  (7000, 27)\n",
      "epoch : 1000/5000, loss = 6.392798\n",
      "epoch : 2000/5000, loss = 5.116668\n",
      "epoch : 3000/5000, loss = 4.560927\n",
      "epoch : 4000/5000, loss = 4.223427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "385it [2:49:41, 16.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 4.018277\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9205971504297785, AUC-PR: 0.265542455753461\n",
      "Current experiment parameters: ('1_ALOI', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9205971504297785, 'aucpr': 0.265542455753461}, fitting time: 79.46199917793274, inference time: 0.0030198097229003906\n",
      "subsampling for dataset 1_ALOI...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 334, 'Anomalies Ratio(%)': 3.34}\n",
      "Train data shape after filter corrcoef:  (7000, 27)\n",
      "epoch : 1000/5000, loss = 7.255427\n",
      "epoch : 2000/5000, loss = 5.504507\n",
      "epoch : 3000/5000, loss = 4.841082\n",
      "epoch : 4000/5000, loss = 4.453481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "386it [2:53:30, 24.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 4.220287\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8913310344827585, AUC-PR: 0.24155649267615886\n",
      "Current experiment parameters: ('1_ALOI', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8913310344827585, 'aucpr': 0.24155649267615886}, fitting time: 79.20072078704834, inference time: 0.0033020973205566406\n",
      "subsampling for dataset 1_ALOI...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 332, 'Anomalies Ratio(%)': 3.32}\n",
      "Train data shape after filter corrcoef:  (7000, 27)\n",
      "epoch : 1000/5000, loss = 6.555786\n",
      "epoch : 2000/5000, loss = 5.332558\n",
      "epoch : 3000/5000, loss = 4.739936\n",
      "epoch : 4000/5000, loss = 4.308499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [2:57:19, 35.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 4.094097\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9134827586206896, AUC-PR: 0.28838875123663077\n",
      "Current experiment parameters: ('1_ALOI', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9134827586206896, 'aucpr': 0.28838875123663077}, fitting time: 79.32441711425781, inference time: 0.003340005874633789\n",
      "generating duplicate samples for dataset 18_Ionosphere...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 32, 'Anomalies': 3637, 'Anomalies Ratio(%)': 36.37}\n",
      "Train data shape after filter corrcoef:  (7000, 32)\n",
      "epoch : 1000/5000, loss = 2.921865\n",
      "epoch : 2000/5000, loss = 2.167876\n",
      "epoch : 3000/5000, loss = 1.842020\n",
      "epoch : 4000/5000, loss = 1.676850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "409it [2:59:02, 16.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.560787\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9488380333592771, AUC-PR: 0.940782428068619\n",
      "Current experiment parameters: ('18_Ionosphere', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9488380333592771, 'aucpr': 0.940782428068619}, fitting time: 78.44105792045593, inference time: 0.002853870391845703\n",
      "generating duplicate samples for dataset 18_Ionosphere...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 32, 'Anomalies': 3560, 'Anomalies Ratio(%)': 35.6}\n",
      "Train data shape after filter corrcoef:  (7000, 32)\n",
      "epoch : 1000/5000, loss = 2.613095\n",
      "epoch : 2000/5000, loss = 2.080312\n",
      "epoch : 3000/5000, loss = 1.827002\n",
      "epoch : 4000/5000, loss = 1.675251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [3:00:43, 19.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.586184\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9594678817627034, AUC-PR: 0.9479764322164103\n",
      "Current experiment parameters: ('18_Ionosphere', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9594678817627034, 'aucpr': 0.9479764322164103}, fitting time: 79.4688172340393, inference time: 0.0029168128967285156\n",
      "generating duplicate samples for dataset 18_Ionosphere...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 32, 'Anomalies': 3611, 'Anomalies Ratio(%)': 36.11}\n",
      "Train data shape after filter corrcoef:  (7000, 32)\n",
      "epoch : 1000/5000, loss = 2.720646\n",
      "epoch : 2000/5000, loss = 2.141543\n",
      "epoch : 3000/5000, loss = 1.807484\n",
      "epoch : 4000/5000, loss = 1.628649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "411it [3:02:19, 23.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.514778\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9461507597618817, AUC-PR: 0.9386955123807481\n",
      "Current experiment parameters: ('18_Ionosphere', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9461507597618817, 'aucpr': 0.9386955123807481}, fitting time: 79.65746212005615, inference time: 0.002894163131713867\n",
      "generating duplicate samples for dataset 20_letter...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 32, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "Train data shape after filter corrcoef:  (7000, 32)\n",
      "epoch : 1000/5000, loss = 5.870147\n",
      "epoch : 2000/5000, loss = 4.681426\n",
      "epoch : 3000/5000, loss = 4.188035\n",
      "epoch : 4000/5000, loss = 3.908348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "433it [3:04:34, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 3.729193\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9808074504344486, AUC-PR: 0.8448651099017055\n",
      "Current experiment parameters: ('20_letter', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9808074504344486, 'aucpr': 0.8448651099017055}, fitting time: 79.97953295707703, inference time: 0.004144906997680664\n",
      "generating duplicate samples for dataset 20_letter...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 32, 'Anomalies': 610, 'Anomalies Ratio(%)': 6.1}\n",
      "Train data shape after filter corrcoef:  (7000, 32)\n",
      "epoch : 1000/5000, loss = 5.535408\n",
      "epoch : 2000/5000, loss = 4.403114\n",
      "epoch : 3000/5000, loss = 3.915688\n",
      "epoch : 4000/5000, loss = 3.649958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "434it [3:06:39, 17.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 3.474976\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9650521521364238, AUC-PR: 0.8193610437938539\n",
      "Current experiment parameters: ('20_letter', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9650521521364238, 'aucpr': 0.8193610437938539}, fitting time: 79.79868602752686, inference time: 0.003422260284423828\n",
      "generating duplicate samples for dataset 20_letter...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 32, 'Anomalies': 636, 'Anomalies Ratio(%)': 6.36}\n",
      "Train data shape after filter corrcoef:  (7000, 32)\n",
      "epoch : 1000/5000, loss = 6.288071\n",
      "epoch : 2000/5000, loss = 5.212294\n",
      "epoch : 3000/5000, loss = 4.665668\n",
      "epoch : 4000/5000, loss = 4.331257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "435it [3:08:47, 22.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 4.084022\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9845932762865808, AUC-PR: 0.8960805321108044\n",
      "Current experiment parameters: ('20_letter', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9845932762865808, 'aucpr': 0.8960805321108044}, fitting time: 79.32594585418701, inference time: 0.0030908584594726562\n",
      "generating duplicate samples for dataset 19_landsat...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 2052, 'Anomalies Ratio(%)': 20.52}\n",
      "Train data shape after filter corrcoef:  (7000, 36)\n",
      "epoch : 1000/5000, loss = 2.373251\n",
      "epoch : 2000/5000, loss = 1.921113\n",
      "epoch : 3000/5000, loss = 1.645445\n",
      "epoch : 4000/5000, loss = 1.482221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "457it [3:11:44, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.387560\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9558753431970715, AUC-PR: 0.7788137232120654\n",
      "Current experiment parameters: ('19_landsat', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9558753431970715, 'aucpr': 0.7788137232120654}, fitting time: 82.0051281452179, inference time: 0.0030319690704345703\n",
      "generating duplicate samples for dataset 19_landsat...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 2081, 'Anomalies Ratio(%)': 20.81}\n",
      "Train data shape after filter corrcoef:  (7000, 36)\n",
      "epoch : 1000/5000, loss = 2.458326\n",
      "epoch : 2000/5000, loss = 1.949750\n",
      "epoch : 3000/5000, loss = 1.700764\n",
      "epoch : 4000/5000, loss = 1.564951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "458it [3:14:38, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.466333\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9401985938444272, AUC-PR: 0.7366804858012523\n",
      "Current experiment parameters: ('19_landsat', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9401985938444272, 'aucpr': 0.7366804858012523}, fitting time: 82.78701782226562, inference time: 0.0029621124267578125\n",
      "generating duplicate samples for dataset 19_landsat...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 1998, 'Anomalies Ratio(%)': 19.98}\n",
      "Train data shape after filter corrcoef:  (7000, 36)\n",
      "epoch : 1000/5000, loss = 2.363889\n",
      "epoch : 2000/5000, loss = 1.970606\n",
      "epoch : 3000/5000, loss = 1.777849\n",
      "epoch : 4000/5000, loss = 1.652496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "459it [3:17:58, 29.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.564752\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9531754645914787, AUC-PR: 0.760629804430062\n",
      "Current experiment parameters: ('19_landsat', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9531754645914787, 'aucpr': 0.760629804430062}, fitting time: 82.32111930847168, inference time: 0.003401041030883789\n",
      "generating duplicate samples for dataset 14_glass...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 7, 'Anomalies': 412, 'Anomalies Ratio(%)': 4.12}\n",
      "Train data shape after filter corrcoef:  (7000, 7)\n",
      "epoch : 1000/5000, loss = 0.216334\n",
      "epoch : 2000/5000, loss = 0.164259\n",
      "epoch : 3000/5000, loss = 0.137509\n",
      "epoch : 4000/5000, loss = 0.122881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "481it [3:19:47, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.112735\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.837215106106151, AUC-PR: 0.2862938225639795\n",
      "Current experiment parameters: ('14_glass', 0.0, 1), model: Customized, metrics: {'aucroc': 0.837215106106151, 'aucpr': 0.2862938225639795}, fitting time: 78.52639698982239, inference time: 0.002732992172241211\n",
      "generating duplicate samples for dataset 14_glass...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 7, 'Anomalies': 397, 'Anomalies Ratio(%)': 3.97}\n",
      "Train data shape after filter corrcoef:  (7000, 7)\n",
      "epoch : 1000/5000, loss = 0.216074\n",
      "epoch : 2000/5000, loss = 0.155890\n",
      "epoch : 3000/5000, loss = 0.128983\n",
      "epoch : 4000/5000, loss = 0.112884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "482it [3:21:30, 17.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.102121\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8449476284786737, AUC-PR: 0.21739720787308092\n",
      "Current experiment parameters: ('14_glass', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8449476284786737, 'aucpr': 0.21739720787308092}, fitting time: 77.31060099601746, inference time: 0.0029211044311523438\n",
      "generating duplicate samples for dataset 14_glass...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 7, 'Anomalies': 402, 'Anomalies Ratio(%)': 4.02}\n",
      "Train data shape after filter corrcoef:  (7000, 7)\n",
      "epoch : 1000/5000, loss = 0.218766\n",
      "epoch : 2000/5000, loss = 0.162704\n",
      "epoch : 3000/5000, loss = 0.137345\n",
      "epoch : 4000/5000, loss = 0.120413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "483it [3:23:26, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.109493\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.7966207274679281, AUC-PR: 0.3151321872590694\n",
      "Current experiment parameters: ('14_glass', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7966207274679281, 'aucpr': 0.3151321872590694}, fitting time: 76.19946074485779, inference time: 0.0026857852935791016\n",
      "subsampling for dataset 23_mammography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 230, 'Anomalies Ratio(%)': 2.3}\n",
      "Train data shape after filter corrcoef:  (7000, 6)\n",
      "epoch : 1000/5000, loss = 0.149615\n",
      "epoch : 2000/5000, loss = 0.117420\n",
      "epoch : 3000/5000, loss = 0.100794\n",
      "epoch : 4000/5000, loss = 0.087051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "505it [3:25:26, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.078418\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.6026631856367959, AUC-PR: 0.12924421775100609\n",
      "Current experiment parameters: ('23_mammography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6026631856367959, 'aucpr': 0.12924421775100609}, fitting time: 76.09371185302734, inference time: 0.002482175827026367\n",
      "subsampling for dataset 23_mammography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 241, 'Anomalies Ratio(%)': 2.41}\n",
      "Train data shape after filter corrcoef:  (7000, 6)\n",
      "epoch : 1000/5000, loss = 0.175350\n",
      "epoch : 2000/5000, loss = 0.133312\n",
      "epoch : 3000/5000, loss = 0.112650\n",
      "epoch : 4000/5000, loss = 0.099528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "506it [3:27:37, 16.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.087859\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.6532141772920461, AUC-PR: 0.24000535678171622\n",
      "Current experiment parameters: ('23_mammography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6532141772920461, 'aucpr': 0.24000535678171622}, fitting time: 75.7761549949646, inference time: 0.002763032913208008\n",
      "subsampling for dataset 23_mammography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 227, 'Anomalies Ratio(%)': 2.27}\n",
      "Train data shape after filter corrcoef:  (7000, 6)\n",
      "epoch : 1000/5000, loss = 0.177613\n",
      "epoch : 2000/5000, loss = 0.127902\n",
      "epoch : 3000/5000, loss = 0.110812\n",
      "epoch : 4000/5000, loss = 0.095171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "507it [3:29:51, 22.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.087669\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.6471340582617766, AUC-PR: 0.1848889311552964\n",
      "Current experiment parameters: ('23_mammography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6471340582617766, 'aucpr': 0.1848889311552964}, fitting time: 75.97996211051941, inference time: 0.0026159286499023438\n",
      "generating duplicate samples for dataset 30_satellite...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 3138, 'Anomalies Ratio(%)': 31.38}\n",
      "Train data shape after filter corrcoef:  (7000, 36)\n",
      "epoch : 1000/5000, loss = 3.016205\n",
      "epoch : 2000/5000, loss = 2.539188\n",
      "epoch : 3000/5000, loss = 2.298641\n",
      "epoch : 4000/5000, loss = 2.149742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "529it [3:32:57, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.053854\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9561769458776921, AUC-PR: 0.8709128821904657\n",
      "Current experiment parameters: ('30_satellite', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9561769458776921, 'aucpr': 0.8709128821904657}, fitting time: 82.22650098800659, inference time: 0.0032968521118164062\n",
      "generating duplicate samples for dataset 30_satellite...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 3190, 'Anomalies Ratio(%)': 31.9}\n",
      "Train data shape after filter corrcoef:  (7000, 36)\n",
      "epoch : 1000/5000, loss = 3.035099\n",
      "epoch : 2000/5000, loss = 2.586308\n",
      "epoch : 3000/5000, loss = 2.336232\n",
      "epoch : 4000/5000, loss = 2.181770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "530it [3:36:15, 21.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.061915\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9632084682973335, AUC-PR: 0.8888412569233362\n",
      "Current experiment parameters: ('30_satellite', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9632084682973335, 'aucpr': 0.8888412569233362}, fitting time: 83.45776319503784, inference time: 0.003323793411254883\n",
      "generating duplicate samples for dataset 30_satellite...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 3089, 'Anomalies Ratio(%)': 30.89}\n",
      "Train data shape after filter corrcoef:  (7000, 36)\n",
      "epoch : 1000/5000, loss = 3.176465\n",
      "epoch : 2000/5000, loss = 2.671057\n",
      "epoch : 3000/5000, loss = 2.414111\n",
      "epoch : 4000/5000, loss = 2.245234\n",
      "epoch : 5000/5000, loss = 2.118263\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9575364357374391, AUC-PR: 0.8668111383190465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "531it [3:39:52, 31.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('30_satellite', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9575364357374391, 'aucpr': 0.8668111383190465}, fitting time: 83.7971601486206, inference time: 0.008213996887207031\n",
      "generating duplicate samples for dataset 24_mnist...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 100, 'Anomalies': 959, 'Anomalies Ratio(%)': 9.59}\n",
      "Train data shape after filter corrcoef:  (7000, 100)\n",
      "epoch : 1000/5000, loss = 57.229123\n",
      "epoch : 2000/5000, loss = 51.846243\n",
      "epoch : 3000/5000, loss = 49.533604\n",
      "epoch : 4000/5000, loss = 48.225367\n",
      "epoch : 5000/5000, loss = 47.373734\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9978349823828254, AUC-PR: 0.9755161428260473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "553it [3:43:44, 18.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('24_mnist', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9978349823828254, 'aucpr': 0.9755161428260473}, fitting time: 109.85812282562256, inference time: 0.01004791259765625\n",
      "generating duplicate samples for dataset 24_mnist...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 100, 'Anomalies': 948, 'Anomalies Ratio(%)': 9.48}\n",
      "Train data shape after filter corrcoef:  (7000, 100)\n",
      "epoch : 1000/5000, loss = 57.701671\n",
      "epoch : 2000/5000, loss = 51.909775\n",
      "epoch : 3000/5000, loss = 49.541874\n",
      "epoch : 4000/5000, loss = 48.289216\n",
      "epoch : 5000/5000, loss = 47.403059\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9949218506917795, AUC-PR: 0.918076824909101\n",
      "Current experiment parameters: ('24_mnist', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9949218506917795, 'aucpr': 0.918076824909101}, fitting time: 108.69994616508484, inference time: 0.005811929702758789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "554it [3:47:54, 27.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 24_mnist...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 100, 'Anomalies': 942, 'Anomalies Ratio(%)': 9.42}\n",
      "Train data shape after filter corrcoef:  (7000, 100)\n",
      "epoch : 1000/5000, loss = 59.555214\n",
      "epoch : 2000/5000, loss = 54.412119\n",
      "epoch : 3000/5000, loss = 51.896132\n",
      "epoch : 4000/5000, loss = 50.454305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "555it [3:51:48, 38.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 49.537299\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9985524982735323, AUC-PR: 0.9750941801308539\n",
      "Current experiment parameters: ('24_mnist', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9985524982735323, 'aucpr': 0.9750941801308539}, fitting time: 108.19971799850464, inference time: 0.005845069885253906\n",
      "generating duplicate samples for dataset 38_thyroid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 252, 'Anomalies Ratio(%)': 2.52}\n",
      "Train data shape after filter corrcoef:  (7000, 6)\n",
      "epoch : 1000/5000, loss = 0.416440\n",
      "epoch : 2000/5000, loss = 0.319908\n",
      "epoch : 3000/5000, loss = 0.262929\n",
      "epoch : 4000/5000, loss = 0.228268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "577it [3:54:24, 18.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.207637\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8108485132118943, AUC-PR: 0.1992379671777604\n",
      "Current experiment parameters: ('38_thyroid', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8108485132118943, 'aucpr': 0.1992379671777604}, fitting time: 75.74679708480835, inference time: 0.003638029098510742\n",
      "generating duplicate samples for dataset 38_thyroid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 258, 'Anomalies Ratio(%)': 2.58}\n",
      "Train data shape after filter corrcoef:  (7000, 6)\n",
      "epoch : 1000/5000, loss = 0.378171\n",
      "epoch : 2000/5000, loss = 0.297924\n",
      "epoch : 3000/5000, loss = 0.242717\n",
      "epoch : 4000/5000, loss = 0.211341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "578it [3:56:58, 24.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.190602\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.818897148011072, AUC-PR: 0.18230528539769753\n",
      "Current experiment parameters: ('38_thyroid', 0.0, 2), model: Customized, metrics: {'aucroc': 0.818897148011072, 'aucpr': 0.18230528539769753}, fitting time: 76.0500819683075, inference time: 0.0034389495849609375\n",
      "generating duplicate samples for dataset 38_thyroid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 243, 'Anomalies Ratio(%)': 2.43}\n",
      "Train data shape after filter corrcoef:  (7000, 6)\n",
      "epoch : 1000/5000, loss = 0.388707\n",
      "epoch : 2000/5000, loss = 0.298126\n",
      "epoch : 3000/5000, loss = 0.252135\n",
      "epoch : 4000/5000, loss = 0.222159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "579it [3:59:37, 31.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.198250\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8346944601747546, AUC-PR: 0.10958982882752416\n",
      "Current experiment parameters: ('38_thyroid', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8346944601747546, 'aucpr': 0.10958982882752416}, fitting time: 75.82128882408142, inference time: 0.003158092498779297\n",
      "generating duplicate samples for dataset 42_WBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 424, 'Anomalies Ratio(%)': 4.24}\n",
      "Train data shape after filter corrcoef:  (7000, 9)\n",
      "epoch : 1000/5000, loss = 0.725033\n",
      "epoch : 2000/5000, loss = 0.543908\n",
      "epoch : 3000/5000, loss = 0.461770\n",
      "epoch : 4000/5000, loss = 0.406988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [4:01:40, 15.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.375728\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8964921849091871, AUC-PR: 0.4929182420496931\n",
      "Current experiment parameters: ('42_WBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8964921849091871, 'aucpr': 0.4929182420496931}, fitting time: 76.65505886077881, inference time: 0.0028879642486572266\n",
      "generating duplicate samples for dataset 42_WBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 421, 'Anomalies Ratio(%)': 4.21}\n",
      "Train data shape after filter corrcoef:  (7000, 9)\n",
      "epoch : 1000/5000, loss = 0.887470\n",
      "epoch : 2000/5000, loss = 0.647804\n",
      "epoch : 3000/5000, loss = 0.555487\n",
      "epoch : 4000/5000, loss = 0.496399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "602it [4:03:54, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.456389\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9225679601462482, AUC-PR: 0.4797289392746438\n",
      "Current experiment parameters: ('42_WBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9225679601462482, 'aucpr': 0.4797289392746438}, fitting time: 76.03441095352173, inference time: 0.0028028488159179688\n",
      "generating duplicate samples for dataset 42_WBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 452, 'Anomalies Ratio(%)': 4.52}\n",
      "Train data shape after filter corrcoef:  (7000, 9)\n",
      "epoch : 1000/5000, loss = 0.784328\n",
      "epoch : 2000/5000, loss = 0.607063\n",
      "epoch : 3000/5000, loss = 0.513614\n",
      "epoch : 4000/5000, loss = 0.456893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "603it [4:05:50, 24.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.415772\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8596907862306934, AUC-PR: 0.4902720228530858\n",
      "Current experiment parameters: ('42_WBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8596907862306934, 'aucpr': 0.4902720228530858}, fitting time: 76.48839592933655, inference time: 0.002513885498046875\n",
      "generating duplicate samples for dataset 21_Lymphography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 18, 'Anomalies': 387, 'Anomalies Ratio(%)': 3.87}\n",
      "Train data shape after filter corrcoef:  (7000, 18)\n",
      "epoch : 1000/5000, loss = 2.272013\n",
      "epoch : 2000/5000, loss = 1.678274\n",
      "epoch : 3000/5000, loss = 1.425196\n",
      "epoch : 4000/5000, loss = 1.288648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [4:07:35, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.192234\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9203871538571907, AUC-PR: 0.5503816872402727\n",
      "Current experiment parameters: ('21_Lymphography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9203871538571907, 'aucpr': 0.5503816872402727}, fitting time: 76.8116819858551, inference time: 0.002946138381958008\n",
      "generating duplicate samples for dataset 21_Lymphography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 18, 'Anomalies': 388, 'Anomalies Ratio(%)': 3.88}\n",
      "Train data shape after filter corrcoef:  (7000, 18)\n",
      "epoch : 1000/5000, loss = 2.557961\n",
      "epoch : 2000/5000, loss = 1.942931\n",
      "epoch : 3000/5000, loss = 1.657163\n",
      "epoch : 4000/5000, loss = 1.492185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "626it [4:09:25, 16.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.390169\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9502337510163087, AUC-PR: 0.6542342852035272\n",
      "Current experiment parameters: ('21_Lymphography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9502337510163087, 'aucpr': 0.6542342852035272}, fitting time: 76.32937502861023, inference time: 0.0029020309448242188\n",
      "generating duplicate samples for dataset 21_Lymphography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 18, 'Anomalies': 435, 'Anomalies Ratio(%)': 4.35}\n",
      "Train data shape after filter corrcoef:  (7000, 18)\n",
      "epoch : 1000/5000, loss = 2.518013\n",
      "epoch : 2000/5000, loss = 1.908266\n",
      "epoch : 3000/5000, loss = 1.602000\n",
      "epoch : 4000/5000, loss = 1.414967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "627it [4:11:12, 20.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.305939\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9538273921200751, AUC-PR: 0.6689100797458725\n",
      "Current experiment parameters: ('21_Lymphography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9538273921200751, 'aucpr': 0.6689100797458725}, fitting time: 76.45273184776306, inference time: 0.0033431053161621094\n",
      "subsampling for dataset 8_celeba...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 222, 'Anomalies Ratio(%)': 2.22}\n",
      "Train data shape after filter corrcoef:  (7000, 39)\n",
      "epoch : 1000/5000, loss = 16.125825\n",
      "epoch : 2000/5000, loss = 14.015408\n",
      "epoch : 3000/5000, loss = 12.949469\n",
      "epoch : 4000/5000, loss = 12.261916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "649it [4:13:28, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 11.851082\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9911150011958618, AUC-PR: 0.8513805432704878\n",
      "Current experiment parameters: ('8_celeba', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9911150011958618, 'aucpr': 0.8513805432704878}, fitting time: 81.09489178657532, inference time: 0.003392934799194336\n",
      "subsampling for dataset 8_celeba...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 238, 'Anomalies Ratio(%)': 2.38}\n",
      "Train data shape after filter corrcoef:  (7000, 39)\n",
      "epoch : 1000/5000, loss = 14.721295\n",
      "epoch : 2000/5000, loss = 12.739373\n",
      "epoch : 3000/5000, loss = 11.835488\n",
      "epoch : 4000/5000, loss = 11.273180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "650it [4:15:38, 16.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 10.911662\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.994388316927856, AUC-PR: 0.9071277579307512\n",
      "Current experiment parameters: ('8_celeba', 0.0, 2), model: Customized, metrics: {'aucroc': 0.994388316927856, 'aucpr': 0.9071277579307512}, fitting time: 82.54504895210266, inference time: 0.003355264663696289\n",
      "subsampling for dataset 8_celeba...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 39, 'Anomalies': 216, 'Anomalies Ratio(%)': 2.16}\n",
      "Train data shape after filter corrcoef:  (7000, 39)\n",
      "epoch : 1000/5000, loss = 15.623485\n",
      "epoch : 2000/5000, loss = 13.603657\n",
      "epoch : 3000/5000, loss = 12.588608\n",
      "epoch : 4000/5000, loss = 11.956517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "651it [4:17:55, 22.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 11.536052\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9960424583933954, AUC-PR: 0.8674540613870023\n",
      "Current experiment parameters: ('8_celeba', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9960424583933954, 'aucpr': 0.8674540613870023}, fitting time: 81.77138090133667, inference time: 0.003216981887817383\n",
      "subsampling for dataset 33_skin...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2081, 'Anomalies Ratio(%)': 20.81}\n",
      "Train data shape after filter corrcoef:  (7000, 3)\n",
      "epoch : 1000/5000, loss = 0.564145\n",
      "epoch : 2000/5000, loss = 0.469990\n",
      "epoch : 3000/5000, loss = 0.424194\n",
      "epoch : 4000/5000, loss = 0.378015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "673it [4:19:13, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.372473\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.6354605078563411, AUC-PR: 0.3274371230308795\n",
      "Current experiment parameters: ('33_skin', 0.0, 1), model: Customized, metrics: {'aucroc': 0.6354605078563411, 'aucpr': 0.3274371230308795}, fitting time: 73.97116804122925, inference time: 0.0025489330291748047\n",
      "subsampling for dataset 33_skin...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2082, 'Anomalies Ratio(%)': 20.82}\n",
      "Train data shape after filter corrcoef:  (7000, 3)\n",
      "epoch : 1000/5000, loss = 0.370222\n",
      "epoch : 2000/5000, loss = 0.459165\n",
      "epoch : 3000/5000, loss = 0.451549\n",
      "epoch : 4000/5000, loss = 0.322658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "674it [4:20:29, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.539682\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.6413817263157895, AUC-PR: 0.3595744091764256\n",
      "Current experiment parameters: ('33_skin', 0.0, 2), model: Customized, metrics: {'aucroc': 0.6413817263157895, 'aucpr': 0.3595744091764256}, fitting time: 72.89044880867004, inference time: 0.0025620460510253906\n",
      "subsampling for dataset 33_skin...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 2066, 'Anomalies Ratio(%)': 20.66}\n",
      "Train data shape after filter corrcoef:  (7000, 3)\n",
      "epoch : 1000/5000, loss = 0.325068\n",
      "epoch : 2000/5000, loss = 0.344536\n",
      "epoch : 3000/5000, loss = 0.329402\n",
      "epoch : 4000/5000, loss = 0.452622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "675it [4:21:45, 16.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.442365\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.6174735700731906, AUC-PR: 0.319337590500012\n",
      "Current experiment parameters: ('33_skin', 0.0, 3), model: Customized, metrics: {'aucroc': 0.6174735700731906, 'aucpr': 0.319337590500012}, fitting time: 73.37752914428711, inference time: 0.002862691879272461\n",
      "subsampling for dataset 34_smtp...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "Train data shape after filter corrcoef:  (7000, 3)\n",
      "epoch : 1000/5000, loss = 0.430031\n",
      "epoch : 2000/5000, loss = 0.322660\n",
      "epoch : 3000/5000, loss = 0.409778\n",
      "epoch : 4000/5000, loss = 0.510006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "697it [4:23:00,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.430156\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9546515505168389, AUC-PR: 0.0072992700729927005\n",
      "Current experiment parameters: ('34_smtp', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9546515505168389, 'aucpr': 0.0072992700729927005}, fitting time: 72.69511294364929, inference time: 0.0026121139526367188\n",
      "subsampling for dataset 34_smtp...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 4, 'Anomalies Ratio(%)': 0.04}\n",
      "Train data shape after filter corrcoef:  (7000, 3)\n",
      "epoch : 1000/5000, loss = 0.766907\n",
      "epoch : 2000/5000, loss = 0.291462\n",
      "epoch : 3000/5000, loss = 0.244931\n",
      "epoch : 4000/5000, loss = 0.332165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "698it [4:24:17, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.317058\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.7222407469156386, AUC-PR: 0.001199040767386091\n",
      "Current experiment parameters: ('34_smtp', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7222407469156386, 'aucpr': 0.001199040767386091}, fitting time: 73.35607099533081, inference time: 0.0026769638061523438\n",
      "subsampling for dataset 34_smtp...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 3, 'Anomalies': 5, 'Anomalies Ratio(%)': 0.05}\n",
      "Train data shape after filter corrcoef:  (7000, 3)\n",
      "epoch : 1000/5000, loss = 0.348195\n",
      "epoch : 2000/5000, loss = 0.290823\n",
      "epoch : 3000/5000, loss = 0.252388\n",
      "epoch : 4000/5000, loss = 0.236250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "699it [4:25:32, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.233361\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.3602401601067379, AUC-PR: 0.0009227953476472555\n",
      "Current experiment parameters: ('34_smtp', 0.0, 3), model: Customized, metrics: {'aucroc': 0.3602401601067379, 'aucpr': 0.0009227953476472555}, fitting time: 72.62668490409851, inference time: 0.003386974334716797\n",
      "generating duplicate samples for dataset 28_pendigits...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 16, 'Anomalies': 206, 'Anomalies Ratio(%)': 2.06}\n",
      "Train data shape after filter corrcoef:  (7000, 16)\n",
      "epoch : 1000/5000, loss = 1.583625\n",
      "epoch : 2000/5000, loss = 1.180054\n",
      "epoch : 3000/5000, loss = 1.013996\n",
      "epoch : 4000/5000, loss = 0.920423\n",
      "epoch : 5000/5000, loss = 0.862971\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9307297042095786, AUC-PR: 0.5423103239038671\n",
      "Current experiment parameters: ('28_pendigits', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9307297042095786, 'aucpr': 0.5423103239038671}, fitting time: 76.50751066207886, inference time: 0.0035932064056396484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "721it [4:28:54, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 28_pendigits...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 16, 'Anomalies': 228, 'Anomalies Ratio(%)': 2.28}\n",
      "Train data shape after filter corrcoef:  (7000, 16)\n",
      "epoch : 1000/5000, loss = 1.782551\n",
      "epoch : 2000/5000, loss = 1.288902\n",
      "epoch : 3000/5000, loss = 1.092784\n",
      "epoch : 4000/5000, loss = 0.993825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "722it [4:32:11, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.931286\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9083791429259289, AUC-PR: 0.35948561152867975\n",
      "Current experiment parameters: ('28_pendigits', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9083791429259289, 'aucpr': 0.35948561152867975}, fitting time: 76.77102303504944, inference time: 0.0028731822967529297\n",
      "generating duplicate samples for dataset 28_pendigits...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 16, 'Anomalies': 238, 'Anomalies Ratio(%)': 2.38}\n",
      "Train data shape after filter corrcoef:  (7000, 16)\n",
      "epoch : 1000/5000, loss = 1.495050\n",
      "epoch : 2000/5000, loss = 1.155105\n",
      "epoch : 3000/5000, loss = 0.997889\n",
      "epoch : 4000/5000, loss = 0.904801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "723it [4:35:28, 27.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.843384\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9083425098216475, AUC-PR: 0.34254793017181606\n",
      "Current experiment parameters: ('28_pendigits', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9083425098216475, 'aucpr': 0.34254793017181606}, fitting time: 76.54203677177429, inference time: 0.0029921531677246094\n",
      "generating duplicate samples for dataset 39_vertebral...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 1268, 'Anomalies Ratio(%)': 12.68}\n",
      "Train data shape after filter corrcoef:  (7000, 6)\n",
      "epoch : 1000/5000, loss = 0.328879\n",
      "epoch : 2000/5000, loss = 0.259656\n",
      "epoch : 3000/5000, loss = 0.221608\n",
      "epoch : 4000/5000, loss = 0.195392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "745it [4:37:30, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.177777\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8316582965046204, AUC-PR: 0.5548808670308314\n",
      "Current experiment parameters: ('39_vertebral', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8316582965046204, 'aucpr': 0.5548808670308314}, fitting time: 75.56507110595703, inference time: 0.0026540756225585938\n",
      "generating duplicate samples for dataset 39_vertebral...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 1307, 'Anomalies Ratio(%)': 13.07}\n",
      "Train data shape after filter corrcoef:  (7000, 6)\n",
      "epoch : 1000/5000, loss = 0.317928\n",
      "epoch : 2000/5000, loss = 0.237025\n",
      "epoch : 3000/5000, loss = 0.201302\n",
      "epoch : 4000/5000, loss = 0.177222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "746it [4:39:20, 17.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.160165\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8207986415425067, AUC-PR: 0.5288789257015868\n",
      "Current experiment parameters: ('39_vertebral', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8207986415425067, 'aucpr': 0.5288789257015868}, fitting time: 75.51947021484375, inference time: 0.0033190250396728516\n",
      "generating duplicate samples for dataset 39_vertebral...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 1287, 'Anomalies Ratio(%)': 12.87}\n",
      "Train data shape after filter corrcoef:  (7000, 6)\n",
      "epoch : 1000/5000, loss = 0.335391\n",
      "epoch : 2000/5000, loss = 0.256304\n",
      "epoch : 3000/5000, loss = 0.217659\n",
      "epoch : 4000/5000, loss = 0.194153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "747it [4:41:21, 23.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.178212\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.797928452216245, AUC-PR: 0.472809255826148\n",
      "Current experiment parameters: ('39_vertebral', 0.0, 3), model: Customized, metrics: {'aucroc': 0.797928452216245, 'aucpr': 0.472809255826148}, fitting time: 75.72606492042542, inference time: 0.0025300979614257812\n",
      "subsampling for dataset 11_donors...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 618, 'Anomalies Ratio(%)': 6.18}\n",
      "Train data shape after filter corrcoef:  (7000, 10)\n",
      "epoch : 1000/5000, loss = 0.634027\n",
      "epoch : 2000/5000, loss = 0.446305\n",
      "epoch : 3000/5000, loss = 0.349817\n",
      "epoch : 4000/5000, loss = 0.280122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "769it [4:43:10, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.244875\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.7725236426479766, AUC-PR: 0.3098530665549925\n",
      "Current experiment parameters: ('11_donors', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7725236426479766, 'aucpr': 0.3098530665549925}, fitting time: 75.03402900695801, inference time: 0.0026769638061523438\n",
      "subsampling for dataset 11_donors...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 578, 'Anomalies Ratio(%)': 5.78}\n",
      "Train data shape after filter corrcoef:  (7000, 10)\n",
      "epoch : 1000/5000, loss = 0.775321\n",
      "epoch : 2000/5000, loss = 0.491045\n",
      "epoch : 3000/5000, loss = 0.380515\n",
      "epoch : 4000/5000, loss = 0.310971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "770it [4:45:06, 15.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.276850\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8068439960660109, AUC-PR: 0.44555472251700223\n",
      "Current experiment parameters: ('11_donors', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8068439960660109, 'aucpr': 0.44555472251700223}, fitting time: 74.74645781517029, inference time: 0.0029191970825195312\n",
      "subsampling for dataset 11_donors...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 597, 'Anomalies Ratio(%)': 5.97}\n",
      "Train data shape after filter corrcoef:  (7000, 10)\n",
      "epoch : 1000/5000, loss = 0.982537\n",
      "epoch : 2000/5000, loss = 0.531929\n",
      "epoch : 3000/5000, loss = 0.410718\n",
      "epoch : 4000/5000, loss = 0.350227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "771it [4:46:54, 20.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.312371\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8134561419838046, AUC-PR: 0.4263851239071993\n",
      "Current experiment parameters: ('11_donors', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8134561419838046, 'aucpr': 0.4263851239071993}, fitting time: 76.3938410282135, inference time: 0.0029671192169189453\n",
      "generating duplicate samples for dataset 43_WDBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 30, 'Anomalies': 264, 'Anomalies Ratio(%)': 2.64}\n",
      "Train data shape after filter corrcoef:  (7000, 27)\n",
      "epoch : 1000/5000, loss = 4.153611\n",
      "epoch : 2000/5000, loss = 3.377707\n",
      "epoch : 3000/5000, loss = 3.042562\n",
      "epoch : 4000/5000, loss = 2.843786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "793it [4:48:59, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.695311\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9710693840760274, AUC-PR: 0.6208552588423546\n",
      "Current experiment parameters: ('43_WDBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9710693840760274, 'aucpr': 0.6208552588423546}, fitting time: 78.95435690879822, inference time: 0.0029261112213134766\n",
      "generating duplicate samples for dataset 43_WDBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 30, 'Anomalies': 275, 'Anomalies Ratio(%)': 2.75}\n",
      "Train data shape after filter corrcoef:  (7000, 27)\n",
      "epoch : 1000/5000, loss = 4.142842\n",
      "epoch : 2000/5000, loss = 3.400048\n",
      "epoch : 3000/5000, loss = 3.035716\n",
      "epoch : 4000/5000, loss = 2.830474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "794it [4:51:03, 15.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.707265\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9651853901722762, AUC-PR: 0.6133590396209777\n",
      "Current experiment parameters: ('43_WDBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9651853901722762, 'aucpr': 0.6133590396209777}, fitting time: 79.16296911239624, inference time: 0.003943920135498047\n",
      "generating duplicate samples for dataset 43_WDBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 30, 'Anomalies': 261, 'Anomalies Ratio(%)': 2.61}\n",
      "Train data shape after filter corrcoef:  (7000, 27)\n",
      "epoch : 1000/5000, loss = 4.090987\n",
      "epoch : 2000/5000, loss = 3.000830\n",
      "epoch : 3000/5000, loss = 2.651340\n",
      "epoch : 4000/5000, loss = 2.436459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "795it [4:53:18, 21.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.300561\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9828226188595799, AUC-PR: 0.683854226349243\n",
      "Current experiment parameters: ('43_WDBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9828226188595799, 'aucpr': 0.683854226349243}, fitting time: 80.3174729347229, inference time: 0.002935647964477539\n",
      "generating duplicate samples for dataset 29_Pima...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 8, 'Anomalies': 3452, 'Anomalies Ratio(%)': 34.52}\n",
      "Train data shape after filter corrcoef:  (7000, 8)\n",
      "epoch : 1000/5000, loss = 0.966298\n",
      "epoch : 2000/5000, loss = 0.717485\n",
      "epoch : 3000/5000, loss = 0.620886\n",
      "epoch : 4000/5000, loss = 0.554776\n",
      "epoch : 5000/5000, loss = 0.507593\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8719921914932097, AUC-PR: 0.8127159221596221\n",
      "Current experiment parameters: ('29_Pima', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8719921914932097, 'aucpr': 0.8127159221596221}, fitting time: 75.78889107704163, inference time: 0.0032777786254882812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "817it [4:55:38, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 29_Pima...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 8, 'Anomalies': 3360, 'Anomalies Ratio(%)': 33.6}\n",
      "Train data shape after filter corrcoef:  (7000, 8)\n",
      "epoch : 1000/5000, loss = 1.118906\n",
      "epoch : 2000/5000, loss = 0.815321\n",
      "epoch : 3000/5000, loss = 0.683055\n",
      "epoch : 4000/5000, loss = 0.607598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "818it [4:58:19, 18.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.550890\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.895279032797858, AUC-PR: 0.8444336556382896\n",
      "Current experiment parameters: ('29_Pima', 0.0, 2), model: Customized, metrics: {'aucroc': 0.895279032797858, 'aucpr': 0.8444336556382896}, fitting time: 78.19035696983337, inference time: 0.004200935363769531\n",
      "generating duplicate samples for dataset 29_Pima...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 8, 'Anomalies': 3541, 'Anomalies Ratio(%)': 35.41}\n",
      "Train data shape after filter corrcoef:  (7000, 8)\n",
      "epoch : 1000/5000, loss = 1.022434\n",
      "epoch : 2000/5000, loss = 0.784575\n",
      "epoch : 3000/5000, loss = 0.666247\n",
      "epoch : 4000/5000, loss = 0.598190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "819it [5:00:41, 24.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.549672\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8766755289686496, AUC-PR: 0.8243792763223012\n",
      "Current experiment parameters: ('29_Pima', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8766755289686496, 'aucpr': 0.8243792763223012}, fitting time: 75.2638611793518, inference time: 0.002972126007080078\n",
      "generating duplicate samples for dataset 7_Cardiotocography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 2139, 'Anomalies Ratio(%)': 21.39}\n",
      "Train data shape after filter corrcoef:  (7000, 21)\n",
      "epoch : 1000/5000, loss = 3.662955\n",
      "epoch : 2000/5000, loss = 2.548727\n",
      "epoch : 3000/5000, loss = 2.176200\n",
      "epoch : 4000/5000, loss = 2.001314\n",
      "epoch : 5000/5000, loss = 1.853613\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.939574035760809, AUC-PR: 0.8254410264034743\n",
      "Current experiment parameters: ('7_Cardiotocography', 0.0, 1), model: Customized, metrics: {'aucroc': 0.939574035760809, 'aucpr': 0.8254410264034743}, fitting time: 76.33625793457031, inference time: 0.003403902053833008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "841it [5:03:30, 14.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 7_Cardiotocography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 2231, 'Anomalies Ratio(%)': 22.31}\n",
      "Train data shape after filter corrcoef:  (7000, 21)\n",
      "epoch : 1000/5000, loss = 3.817826\n",
      "epoch : 2000/5000, loss = 2.883804\n",
      "epoch : 3000/5000, loss = 2.517770\n",
      "epoch : 4000/5000, loss = 2.332357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "842it [5:07:11, 22.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.188014\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9316061737586401, AUC-PR: 0.7997917331777419\n",
      "Current experiment parameters: ('7_Cardiotocography', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9316061737586401, 'aucpr': 0.7997917331777419}, fitting time: 77.28746294975281, inference time: 0.0030231475830078125\n",
      "generating duplicate samples for dataset 7_Cardiotocography...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 21, 'Anomalies': 2255, 'Anomalies Ratio(%)': 22.55}\n",
      "Train data shape after filter corrcoef:  (7000, 21)\n",
      "epoch : 1000/5000, loss = 3.907736\n",
      "epoch : 2000/5000, loss = 3.036678\n",
      "epoch : 3000/5000, loss = 2.624913\n",
      "epoch : 4000/5000, loss = 2.364863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "843it [5:10:33, 31.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.195285\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9289285553049557, AUC-PR: 0.8146709209413753\n",
      "Current experiment parameters: ('7_Cardiotocography', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9289285553049557, 'aucpr': 0.8146709209413753}, fitting time: 76.93605613708496, inference time: 0.0030219554901123047\n",
      "subsampling for dataset 5_campaign...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1134, 'Anomalies Ratio(%)': 11.34}\n",
      "Train data shape after filter corrcoef:  (7000, 60)\n",
      "epoch : 1000/5000, loss = 28.751240\n",
      "epoch : 2000/5000, loss = 25.097073\n",
      "epoch : 3000/5000, loss = 23.640780\n",
      "epoch : 4000/5000, loss = 22.622189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "865it [5:12:35, 15.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 22.084243\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9933624502432552, AUC-PR: 0.9683572491066683\n",
      "Current experiment parameters: ('5_campaign', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9933624502432552, 'aucpr': 0.9683572491066683}, fitting time: 89.7622389793396, inference time: 0.0038797855377197266\n",
      "subsampling for dataset 5_campaign...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "Train data shape after filter corrcoef:  (7000, 60)\n",
      "epoch : 1000/5000, loss = 29.423039\n",
      "epoch : 2000/5000, loss = 25.811049\n",
      "epoch : 3000/5000, loss = 24.094052\n",
      "epoch : 4000/5000, loss = 23.048576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "866it [5:14:39, 19.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 22.437761\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9938852362154534, AUC-PR: 0.9502323194514476\n",
      "Current experiment parameters: ('5_campaign', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9938852362154534, 'aucpr': 0.9502323194514476}, fitting time: 90.77105689048767, inference time: 0.0038993358612060547\n",
      "subsampling for dataset 5_campaign...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1129, 'Anomalies Ratio(%)': 11.29}\n",
      "Train data shape after filter corrcoef:  (7000, 60)\n",
      "epoch : 1000/5000, loss = 31.052498\n",
      "epoch : 2000/5000, loss = 26.950399\n",
      "epoch : 3000/5000, loss = 25.011437\n",
      "epoch : 4000/5000, loss = 23.957683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "867it [5:16:40, 24.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 23.251370\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9952520788090622, AUC-PR: 0.9682831623046045\n",
      "Current experiment parameters: ('5_campaign', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9952520788090622, 'aucpr': 0.9682831623046045}, fitting time: 90.6620888710022, inference time: 0.0034461021423339844\n",
      "generating duplicate samples for dataset 44_Wilt...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 5, 'Anomalies': 505, 'Anomalies Ratio(%)': 5.05}\n",
      "Train data shape after filter corrcoef:  (7000, 5)\n",
      "epoch : 1000/5000, loss = 0.479950\n",
      "epoch : 2000/5000, loss = 0.433532\n",
      "epoch : 3000/5000, loss = 0.464584\n",
      "epoch : 4000/5000, loss = 0.483034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "889it [5:18:00, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.526141\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.7672096762270845, AUC-PR: 0.23835626405225752\n",
      "Current experiment parameters: ('44_Wilt', 0.0, 1), model: Customized, metrics: {'aucroc': 0.7672096762270845, 'aucpr': 0.23835626405225752}, fitting time: 75.76960611343384, inference time: 0.002680063247680664\n",
      "generating duplicate samples for dataset 44_Wilt...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 5, 'Anomalies': 575, 'Anomalies Ratio(%)': 5.75}\n",
      "Train data shape after filter corrcoef:  (7000, 5)\n",
      "epoch : 1000/5000, loss = 0.446693\n",
      "epoch : 2000/5000, loss = 0.358597\n",
      "epoch : 3000/5000, loss = 0.377293\n",
      "epoch : 4000/5000, loss = 0.391342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "890it [5:19:21, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.439828\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8144468931943029, AUC-PR: 0.2440688388884188\n",
      "Current experiment parameters: ('44_Wilt', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8144468931943029, 'aucpr': 0.2440688388884188}, fitting time: 74.9422767162323, inference time: 0.0030989646911621094\n",
      "generating duplicate samples for dataset 44_Wilt...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 5, 'Anomalies': 518, 'Anomalies Ratio(%)': 5.18}\n",
      "Train data shape after filter corrcoef:  (7000, 5)\n",
      "epoch : 1000/5000, loss = 0.475318\n",
      "epoch : 2000/5000, loss = 0.453409\n",
      "epoch : 3000/5000, loss = 0.410475\n",
      "epoch : 4000/5000, loss = 0.423297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "891it [5:20:42, 17.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.359839\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.80450592437213, AUC-PR: 0.207980724558989\n",
      "Current experiment parameters: ('44_Wilt', 0.0, 3), model: Customized, metrics: {'aucroc': 0.80450592437213, 'aucpr': 0.207980724558989}, fitting time: 74.8367350101471, inference time: 0.0025849342346191406\n",
      "subsampling for dataset 10_cover...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 97, 'Anomalies Ratio(%)': 0.97}\n",
      "Train data shape after filter corrcoef:  (7000, 10)\n",
      "epoch : 1000/5000, loss = 1.233377\n",
      "epoch : 2000/5000, loss = 0.909811\n",
      "epoch : 3000/5000, loss = 0.721081\n",
      "epoch : 4000/5000, loss = 0.616527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "913it [5:25:43, 15.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.552605\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9015308905627968, AUC-PR: 0.3054833683295539\n",
      "Current experiment parameters: ('10_cover', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9015308905627968, 'aucpr': 0.3054833683295539}, fitting time: 76.88827800750732, inference time: 0.0026531219482421875\n",
      "subsampling for dataset 10_cover...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 116, 'Anomalies Ratio(%)': 1.16}\n",
      "Train data shape after filter corrcoef:  (7000, 10)\n",
      "epoch : 1000/5000, loss = 1.206863\n",
      "epoch : 2000/5000, loss = 0.741820\n",
      "epoch : 3000/5000, loss = 0.599722\n",
      "epoch : 4000/5000, loss = 0.528491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "914it [5:30:36, 26.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.476446\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9477908937605395, AUC-PR: 0.36064813799496853\n",
      "Current experiment parameters: ('10_cover', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9477908937605395, 'aucpr': 0.36064813799496853}, fitting time: 75.79507207870483, inference time: 0.002791881561279297\n",
      "subsampling for dataset 10_cover...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 95, 'Anomalies Ratio(%)': 0.95}\n",
      "Train data shape after filter corrcoef:  (7000, 10)\n",
      "epoch : 1000/5000, loss = 0.896811\n",
      "epoch : 2000/5000, loss = 0.683950\n",
      "epoch : 3000/5000, loss = 0.562875\n",
      "epoch : 4000/5000, loss = 0.498964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "915it [5:35:53, 41.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.456111\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9583493558930974, AUC-PR: 0.3592246898046253\n",
      "Current experiment parameters: ('10_cover', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9583493558930974, 'aucpr': 0.3592246898046253}, fitting time: 75.81496667861938, inference time: 0.0033731460571289062\n",
      "generating duplicate samples for dataset 46_WPBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 33, 'Anomalies': 2318, 'Anomalies Ratio(%)': 23.18}\n",
      "Train data shape after filter corrcoef:  (7000, 31)\n",
      "epoch : 1000/5000, loss = 4.688350\n",
      "epoch : 2000/5000, loss = 3.711597\n",
      "epoch : 3000/5000, loss = 3.248761\n",
      "epoch : 4000/5000, loss = 3.004434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "937it [5:37:27, 18.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.822504\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9649925872750824, AUC-PR: 0.9213364369282286\n",
      "Current experiment parameters: ('46_WPBC', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9649925872750824, 'aucpr': 0.9213364369282286}, fitting time: 80.10103583335876, inference time: 0.003114938735961914\n",
      "generating duplicate samples for dataset 46_WPBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 33, 'Anomalies': 2333, 'Anomalies Ratio(%)': 23.33}\n",
      "Train data shape after filter corrcoef:  (7000, 31)\n",
      "epoch : 1000/5000, loss = 5.034597\n",
      "epoch : 2000/5000, loss = 3.700664\n",
      "epoch : 3000/5000, loss = 3.219035\n",
      "epoch : 4000/5000, loss = 2.954370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [5:39:01, 21.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.768416\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9633354037267081, AUC-PR: 0.9307392431020097\n",
      "Current experiment parameters: ('46_WPBC', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9633354037267081, 'aucpr': 0.9307392431020097}, fitting time: 80.07712817192078, inference time: 0.003782033920288086\n",
      "generating duplicate samples for dataset 46_WPBC...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 33, 'Anomalies': 2395, 'Anomalies Ratio(%)': 23.95}\n",
      "Train data shape after filter corrcoef:  (7000, 31)\n",
      "epoch : 1000/5000, loss = 4.685335\n",
      "epoch : 2000/5000, loss = 3.532493\n",
      "epoch : 3000/5000, loss = 3.083317\n",
      "epoch : 4000/5000, loss = 2.804187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "939it [5:40:33, 24.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 2.608551\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9567302972673211, AUC-PR: 0.9260151675372006\n",
      "Current experiment parameters: ('46_WPBC', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9567302972673211, 'aucpr': 0.9260151675372006}, fitting time: 79.97770094871521, inference time: 0.003080129623413086\n",
      "generating duplicate samples for dataset 37_Stamps...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 908, 'Anomalies Ratio(%)': 9.08}\n",
      "Train data shape after filter corrcoef:  (7000, 9)\n",
      "epoch : 1000/5000, loss = 0.863007\n",
      "epoch : 2000/5000, loss = 0.473221\n",
      "epoch : 3000/5000, loss = 0.369961\n",
      "epoch : 4000/5000, loss = 0.323487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "961it [5:42:59, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.292557\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8874956874245299, AUC-PR: 0.5373590375739036\n",
      "Current experiment parameters: ('37_Stamps', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8874956874245299, 'aucpr': 0.5373590375739036}, fitting time: 75.99530911445618, inference time: 0.002991199493408203\n",
      "generating duplicate samples for dataset 37_Stamps...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 918, 'Anomalies Ratio(%)': 9.18}\n",
      "Train data shape after filter corrcoef:  (7000, 9)\n",
      "epoch : 1000/5000, loss = 0.570917\n",
      "epoch : 2000/5000, loss = 0.416911\n",
      "epoch : 3000/5000, loss = 0.355414\n",
      "epoch : 4000/5000, loss = 0.316238\n",
      "epoch : 5000/5000, loss = 0.291764\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8552393661384488, AUC-PR: 0.4509374761140873\n",
      "Current experiment parameters: ('37_Stamps', 0.0, 2), model: Customized, metrics: {'aucroc': 0.8552393661384488, 'aucpr': 0.4509374761140873}, fitting time: 76.19617104530334, inference time: 0.0038068294525146484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "962it [5:45:52, 19.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 37_Stamps...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 9, 'Anomalies': 874, 'Anomalies Ratio(%)': 8.74}\n",
      "Train data shape after filter corrcoef:  (7000, 9)\n",
      "epoch : 1000/5000, loss = 0.626415\n",
      "epoch : 2000/5000, loss = 0.438008\n",
      "epoch : 3000/5000, loss = 0.360212\n",
      "epoch : 4000/5000, loss = 0.318754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "963it [5:48:14, 26.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.293094\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9018952932714022, AUC-PR: 0.5475150978137587\n",
      "Current experiment parameters: ('37_Stamps', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9018952932714022, 'aucpr': 0.5475150978137587}, fitting time: 75.18901705741882, inference time: 0.0037360191345214844\n",
      "generating duplicate samples for dataset 2_annthyroid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 695, 'Anomalies Ratio(%)': 6.95}\n",
      "Train data shape after filter corrcoef:  (7000, 6)\n",
      "epoch : 1000/5000, loss = 0.455325\n",
      "epoch : 2000/5000, loss = 0.338047\n",
      "epoch : 3000/5000, loss = 0.279386\n",
      "epoch : 4000/5000, loss = 0.246705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "985it [5:50:50, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.228141\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8153773831827199, AUC-PR: 0.29562821748266416\n",
      "Current experiment parameters: ('2_annthyroid', 0.0, 1), model: Customized, metrics: {'aucroc': 0.8153773831827199, 'aucpr': 0.29562821748266416}, fitting time: 76.10463213920593, inference time: 0.0032961368560791016\n",
      "generating duplicate samples for dataset 2_annthyroid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 746, 'Anomalies Ratio(%)': 7.46}\n",
      "Train data shape after filter corrcoef:  (7000, 6)\n",
      "epoch : 1000/5000, loss = 0.405861\n",
      "epoch : 2000/5000, loss = 0.298127\n",
      "epoch : 3000/5000, loss = 0.248679\n",
      "epoch : 4000/5000, loss = 0.216945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "986it [5:53:26, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.199231\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.7788168356319473, AUC-PR: 0.2727507079550842\n",
      "Current experiment parameters: ('2_annthyroid', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7788168356319473, 'aucpr': 0.2727507079550842}, fitting time: 76.3975019454956, inference time: 0.0039520263671875\n",
      "generating duplicate samples for dataset 2_annthyroid...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 6, 'Anomalies': 747, 'Anomalies Ratio(%)': 7.47}\n",
      "Train data shape after filter corrcoef:  (7000, 6)\n",
      "epoch : 1000/5000, loss = 0.409056\n",
      "epoch : 2000/5000, loss = 0.308997\n",
      "epoch : 3000/5000, loss = 0.279665\n",
      "epoch : 4000/5000, loss = 0.242699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "987it [5:56:29, 28.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.210696\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.8051377881844379, AUC-PR: 0.28088227622513023\n",
      "Current experiment parameters: ('2_annthyroid', 0.0, 3), model: Customized, metrics: {'aucroc': 0.8051377881844379, 'aucpr': 0.28088227622513023}, fitting time: 76.73458909988403, inference time: 0.0034742355346679688\n",
      "generating duplicate samples for dataset 27_PageBlocks...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 900, 'Anomalies Ratio(%)': 9.0}\n",
      "Train data shape after filter corrcoef:  (7000, 10)\n",
      "epoch : 1000/5000, loss = 0.405760\n",
      "epoch : 2000/5000, loss = 0.242341\n",
      "epoch : 3000/5000, loss = 0.193875\n",
      "epoch : 4000/5000, loss = 0.162135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1009it [5:59:59, 16.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.147944\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.77334011667345, AUC-PR: 0.28564113311706596\n",
      "Current experiment parameters: ('27_PageBlocks', 0.0, 1), model: Customized, metrics: {'aucroc': 0.77334011667345, 'aucpr': 0.28564113311706596}, fitting time: 75.87772417068481, inference time: 0.002841949462890625\n",
      "generating duplicate samples for dataset 27_PageBlocks...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 936, 'Anomalies Ratio(%)': 9.36}\n",
      "Train data shape after filter corrcoef:  (7000, 10)\n",
      "epoch : 1000/5000, loss = 0.391798\n",
      "epoch : 2000/5000, loss = 0.275367\n",
      "epoch : 3000/5000, loss = 0.227105\n",
      "epoch : 4000/5000, loss = 0.195870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [6:05:15, 28.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 0.174692\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.7708075111349029, AUC-PR: 0.25397206072264766\n",
      "Current experiment parameters: ('27_PageBlocks', 0.0, 2), model: Customized, metrics: {'aucroc': 0.7708075111349029, 'aucpr': 0.25397206072264766}, fitting time: 75.50393414497375, inference time: 0.003084897994995117\n",
      "generating duplicate samples for dataset 27_PageBlocks...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 10, 'Anomalies': 1004, 'Anomalies Ratio(%)': 10.04}\n",
      "Train data shape after filter corrcoef:  (7000, 10)\n",
      "epoch : 1000/5000, loss = 0.354543\n",
      "epoch : 2000/5000, loss = 0.238238\n",
      "epoch : 3000/5000, loss = 0.191071\n",
      "epoch : 4000/5000, loss = 0.173454\n",
      "epoch : 5000/5000, loss = 0.155173\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.7732493516117079, AUC-PR: 0.30625225982671306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1011it [6:09:39, 40.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('27_PageBlocks', 0.0, 3), model: Customized, metrics: {'aucroc': 0.7732493516117079, 'aucpr': 0.30625225982671306}, fitting time: 85.38988089561462, inference time: 0.010395288467407227\n",
      "generating duplicate samples for dataset 31_satimage-2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 110, 'Anomalies Ratio(%)': 1.1}\n",
      "Train data shape after filter corrcoef:  (7000, 36)\n",
      "epoch : 1000/5000, loss = 2.532155\n",
      "epoch : 2000/5000, loss = 2.174105\n",
      "epoch : 3000/5000, loss = 1.963343\n",
      "epoch : 4000/5000, loss = 1.819582\n",
      "epoch : 5000/5000, loss = 1.739664\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9434690688482398, AUC-PR: 0.18239959005751105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1033it [6:12:42, 20.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('31_satimage-2', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9434690688482398, 'aucpr': 0.18239959005751105}, fitting time: 85.81177020072937, inference time: 0.008485794067382812\n",
      "generating duplicate samples for dataset 31_satimage-2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 126, 'Anomalies Ratio(%)': 1.26}\n",
      "Train data shape after filter corrcoef:  (7000, 36)\n",
      "epoch : 1000/5000, loss = 2.609652\n",
      "epoch : 2000/5000, loss = 2.100253\n",
      "epoch : 3000/5000, loss = 1.832016\n",
      "epoch : 4000/5000, loss = 1.651423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1034it [6:15:33, 26.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.557505\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9542449980454174, AUC-PR: 0.29423387640690135\n",
      "Current experiment parameters: ('31_satimage-2', 0.0, 2), model: Customized, metrics: {'aucroc': 0.9542449980454174, 'aucpr': 0.29423387640690135}, fitting time: 83.46347212791443, inference time: 0.004773139953613281\n",
      "generating duplicate samples for dataset 31_satimage-2...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 36, 'Anomalies': 115, 'Anomalies Ratio(%)': 1.15}\n",
      "Train data shape after filter corrcoef:  (7000, 36)\n",
      "epoch : 1000/5000, loss = 2.557024\n",
      "epoch : 2000/5000, loss = 2.036347\n",
      "epoch : 3000/5000, loss = 1.764036\n",
      "epoch : 4000/5000, loss = 1.603118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1035it [6:18:42, 34.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 1.506785\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9750505731625084, AUC-PR: 0.4034286399138699\n",
      "Current experiment parameters: ('31_satimage-2', 0.0, 3), model: Customized, metrics: {'aucroc': 0.9750505731625084, 'aucpr': 0.4034286399138699}, fitting time: 83.0590751171112, inference time: 0.0034160614013671875\n",
      "subsampling for dataset 3_backdoor...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 252, 'Anomalies Ratio(%)': 2.52}\n",
      "Train data shape after filter corrcoef:  (7000, 192)\n",
      "epoch : 1000/5000, loss = 144.729288\n",
      "epoch : 2000/5000, loss = 136.629519\n",
      "epoch : 3000/5000, loss = 133.416460\n",
      "epoch : 4000/5000, loss = 131.675485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1057it [6:21:26, 17.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 130.472991\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 1.0, AUC-PR: 1.0000000000000002\n",
      "Current experiment parameters: ('3_backdoor', 0.0, 1), model: Customized, metrics: {'aucroc': 1.0, 'aucpr': 1.0000000000000002}, fitting time: 140.12855219841003, inference time: 0.007905006408691406\n",
      "subsampling for dataset 3_backdoor...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 246, 'Anomalies Ratio(%)': 2.46}\n",
      "Train data shape after filter corrcoef:  (7000, 192)\n",
      "epoch : 1000/5000, loss = 144.224628\n",
      "epoch : 2000/5000, loss = 135.705401\n",
      "epoch : 3000/5000, loss = 132.502578\n",
      "epoch : 4000/5000, loss = 130.783843\n",
      "epoch : 5000/5000, loss = 129.705788\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 1.0, AUC-PR: 0.9999999999999999\n",
      "Current experiment parameters: ('3_backdoor', 0.0, 2), model: Customized, metrics: {'aucroc': 1.0, 'aucpr': 0.9999999999999999}, fitting time: 145.68485307693481, inference time: 0.008313894271850586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1058it [6:24:28, 24.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsampling for dataset 3_backdoor...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 196, 'Anomalies': 256, 'Anomalies Ratio(%)': 2.56}\n",
      "Train data shape after filter corrcoef:  (7000, 192)\n",
      "epoch : 1000/5000, loss = 143.727243\n",
      "epoch : 2000/5000, loss = 135.914506\n",
      "epoch : 3000/5000, loss = 132.703426\n",
      "epoch : 4000/5000, loss = 130.746948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1059it [6:27:16, 31.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5000/5000, loss = 129.598597\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 1.0, AUC-PR: 1.0\n",
      "Current experiment parameters: ('3_backdoor', 0.0, 3), model: Customized, metrics: {'aucroc': 1.0, 'aucpr': 1.0}, fitting time: 143.57088208198547, inference time: 0.007938146591186523\n",
      "generating duplicate samples for dataset 36_speech...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 400, 'Anomalies': 166, 'Anomalies Ratio(%)': 1.66}\n",
      "Train data shape after filter corrcoef:  (7000, 400)\n",
      "epoch : 1000/5000, loss = 348.235225\n",
      "epoch : 2000/5000, loss = 338.431047\n",
      "epoch : 3000/5000, loss = 334.553804\n",
      "epoch : 4000/5000, loss = 332.124429\n",
      "epoch : 5000/5000, loss = 330.790384\n",
      "(3000,)\n",
      "(3000, 1)\n",
      "Model: Customized, AUC-ROC: 0.9999999999999999, AUC-PR: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1081it [6:32:25, 20.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current experiment parameters: ('36_speech', 0.0, 1), model: Customized, metrics: {'aucroc': 0.9999999999999999, 'aucpr': 1.0}, fitting time: 239.88499903678894, inference time: 0.017811059951782227\n",
      "generating duplicate samples for dataset 36_speech...\n"
     ]
    }
   ],
   "source": [
    "#customized = SimpleAE()\n",
    "results = pipeline.run(clf=SimpleAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adbench.baseline.FEAWAD.run import FEAWAD\n",
    "from adbench.baseline.DeepSAD.src.run import DeepSAD\n",
    "from adbench.baseline.PyOD import KNN\n",
    "results = pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your customized algorithm on customized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized model on customized dataset\n",
    "import numpy as np\n",
    "dataset = {}\n",
    "dataset['X'] = np.random.randn(1000, 20)\n",
    "dataset['y'] = np.random.choice([0, 1], 1000)\n",
    "results = pipeline.run(dataset=dataset, clf=SimpleAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import AD algorithms from ADBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit transform: X shape before:  (1000, 4)\n",
      "[[0. 1. 1. 1.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 1. 0.]]\n",
      "Train data shape after filter corrcoef:  (1000, 1)\n",
      "epoch : 1000/3000, loss = 1.000339\n",
      "epoch : 2000/3000, loss = 1.000902\n",
      "epoch : 3000/3000, loss = 1.001148\n",
      "(100, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' from adbench.baseline.PReNet.run import PReNet\\nmodel = PReNet(seed=42)\\nmodel.fit(X_train, y_train)  # fit\\nscore = model.predict_score(X_test)  # predict '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = np.random.randn(1000, 1)\n",
    "X_train = np.concatenate((X_train, X_train, X_train, X_train), axis=-1)\n",
    "y_train = np.random.choice([0, 1], 1000)\n",
    "X_test = np.random.randn(100, 4)\n",
    "y_test = np.random.choice([0, 1], 100)\n",
    "\n",
    "# Directly import AD algorithms from the existing toolkits like PyOD\n",
    "#from adbench.baseline.PyOD import PYOD\n",
    "#model = PYOD(seed=42, model_name='XGBOD')  # initialization\n",
    "model = SimpleAE(seed=42)\n",
    "model.fit(X_train, y_train)  # fit\n",
    "score = model.predict_score(X_test)  # predict\n",
    "print(score.shape)\n",
    "\n",
    "# Import deep learning AD algorithms from our ADBench\n",
    "\"\"\" from adbench.baseline.PReNet.run import PReNet\n",
    "model = PReNet(seed=42)\n",
    "model.fit(X_train, y_train)  # fit\n",
    "score = model.predict_score(X_test)  # predict \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
